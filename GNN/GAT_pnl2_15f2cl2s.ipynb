{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1]]\n",
      "TEMPORAL: xformer_cls | heads= 4 | d_model= 64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),\n",
    "    # NEW: holdout final test split (по времени, на sample-space)\n",
    "    \"final_test_frac\": 0.10,\n",
    "\n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 84],  # 30m,1h,2h,4h,7h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 1*12,       # 1h     # нужен для sample_t (чтобы TB-exit не вылезал за конец)\n",
    "    \"lookback\": 7*12,\n",
    "    \"tb_pt_mult\": 1.2,\n",
    "    \"tb_sl_mult\": 1.1,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "\n",
    "    # training (общие)\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.3,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "\n",
    "    # --- old Attn params kept for compatibility: now used as ATTENTION dims ---\n",
    "    # Attn_hidden -> d_model (размер темпорального представления)\n",
    "    # Attn_layers -> n_layers (кол-во attention/transformer layers, если режим их использует)\n",
    "    \"Attn_hidden\": 64,\n",
    "    \"Attn_layers\": 1,\n",
    "\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "\n",
    "    # ---- PnL proxy during DIR training (grid selector)\n",
    "    \"proxy_min_trades\": 20,\n",
    "\n",
    "    # -------------------------------\n",
    "    # NEW: attention-based temporal encoder config\n",
    "    # -------------------------------\n",
    "    # ДВА режима (по твоему требованию):\n",
    "    # 1) \"xformer_cls\"  -> TransformerEncoder + [CLS] token, берём CLS как summary\n",
    "    # 2) \"attn_pool\"    -> learnable query + MultiHeadAttention pooling (быстрый и стабильный)\n",
    "    \"temporal_mode\": \"xformer_cls\",   # \"xformer_cls\" | \"attn_pool\"\n",
    "    \"attn_heads\": 4,                  # будет автоматически приведено к делителю d_model\n",
    "    \"attn_ff_mult\": 4,                # FFN dim = ff_mult * d_model (для xformer_cls)\n",
    "    \"attn_dropout\": None,             # None -> использовать CFG[\"dropout\"]\n",
    "    \"attn_causal\": False,             # опционально для xformer (обычно False, т.к. окно past-only)\n",
    "    \"attn_use_pos_emb\": True,         # learned positional embeddings\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "print(\"EDGE_INDEX:\", EDGE_INDEX.tolist())\n",
    "\n",
    "print(\"TEMPORAL:\", CFG[\"temporal_mode\"], \"| heads=\", CFG[\"attn_heads\"], \"| d_model=\", CFG[\"Attn_hidden\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (2693, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int, part = [0,100]) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.iloc[int(len(df)*part[0]/100) : int(len(df)*part[1]/100)]\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels, part = [0, 80]), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels, part = [0, 80]), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels, part = [0, 80]), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (2693, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [ 655 1311  727]\n",
      "Trade ratio: 0.5131823245451169\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=1*12, \n",
    "    vol_window=7*12,\n",
    "    pt_mult=1.2,\n",
    "    sl_mult=1.1,\n",
    "    min_barrier=0.001,\n",
    "    max_barrier=0.006,\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (2693, 3, 15) edge_feat: (2693, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 2597 t range: 83 2679\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb5de4",
   "metadata": {},
   "source": [
    "## Train (folds) - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9bad799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout split:\n",
      "  n_samples total: 2597\n",
      "  n_samples CV   : 2337 (90.0%)\n",
      "  n_samples FINAL: 260 (10.0%)\n",
      "  CV range   : 0 2336\n",
      "  FINAL range: 2337 2596\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: final holdout split (90% CV + 10% final test), time-ordered\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_final_holdout_split(n_samples: int, final_test_frac: float):\n",
    "    if not (0.0 < final_test_frac < 0.5):\n",
    "        raise ValueError(\"final_test_frac should be in (0, 0.5)\")\n",
    "\n",
    "    n_final = max(1, int(round(final_test_frac * n_samples)))\n",
    "    n_cv = n_samples - n_final\n",
    "    if n_cv <= 10:\n",
    "        raise ValueError(\"Too few samples left for CV after holdout split.\")\n",
    "\n",
    "    idx_cv = np.arange(0, n_cv, dtype=np.int64)\n",
    "    idx_final = np.arange(n_cv, n_samples, dtype=np.int64)\n",
    "    return idx_cv, idx_final, n_cv, n_final\n",
    "\n",
    "idx_cv_all, idx_final_test, n_samples_cv, n_samples_final = make_final_holdout_split(\n",
    "    n_samples=n_samples,\n",
    "    final_test_frac=CFG[\"final_test_frac\"],\n",
    ")\n",
    "\n",
    "print(\"Holdout split:\")\n",
    "print(\"  n_samples total:\", n_samples)\n",
    "print(\"  n_samples CV   :\", n_samples_cv, f\"({100*(n_samples_cv/n_samples):.1f}%)\")\n",
    "print(\"  n_samples FINAL:\", n_samples_final, f\"({100*(n_samples_final/n_samples):.1f}%)\")\n",
    "print(\"  CV range   :\", idx_cv_all[0], idx_cv_all[-1])\n",
    "print(\"  FINAL range:\", idx_final_test[0], idx_final_test[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1168 | val 233 | test 233\n",
      " fold 2: train 1401 | val 233 | test 233\n",
      " fold 3: train 1634 | val 233 | test 233\n",
      " fold 4: train 1867 | val 233 | test 233\n",
      "\n",
      "FINAL HOLDOUT:\n",
      " final_test size: 260\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test) on CV-part only\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "\n",
    "        idx_train = np.arange(0, tr_end, dtype=np.int64)\n",
    "        idx_val   = np.arange(tr_end, va_end, dtype=np.int64)\n",
    "        idx_test  = np.arange(va_end, te_end, dtype=np.int64)\n",
    "\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "\n",
    "    return splits\n",
    "\n",
    "# IMPORTANT: строим сплиты только на 90% (CV-part)\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples_cv,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "for i, (a, b, c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT:\")\n",
    "print(\" final_test size:\", len(idx_final_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready. logits shape: (4, 2) | temporal_mode: xformer_cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: GNN + ATTENTION temporal classifier (drop-in вместо Attn)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class EdgeGatedMP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_proj = nn.Linear(in_dim, hidden)\n",
    "        self.ln0 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden + edge_dim, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden + 1)  # msg(hidden) + gate(1)\n",
    "        )\n",
    "\n",
    "        self.upd = nn.Sequential(\n",
    "            nn.Linear(2*hidden, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward_once(self, x_t, edge_attr_t, edge_index):\n",
    "        B, N, _ = x_t.shape\n",
    "        E = edge_index.shape[0]\n",
    "\n",
    "        h = self.ln0(self.node_proj(x_t))  # (B,N,H)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        agg = torch.zeros((B, N, h.shape[-1]), device=h.device, dtype=h.dtype)\n",
    "\n",
    "        for e in range(E):\n",
    "            src = edge_index[e, 0].item()\n",
    "            dst = edge_index[e, 1].item()\n",
    "            h_src = h[:, src, :]\n",
    "            h_dst = h[:, dst, :]\n",
    "            ea = edge_attr_t[:, e, :]\n",
    "\n",
    "            z = torch.cat([h_src, h_dst, ea], dim=-1)\n",
    "            out = self.edge_mlp(z)\n",
    "            msg = out[:, :-1]\n",
    "            gate = torch.sigmoid(out[:, -1:])\n",
    "\n",
    "            agg[:, dst, :] += msg * gate\n",
    "\n",
    "        h2 = self.upd(torch.cat([h, agg], dim=-1))\n",
    "        h2 = self.ln1(h + self.dropout(h2))\n",
    "        h2 = torch.nan_to_num(h2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return h2\n",
    "\n",
    "    def forward(self, x_seq, e_seq, edge_index):\n",
    "        B, L, N, Fin = x_seq.shape\n",
    "        h_out = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            h_out.append(ht)\n",
    "        return torch.stack(h_out, dim=1)  # (B,L,N,H)\n",
    "\n",
    "\n",
    "def _greatest_divisor_leq(x: int, k: int) -> int:\n",
    "    k = max(1, min(k, x))\n",
    "    for d in range(k, 0, -1):\n",
    "        if x % d == 0:\n",
    "            return d\n",
    "    return 1\n",
    "\n",
    "\n",
    "class TemporalAttentionEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention-based temporal encoder над последовательностью (B,L,H_in) -> (B,d_model).\n",
    "\n",
    "    CFG[\"temporal_mode\"]:\n",
    "      - \"xformer_cls\": TransformerEncoder + CLS token -> берём CLS\n",
    "      - \"attn_pool\":   learnable query + MultiHeadAttention pooling -> берём pooled\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        d_model: int,\n",
    "        max_len: int,\n",
    "        mode: str = \"xformer_cls\",\n",
    "        n_heads: int = 4,\n",
    "        n_layers: int = 1,\n",
    "        ff_mult: int = 4,\n",
    "        dropout: float = 0.1,\n",
    "        use_pos_emb: bool = True,\n",
    "        causal: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.max_len = int(max_len)\n",
    "        self.use_pos_emb = bool(use_pos_emb)\n",
    "        self.causal = bool(causal)\n",
    "\n",
    "        self.in_proj = nn.Linear(in_dim, d_model) if in_dim != d_model else nn.Identity()\n",
    "        self.ln_in = nn.LayerNorm(d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        # безопасно подгоним heads под d_model\n",
    "        n_heads = _greatest_divisor_leq(d_model, int(n_heads))\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # positional embeddings\n",
    "        # для режима CLS нужно +1 позиция под CLS\n",
    "        pe_len = self.max_len + (1 if mode == \"xformer_cls\" else 0)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(pe_len, d_model)) if self.use_pos_emb else None\n",
    "\n",
    "        if mode == \"xformer_cls\":\n",
    "            self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "\n",
    "            enc_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=d_model,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=int(ff_mult * d_model),\n",
    "                dropout=dropout,\n",
    "                activation=\"gelu\",\n",
    "                batch_first=True,\n",
    "                norm_first=True,\n",
    "            )\n",
    "            self.encoder = nn.TransformerEncoder(enc_layer, num_layers=int(max(1, n_layers)))\n",
    "            self.ln_out = nn.LayerNorm(d_model)\n",
    "\n",
    "        elif mode == \"attn_pool\":\n",
    "            # learnable query token\n",
    "            self.q = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "            self.mha = nn.MultiheadAttention(\n",
    "                embed_dim=d_model,\n",
    "                num_heads=n_heads,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "            self.ln_q = nn.LayerNorm(d_model)\n",
    "            self.ff = nn.Sequential(\n",
    "                nn.Linear(d_model, 2*d_model),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(2*d_model, d_model),\n",
    "            )\n",
    "            self.ln_out = nn.LayerNorm(d_model)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown temporal_mode={mode}. Use 'xformer_cls' or 'attn_pool'.\")\n",
    "\n",
    "        # init\n",
    "        nn.init.normal_(self.pos_emb, std=0.02) if self.pos_emb is not None else None\n",
    "        for p in [getattr(self, \"cls\", None), getattr(self, \"q\", None)]:\n",
    "            if isinstance(p, torch.nn.Parameter):\n",
    "                nn.init.normal_(p, std=0.02)\n",
    "\n",
    "    def _causal_mask(self, L: int, device):\n",
    "        # True = masked (не смотреть в будущее)\n",
    "        m = torch.triu(torch.ones(L, L, device=device, dtype=torch.bool), diagonal=1)\n",
    "        return m\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,L,in_dim)\n",
    "        return: (B,d_model)\n",
    "        \"\"\"\n",
    "        B, L, _ = x.shape\n",
    "        if L > self.max_len:\n",
    "            raise ValueError(f\"Sequence length L={L} > max_len={self.max_len}. Increase CFG['lookback'].\")\n",
    "\n",
    "        h = self.in_proj(x)            # (B,L,D)\n",
    "        h = self.ln_in(h)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        if self.mode == \"xformer_cls\":\n",
    "            cls = self.cls.expand(B, 1, self.d_model)  # (B,1,D)\n",
    "            tokens = torch.cat([cls, h], dim=1)        # (B,1+L,D)\n",
    "\n",
    "            if self.use_pos_emb:\n",
    "                # позиции: 0..L (0=CLS, далее 1..L)\n",
    "                pe = self.pos_emb[:(L+1), :].unsqueeze(0)  # (1,1+L,D)\n",
    "                tokens = tokens + pe\n",
    "\n",
    "            tokens = self.drop(tokens)\n",
    "\n",
    "            # causal mask на tokens с CLS обычно не нужен; если включён — применим только для (1+L)\n",
    "            src_mask = None\n",
    "            if self.causal:\n",
    "                src_mask = self._causal_mask(L+1, device=tokens.device)\n",
    "\n",
    "            z = self.encoder(tokens, mask=src_mask)  # (B,1+L,D)\n",
    "            out = self.ln_out(z[:, 0, :])            # CLS\n",
    "            return torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        # mode == \"attn_pool\"\n",
    "        tokens = h\n",
    "        if self.use_pos_emb:\n",
    "            pe = self.pos_emb[:L, :].unsqueeze(0)   # (1,L,D)\n",
    "            tokens = tokens + pe\n",
    "        tokens = self.drop(tokens)\n",
    "\n",
    "        q = self.q.expand(B, 1, self.d_model)        # (B,1,D)\n",
    "        q = self.ln_q(q)\n",
    "\n",
    "        # pooled attention: query attends over time tokens\n",
    "        attn_out, _ = self.mha(query=q, key=tokens, value=tokens, need_weights=False)  # (B,1,D)\n",
    "        # residual + FFN\n",
    "        y = q + self.drop(attn_out)\n",
    "        y2 = self.ff(y)\n",
    "        y = self.ln_out(y + self.drop(y2))\n",
    "        out = y[:, 0, :]                              # (B,D)\n",
    "        return torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "class GNN_Attn_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    DROP-IN replacement: имя оставлено тем же, но Attn заменён на Attention temporal encoder.\n",
    "\n",
    "    forward(x,e,edge_index) -> logits (B,2)\n",
    "    \"\"\"\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, Attn_hidden, Attn_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = target_node\n",
    "\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(gnn_layers):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(EdgeGatedMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, dropout=dropout))\n",
    "\n",
    "        # --- temporal attention config (берём из CFG; если нет — safe defaults)\n",
    "        temporal_mode = CFG.get(\"temporal_mode\", \"xformer_cls\")\n",
    "        attn_heads = CFG.get(\"attn_heads\", 4)\n",
    "        ff_mult = CFG.get(\"attn_ff_mult\", 4)\n",
    "        attn_dropout = CFG.get(\"attn_dropout\", None)\n",
    "        attn_dropout = float(dropout if attn_dropout is None else attn_dropout)\n",
    "        attn_causal = bool(CFG.get(\"attn_causal\", False))\n",
    "        use_pos = bool(CFG.get(\"attn_use_pos_emb\", True))\n",
    "        max_len = int(CFG.get(\"lookback\", 128))\n",
    "\n",
    "        self.temporal = TemporalAttentionEncoder(\n",
    "            in_dim=hidden,\n",
    "            d_model=int(Attn_hidden),\n",
    "            max_len=max_len,\n",
    "            mode=str(temporal_mode),\n",
    "            n_heads=int(attn_heads),\n",
    "            n_layers=int(max(1, Attn_layers)),\n",
    "            ff_mult=int(ff_mult),\n",
    "            dropout=attn_dropout,\n",
    "            use_pos_emb=use_pos,\n",
    "            causal=attn_causal,\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(int(Attn_hidden)),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(int(Attn_hidden), int(Attn_hidden)),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(int(Attn_hidden), n_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]         # (B,L,H)\n",
    "        rep = self.temporal(h_tgt)                   # (B,d_model)\n",
    "        logits = self.head(rep)                      # (B,2)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# SMOKE TEST (сразу после классов)\n",
    "# ----------------------------\n",
    "def _smoke_test_model():\n",
    "    B = 4\n",
    "    L = CFG[\"lookback\"]\n",
    "    N = 3\n",
    "    F = 15\n",
    "    E = EDGE_INDEX.shape[0]\n",
    "    W = len(CFG[\"corr_windows\"])\n",
    "\n",
    "    x = torch.randn(B, L, N, F)\n",
    "    e = torch.randn(B, L, E, W)\n",
    "\n",
    "    model = GNN_Attn_Classifier(\n",
    "        node_in=F,\n",
    "        edge_dim=W,\n",
    "        hidden=CFG[\"hidden\"],\n",
    "        gnn_layers=CFG[\"gnn_layers\"],\n",
    "        Attn_hidden=CFG[\"Attn_hidden\"],   # now d_model\n",
    "        Attn_layers=CFG[\"Attn_layers\"],   # now attn layers\n",
    "        dropout=CFG[\"dropout\"],\n",
    "        target_node=TARGET_NODE,\n",
    "        n_classes=2\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x.float(), e.float(), EDGE_INDEX)\n",
    "    print(\"Model ready. logits shape:\", tuple(logits.shape), \"| temporal_mode:\", CFG.get(\"temporal_mode\"))\n",
    "\n",
    "_smoke_test_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn, y_key: str = \"trade\"):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        y = (y_trade_b if y_key == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "\n",
    "    ys = np.concatenate(ys) if len(ys) else np.array([], dtype=np.int64)\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, None, ys, probs, ers\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:, 1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss / max(n, 1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_only(model, loader):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "    return probs, ers\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps, min_trades: int = 0):\n",
    "    \"\"\"\n",
    "    Возвращает лучший pnl_mean по grid (per-bar), плюс пороги и статистику.\n",
    "    min_trades используется как фильтр: комбинации, где сделок меньше, пропускаются.\n",
    "    Если ни одна комбинация не прошла min_trades — вернём best без фильтра (но это будет fallback-сценарий).\n",
    "    \"\"\"\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    sign = np.where(p_up >= 0.5, 1.0, -1.0).astype(np.float32)\n",
    "    cost = float(cost_bps) * 1e-4\n",
    "    N = len(exit_ret)\n",
    "\n",
    "    best = {\n",
    "        \"pnl_mean\": -1e18,\n",
    "        \"pnl_sum\": -1e18,\n",
    "        \"thr_trade\": None,\n",
    "        \"thr_dir\": None,\n",
    "        \"n_trades\": 0,\n",
    "        \"trade_rate\": 0.0,\n",
    "        \"min_trades_used\": int(min_trades),\n",
    "        \"passed_min_trades\": False,\n",
    "    }\n",
    "\n",
    "    # 1) строгий проход (>=min_trades)\n",
    "    for thr_t in thr_trade_grid:\n",
    "        mt = (p_trade >= thr_t)\n",
    "        for thr_d in thr_dir_grid:\n",
    "            mask = mt & (conf_dir >= thr_d)\n",
    "            n_tr = int(mask.sum())\n",
    "            if n_tr < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "            pnl_sum = float(pnl.sum())\n",
    "            pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "            if pnl_mean > best[\"pnl_mean\"]:\n",
    "                best.update({\n",
    "                    \"pnl_mean\": pnl_mean,\n",
    "                    \"pnl_sum\": pnl_sum,\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": n_tr,\n",
    "                    \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                    \"passed_min_trades\": True,\n",
    "                })\n",
    "\n",
    "    # 2) если ничего не прошло min_trades — найдём best без фильтра (для fallback-логов)\n",
    "    if best[\"thr_trade\"] is None:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            mt = (p_trade >= thr_t)\n",
    "            for thr_d in thr_dir_grid:\n",
    "                mask = mt & (conf_dir >= thr_d)\n",
    "                n_tr = int(mask.sum())\n",
    "                pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "                pnl_sum = float(pnl.sum())\n",
    "                pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "                if pnl_mean > best[\"pnl_mean\"]:\n",
    "                    best.update({\n",
    "                        \"pnl_mean\": pnl_mean,\n",
    "                        \"pnl_sum\": pnl_sum,\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": n_tr,\n",
    "                        \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "    select_metric: str | None = None,        # \"va_auc\" | \"va_f1m\" | \"va_pnl_max\"\n",
    "    trade_model_for_pnl=None,                # для stage=\"dir\": фиксированная trade-модель\n",
    "    idx_val_pnl=None,                        # индексы (sample-space) для pnl-proxy, обычно полный idx_val\n",
    "):\n",
    "    \"\"\"\n",
    "    Градиентами оптимизируем: CrossEntropyLoss.\n",
    "    Селектор best checkpoint:\n",
    "      - trade: обычно va_auc\n",
    "      - dir:   va_pnl_max, но если best trades < proxy_min_trades => fallback на va_auc\n",
    "              (реализовано как: best_pnl если были эпохи с trades>=min, иначе best_auc)\n",
    "    \"\"\"\n",
    "    if select_metric is None:\n",
    "        select_metric = \"va_auc\"\n",
    "    if select_metric not in (\"va_auc\", \"va_f1m\", \"va_pnl_max\"):\n",
    "        raise ValueError(\"select_metric must be one of: 'va_auc', 'va_f1m', 'va_pnl_max'\")\n",
    "\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if stage_name != \"dir\":\n",
    "            raise ValueError(\"select_metric='va_pnl_max' supported only for stage_name='dir'\")\n",
    "        if trade_model_for_pnl is None or idx_val_pnl is None:\n",
    "            raise ValueError(\"For va_pnl_max you must pass trade_model_for_pnl and idx_val_pnl (full val indices).\")\n",
    "\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val,   L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test,  L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True,  drop_last=True, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    va_pnl_loader = None\n",
    "    if stage_name == \"dir\" and (idx_val_pnl is not None):\n",
    "        va_pnl_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val_pnl, L)\n",
    "        va_pnl_loader = DataLoader(va_pnl_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_Attn_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        Attn_hidden=cfg[\"Attn_hidden\"], Attn_layers=cfg[\"Attn_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\"))\n",
    "\n",
    "    # --- trade-prob на полном val для PnL proxy (считаем 1 раз)\n",
    "    prob_trade_val_pnl = None\n",
    "    if stage_name == \"dir\" and (trade_model_for_pnl is not None) and (va_pnl_loader is not None):\n",
    "        prob_trade_val_pnl, _ = predict_probs_only(trade_model_for_pnl, va_pnl_loader)\n",
    "\n",
    "    thr_trade_grid_proxy = cfg.get(\"proxy_thr_trade_grid\") or cfg.get(\"thr_trade_grid\", [0.5])\n",
    "    thr_dir_grid_proxy   = cfg.get(\"proxy_thr_dir_grid\")   or cfg.get(\"thr_dir_grid\",   [0.5])\n",
    "    proxy_min_trades = int(cfg.get(\"proxy_min_trades\", 0))\n",
    "\n",
    "    # --- best trackers\n",
    "    best_score = -1e18\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "    best_used = select_metric\n",
    "\n",
    "    # специальные трекеры для va_pnl_max с fallback\n",
    "    best_score_auc = -1e18\n",
    "    best_state_auc = None\n",
    "    best_epoch_auc = -1\n",
    "\n",
    "    best_score_pnl = -1e18\n",
    "    best_state_pnl = None\n",
    "    best_epoch_pnl = -1\n",
    "\n",
    "    seen_pnl_ok = False\n",
    "\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\n",
    "        \"tr_loss\": [], \"va_loss\": [],\n",
    "        \"va_f1m\": [], \"va_auc\": [],\n",
    "        \"va_pnl_max\": [],\n",
    "        \"va_pnl_thr_trade\": [],\n",
    "        \"va_pnl_thr_dir\": [],\n",
    "        \"va_pnl_n_trades\": [],\n",
    "        \"va_sel\": [],\n",
    "        \"va_sel_mode\": []\n",
    "    }\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"] + 1):\n",
    "        # ---- TRAIN\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for x, e, y_trade_b, y_dir_b, er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            y = (y_trade_b if stage_name == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot / max(n, 1)\n",
    "\n",
    "        # ---- VAL classification metrics\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, va_loader, loss_fn, y_key=stage_name\n",
    "        )\n",
    "\n",
    "        # ---- VAL PnL proxy (dir only)\n",
    "        va_pnl_best = {\"pnl_mean\": np.nan, \"thr_trade\": np.nan, \"thr_dir\": np.nan, \"n_trades\": 0, \"trade_rate\": np.nan,\n",
    "                       \"passed_min_trades\": False, \"min_trades_used\": proxy_min_trades}\n",
    "\n",
    "        if stage_name == \"dir\" and (prob_trade_val_pnl is not None) and (va_pnl_loader is not None):\n",
    "            prob_dir_val_pnl, er_dir_val_pnl = predict_probs_only(model, va_pnl_loader)\n",
    "\n",
    "            va_pnl_best = pnl_proxy_grid_max(\n",
    "                prob_trade=prob_trade_val_pnl,\n",
    "                prob_dir=prob_dir_val_pnl,\n",
    "                exit_ret=er_dir_val_pnl,\n",
    "                thr_trade_grid=thr_trade_grid_proxy,\n",
    "                thr_dir_grid=thr_dir_grid_proxy,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "                min_trades=proxy_min_trades,\n",
    "            )\n",
    "\n",
    "        # ---- selection\n",
    "        sel_val = np.nan\n",
    "        sel_mode = select_metric\n",
    "\n",
    "        if select_metric in (\"va_auc\", \"va_f1m\"):\n",
    "            sel_val = (va_auc if select_metric == \"va_auc\" else va_f1m)\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "\n",
    "            # единый best\n",
    "            prev_best = best_score\n",
    "            if sel_val > best_score:\n",
    "                best_score = sel_val\n",
    "                best_epoch = ep\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "        else:\n",
    "            # select_metric == \"va_pnl_max\" (dir only) with hard fallback\n",
    "            pnl_mean = float(va_pnl_best[\"pnl_mean\"])\n",
    "            n_tr = int(va_pnl_best[\"n_trades\"])\n",
    "            pnl_ok = (np.isfinite(pnl_mean) and (n_tr >= proxy_min_trades))\n",
    "\n",
    "            # обновим best_auc (fallback) всегда\n",
    "            if np.isfinite(va_auc) and (va_auc > best_score_auc):\n",
    "                best_score_auc = float(va_auc)\n",
    "                best_epoch_auc = ep\n",
    "                best_state_auc = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            # обновим best_pnl только если pnl_ok\n",
    "            if pnl_ok and (pnl_mean > best_score_pnl):\n",
    "                best_score_pnl = pnl_mean\n",
    "                best_epoch_pnl = ep\n",
    "                best_state_pnl = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            if pnl_ok:\n",
    "                seen_pnl_ok = True\n",
    "                sel_val = pnl_mean\n",
    "                sel_mode = \"va_pnl_max\"\n",
    "            else:\n",
    "                sel_val = float(va_auc) if np.isfinite(va_auc) else -1e18\n",
    "                sel_mode = f\"va_auc_fallback({n_tr}/{proxy_min_trades})\"\n",
    "\n",
    "            # scheduler всегда по текущему sel_val\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "            # early stop: до первой валидной pnl-эпохи -> по AUC, после -> по PnL\n",
    "            improved = False\n",
    "            if not seen_pnl_ok:\n",
    "                # следим за ростом AUC\n",
    "                improved = (np.isfinite(va_auc) and (float(va_auc) >= best_score_auc))\n",
    "            else:\n",
    "                # следим за ростом PnL (только когда pnl_ok)\n",
    "                improved = pnl_ok and (pnl_mean >= best_score_pnl)\n",
    "\n",
    "            if improved:\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "        # если не pnl-метрика — scheduler тут\n",
    "        if select_metric != \"va_pnl_max\":\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "        # ---- logging + hist\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "\n",
    "        hist[\"va_pnl_max\"].append(float(va_pnl_best[\"pnl_mean\"]) if np.isfinite(va_pnl_best[\"pnl_mean\"]) else np.nan)\n",
    "        hist[\"va_pnl_thr_trade\"].append(float(va_pnl_best[\"thr_trade\"]) if va_pnl_best[\"thr_trade\"] is not None else np.nan)\n",
    "        hist[\"va_pnl_thr_dir\"].append(float(va_pnl_best[\"thr_dir\"]) if va_pnl_best[\"thr_dir\"] is not None else np.nan)\n",
    "        hist[\"va_pnl_n_trades\"].append(int(va_pnl_best[\"n_trades\"]))\n",
    "        hist[\"va_sel\"].append(float(sel_val) if np.isfinite(sel_val) else np.nan)\n",
    "        hist[\"va_sel_mode\"].append(sel_mode)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "\n",
    "        # красивый best_str\n",
    "        if select_metric == \"va_pnl_max\":\n",
    "            if best_state_pnl is not None:\n",
    "                best_str = f\"pnl={best_score_pnl:.6f}@ep{best_epoch_pnl:02d}\"\n",
    "            else:\n",
    "                best_str = f\"auc={best_score_auc:.6f}@ep{best_epoch_auc:02d}\"\n",
    "        else:\n",
    "            best_str = f\"{best_score:.6f}@ep{best_epoch:02d}\" if best_epoch > 0 else \"none\"\n",
    "\n",
    "        if stage_name == \"dir\":\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"pnl_max={va_pnl_best['pnl_mean']:.6f} \"\n",
    "                f\"thr=({va_pnl_best['thr_trade']:.2f},{va_pnl_best['thr_dir']:.2f}) \"\n",
    "                f\"trades={va_pnl_best['n_trades']} \"\n",
    "                f\"sel({sel_mode})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"sel({select_metric})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "\n",
    "        if bad >= patience:\n",
    "            break\n",
    "\n",
    "    # ---- choose final best state\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if best_state_pnl is not None:\n",
    "            model.load_state_dict(best_state_pnl)\n",
    "            best_score = best_score_pnl\n",
    "            best_epoch = best_epoch_pnl\n",
    "            best_used = \"va_pnl_max\"\n",
    "        else:\n",
    "            model.load_state_dict(best_state_auc)\n",
    "            best_score = best_score_auc\n",
    "            best_epoch = best_epoch_auc\n",
    "            best_used = \"va_auc_fallback_only\"\n",
    "    else:\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "            best_used = select_metric\n",
    "\n",
    "    # финальные VAL/TEST по best_state\n",
    "    va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "        model, va_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(\n",
    "        model, te_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": float(best_score),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"select_metric\": select_metric,\n",
    "        \"best_used\": best_used,\n",
    "\n",
    "        \"val_loss\": va_loss,\n",
    "        \"val_acc\": va_acc,\n",
    "        \"val_f1m\": va_f1m,\n",
    "        \"val_auc\": va_auc,\n",
    "        \"val_cm\": va_cm,\n",
    "        \"val_y\": va_y,\n",
    "        \"val_prob\": va_prob,\n",
    "        \"val_er\": va_er,\n",
    "\n",
    "        \"test_loss\": te_loss,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_f1m\": te_f1m,\n",
    "        \"test_auc\": te_auc,\n",
    "        \"test_cm\": te_cm,\n",
    "        \"test_y\": te_y,\n",
    "        \"test_prob\": te_prob,\n",
    "        \"test_er\": te_er,\n",
    "\n",
    "        \"hist\": hist,\n",
    "    }\n",
    "    return model, res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: PnL по порогам уверенности (two-stage)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade,          # (N,2) softmax: [:,1]=p_trade\n",
    "    prob_dir,            # (N,2) softmax: [:,1]=p_up\n",
    "    exit_ret,            # (N,) realized log-ret to TB exit\n",
    "    thr_trade: float,\n",
    "    thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:,1]\n",
    "    p_up = prob_dir[:,1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (cost_bps * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(exit_ret),\n",
    "        \"n_trades\": int(trade_mask.sum()),\n",
    "        \"trade_rate\": float(trade_mask.mean()),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg):\n",
    "    rows = []\n",
    "    for thr_t in cfg[\"thr_trade_grid\"]:\n",
    "        for thr_d in cfg[\"thr_dir_grid\"]:\n",
    "            m = two_stage_pnl_by_threshold(\n",
    "                prob_trade=prob_trade,\n",
    "                prob_dir=prob_dir,\n",
    "                exit_ret=exit_ret,\n",
    "                thr_trade=thr_t,\n",
    "                thr_dir=thr_d,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "            )\n",
    "            rows.append({\"thr_trade\":thr_t, \"thr_dir\":thr_d, **m})\n",
    "    return pd.DataFrame(rows).sort_values([\"pnl_mean\",\"pnl_sum\"], ascending=False)\n",
    "\n",
    "print(\"Two-stage PnL threshold utils ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5c430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: shared helper for probs on arbitrary indices\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_on_indices(model, X_scaled, edge_feat, indices, cfg):\n",
    "    ds = LobGraphSequenceDataset2Stage(\n",
    "        X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, cfg[\"lookback\"]\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, yt, yd, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(probs), np.concatenate(ers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1168 233 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.9270 va_loss=0.6741 f1m=0.582 auc=0.619 sel(va_auc)=0.619270 best=0.619270@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.8142 va_loss=0.6591 f1m=0.380 auc=0.631 sel(va_auc)=0.631002 best=0.631002@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7785 va_loss=0.6602 f1m=0.380 auc=0.612 sel(va_auc)=0.612354 best=0.631002@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7595 va_loss=0.6638 f1m=0.380 auc=0.594 sel(va_auc)=0.593784 best=0.631002@ep02\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7323 va_loss=0.6643 f1m=0.380 auc=0.593 sel(va_auc)=0.592852 best=0.631002@ep02\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.7306 va_loss=0.6681 f1m=0.380 auc=0.601 sel(va_auc)=0.601166 best=0.631002@ep02\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.7062 va_loss=0.6689 f1m=0.380 auc=0.617 sel(va_auc)=0.616861 best=0.631002@ep02\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.7203 va_loss=0.6686 f1m=0.380 auc=0.619 sel(va_auc)=0.618803 best=0.631002@ep02\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6930 va_loss=0.6687 f1m=0.380 auc=0.628 sel(va_auc)=0.627972 best=0.631002@ep02\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.6972 va_loss=0.6707 f1m=0.380 auc=0.625 sel(va_auc)=0.624864 best=0.631002@ep02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dir] ep 01 lr=2.00e-04 tr_loss=1.0085 va_loss=0.7215 f1m=0.495 auc=0.473 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.472500 best=auc=0.472500@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8533 va_loss=0.7343 f1m=0.308 auc=0.485 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.485000 best=auc=0.485000@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.8765 va_loss=0.6996 f1m=0.505 auc=0.465 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.464500 best=auc=0.485000@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.9021 va_loss=0.6937 f1m=0.357 auc=0.451 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.450500 best=auc=0.485000@ep02\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.8120 va_loss=0.6923 f1m=0.357 auc=0.428 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.428500 best=auc=0.485000@ep02\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.8145 va_loss=0.6933 f1m=0.422 auc=0.429 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.429000 best=auc=0.485000@ep02\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.8568 va_loss=0.6989 f1m=0.578 auc=0.439 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.438500 best=auc=0.485000@ep02\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7946 va_loss=0.7020 f1m=0.589 auc=0.444 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.444000 best=auc=0.485000@ep02\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7881 va_loss=0.7051 f1m=0.573 auc=0.453 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.452500 best=auc=0.485000@ep02\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.8037 va_loss=0.7030 f1m=0.589 auc=0.457 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.456500 best=auc=0.485000@ep02\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0 | trades= 0.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1401 233 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8917 va_loss=0.5405 f1m=0.429 auc=0.809 sel(va_auc)=0.808670 best=0.808670@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.8212 va_loss=0.5483 f1m=0.429 auc=0.805 sel(va_auc)=0.805025 best=0.808670@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7415 va_loss=0.5460 f1m=0.429 auc=0.790 sel(va_auc)=0.790345 best=0.808670@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7307 va_loss=0.5640 f1m=0.429 auc=0.767 sel(va_auc)=0.766897 best=0.808670@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7328 va_loss=0.5595 f1m=0.429 auc=0.728 sel(va_auc)=0.727685 best=0.808670@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.7204 va_loss=0.5636 f1m=0.429 auc=0.722 sel(va_auc)=0.722365 best=0.808670@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.7154 va_loss=0.5631 f1m=0.429 auc=0.724 sel(va_auc)=0.723744 best=0.808670@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.7103 va_loss=0.5708 f1m=0.429 auc=0.726 sel(va_auc)=0.726207 best=0.808670@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.7119 va_loss=0.5733 f1m=0.429 auc=0.709 sel(va_auc)=0.709163 best=0.808670@ep01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9326 va_loss=0.8035 f1m=0.178 auc=0.531 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.530612 best=auc=0.530612@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8888 va_loss=0.7506 f1m=0.134 auc=0.426 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.426304 best=auc=0.530612@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.8456 va_loss=0.7022 f1m=0.313 auc=0.268 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.267574 best=auc=0.530612@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.8236 va_loss=0.6725 f1m=0.431 auc=0.268 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.267574 best=auc=0.530612@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.8110 va_loss=0.6801 f1m=0.431 auc=0.261 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.260771 best=auc=0.530612@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr_loss=0.7510 va_loss=0.6907 f1m=0.420 auc=0.224 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.224490 best=auc=0.530612@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.7619 va_loss=0.6886 f1m=0.431 auc=0.209 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.208617 best=auc=0.530612@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7462 va_loss=0.6678 f1m=0.458 auc=0.175 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.174603 best=auc=0.530612@ep01\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7419 va_loss=0.6608 f1m=0.458 auc=0.168 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.167800 best=auc=0.530612@ep01\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0 | trades= 0.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 1634 233 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8034 va_loss=0.8661 f1m=0.234 auc=0.594 sel(va_auc)=0.594331 best=0.594331@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7376 va_loss=0.7889 f1m=0.234 auc=0.525 sel(va_auc)=0.524778 best=0.594331@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7383 va_loss=0.7581 f1m=0.234 auc=0.301 sel(va_auc)=0.300556 best=0.594331@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7233 va_loss=0.8148 f1m=0.234 auc=0.286 sel(va_auc)=0.285516 best=0.594331@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7036 va_loss=0.7200 f1m=0.234 auc=0.310 sel(va_auc)=0.309511 best=0.594331@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.7002 va_loss=0.7643 f1m=0.234 auc=0.388 sel(va_auc)=0.387672 best=0.594331@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6864 va_loss=0.7722 f1m=0.234 auc=0.335 sel(va_auc)=0.335246 best=0.594331@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6905 va_loss=0.7626 f1m=0.234 auc=0.253 sel(va_auc)=0.252913 best=0.594331@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6872 va_loss=0.7598 f1m=0.234 auc=0.239 sel(va_auc)=0.239437 best=0.594331@ep01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9020 va_loss=0.6758 f1m=0.382 auc=0.298 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.297742 best=auc=0.297742@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8708 va_loss=0.6811 f1m=0.382 auc=0.346 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.345968 best=auc=0.345968@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.8125 va_loss=0.6838 f1m=0.382 auc=0.318 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.317581 best=auc=0.345968@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7599 va_loss=0.6739 f1m=0.382 auc=0.395 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.394839 best=auc=0.394839@ep04\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7933 va_loss=0.6735 f1m=0.382 auc=0.455 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.454839 best=auc=0.454839@ep05\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7745 va_loss=0.6724 f1m=0.382 auc=0.594 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.594194 best=auc=0.594194@ep06\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.7990 va_loss=0.6786 f1m=0.382 auc=0.620 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.620161 best=auc=0.620161@ep07\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.7831 va_loss=0.6859 f1m=0.464 auc=0.610 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.610323 best=auc=0.620161@ep07\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.7452 va_loss=0.6889 f1m=0.578 auc=0.610 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.610323 best=auc=0.620161@ep07\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.7535 va_loss=0.6876 f1m=0.492 auc=0.651 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.650645 best=auc=0.650645@ep10\n",
      "[dir] ep 11 lr=2.00e-04 tr_loss=0.7201 va_loss=0.6933 f1m=0.531 auc=0.595 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.595484 best=auc=0.650645@ep10\n",
      "[dir] ep 12 lr=2.00e-04 tr_loss=0.7393 va_loss=0.6905 f1m=0.506 auc=0.539 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.539032 best=auc=0.650645@ep10\n",
      "[dir] ep 13 lr=2.00e-04 tr_loss=0.7621 va_loss=0.6847 f1m=0.481 auc=0.561 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.560968 best=auc=0.650645@ep10\n",
      "[dir] ep 14 lr=2.00e-04 tr_loss=0.7650 va_loss=0.6899 f1m=0.518 auc=0.533 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.532742 best=auc=0.650645@ep10\n",
      "[dir] ep 15 lr=1.00e-04 tr_loss=0.6896 va_loss=0.6992 f1m=0.430 auc=0.494 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.493871 best=auc=0.650645@ep10\n",
      "[dir] ep 16 lr=1.00e-04 tr_loss=0.7194 va_loss=0.7015 f1m=0.395 auc=0.493 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.492742 best=auc=0.650645@ep10\n",
      "[dir] ep 17 lr=1.00e-04 tr_loss=0.6911 va_loss=0.7006 f1m=0.405 auc=0.508 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.507581 best=auc=0.650645@ep10\n",
      "[dir] ep 18 lr=1.00e-04 tr_loss=0.7216 va_loss=0.7012 f1m=0.390 auc=0.514 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.514355 best=auc=0.650645@ep10\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0 | trades= 0.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 1867 233 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.9118 va_loss=0.6448 f1m=0.463 auc=0.555 sel(va_auc)=0.554571 best=0.554571@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7966 va_loss=0.7624 f1m=0.121 auc=0.606 sel(va_auc)=0.605877 best=0.605877@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7559 va_loss=0.7248 f1m=0.198 auc=0.646 sel(va_auc)=0.645522 best=0.645522@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7381 va_loss=0.7317 f1m=0.183 auc=0.643 sel(va_auc)=0.643346 best=0.645522@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7134 va_loss=0.7052 f1m=0.345 auc=0.657 sel(va_auc)=0.657027 best=0.657027@ep05\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.7219 va_loss=0.6691 f1m=0.551 auc=0.685 sel(va_auc)=0.685323 best=0.685323@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6861 va_loss=0.6603 f1m=0.561 auc=0.694 sel(va_auc)=0.694030 best=0.694030@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6911 va_loss=0.5537 f1m=0.463 auc=0.700 sel(va_auc)=0.699938 best=0.699938@ep08\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6870 va_loss=0.4689 f1m=0.463 auc=0.698 sel(va_auc)=0.697917 best=0.699938@ep08\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6806 va_loss=0.5541 f1m=0.463 auc=0.697 sel(va_auc)=0.696828 best=0.699938@ep08\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.6804 va_loss=0.4513 f1m=0.463 auc=0.706 sel(va_auc)=0.705535 best=0.705535@ep11\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.6715 va_loss=0.4184 f1m=0.463 auc=0.702 sel(va_auc)=0.701959 best=0.705535@ep11\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.6699 va_loss=0.4711 f1m=0.463 auc=0.692 sel(va_auc)=0.691542 best=0.705535@ep11\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.6704 va_loss=0.4702 f1m=0.463 auc=0.683 sel(va_auc)=0.683147 best=0.705535@ep11\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.6709 va_loss=0.5169 f1m=0.463 auc=0.686 sel(va_auc)=0.686412 best=0.705535@ep11\n",
      "[trade] ep 16 lr=1.00e-04 tr_loss=0.6691 va_loss=0.4152 f1m=0.463 auc=0.688 sel(va_auc)=0.687811 best=0.705535@ep11\n",
      "[trade] ep 17 lr=1.00e-04 tr_loss=0.6616 va_loss=0.4773 f1m=0.463 auc=0.684 sel(va_auc)=0.684235 best=0.705535@ep11\n",
      "[trade] ep 18 lr=1.00e-04 tr_loss=0.6608 va_loss=0.5110 f1m=0.471 auc=0.666 sel(va_auc)=0.665578 best=0.705535@ep11\n",
      "[trade] ep 19 lr=1.00e-04 tr_loss=0.6560 va_loss=0.4538 f1m=0.463 auc=0.677 sel(va_auc)=0.676928 best=0.705535@ep11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9663 va_loss=0.6782 f1m=0.499 auc=0.612 pnl_max=0.001279 thr=(0.65,0.55) trades=110 sel(va_pnl_max)=0.001279 best=pnl=0.001279@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8241 va_loss=0.6949 f1m=0.345 auc=0.610 pnl_max=0.000922 thr=(0.50,0.60) trades=128 sel(va_pnl_max)=0.000922 best=pnl=0.001279@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.8032 va_loss=0.6998 f1m=0.345 auc=0.594 pnl_max=0.000795 thr=(0.50,0.60) trades=134 sel(va_pnl_max)=0.000795 best=pnl=0.001279@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7900 va_loss=0.6907 f1m=0.405 auc=0.589 pnl_max=0.000785 thr=(0.65,0.55) trades=78 sel(va_pnl_max)=0.000785 best=pnl=0.001279@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7904 va_loss=0.7096 f1m=0.329 auc=0.579 pnl_max=-0.000170 thr=(0.50,0.60) trades=26 sel(va_pnl_max)=-0.000170 best=pnl=0.001279@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr_loss=0.7657 va_loss=0.7030 f1m=0.321 auc=0.622 pnl_max=-0.000002 thr=(0.65,0.55) trades=165 sel(va_pnl_max)=-0.000002 best=pnl=0.001279@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.7827 va_loss=0.6887 f1m=0.473 auc=0.636 pnl_max=0.000803 thr=(0.65,0.50) trades=205 sel(va_pnl_max)=0.000803 best=pnl=0.001279@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7453 va_loss=0.6835 f1m=0.621 auc=0.682 pnl_max=0.001845 thr=(0.65,0.50) trades=205 sel(va_pnl_max)=0.001845 best=pnl=0.001845@ep08\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7532 va_loss=0.6867 f1m=0.500 auc=0.673 pnl_max=0.001120 thr=(0.65,0.50) trades=205 sel(va_pnl_max)=0.001120 best=pnl=0.001845@ep08\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.7528 va_loss=0.6829 f1m=0.646 auc=0.679 pnl_max=0.002081 thr=(0.65,0.50) trades=205 sel(va_pnl_max)=0.002081 best=pnl=0.002081@ep10\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.7394 va_loss=0.6843 f1m=0.525 auc=0.679 pnl_max=0.001216 thr=(0.65,0.50) trades=205 sel(va_pnl_max)=0.001216 best=pnl=0.002081@ep10\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.7510 va_loss=0.6836 f1m=0.596 auc=0.669 pnl_max=0.001402 thr=(0.65,0.50) trades=205 sel(va_pnl_max)=0.001402 best=pnl=0.002081@ep10\n",
      "[dir] ep 13 lr=1.00e-04 tr_loss=0.7711 va_loss=0.6846 f1m=0.617 auc=0.650 pnl_max=0.001557 thr=(0.50,0.50) trades=233 sel(va_pnl_max)=0.001557 best=pnl=0.002081@ep10\n",
      "[dir] ep 14 lr=1.00e-04 tr_loss=0.7515 va_loss=0.6968 f1m=0.321 auc=0.638 pnl_max=0.000508 thr=(0.50,0.55) trades=110 sel(va_pnl_max)=0.000508 best=pnl=0.002081@ep10\n",
      "[dir] ep 15 lr=5.00e-05 tr_loss=0.7295 va_loss=0.7003 f1m=0.321 auc=0.624 pnl_max=0.000099 thr=(0.50,0.55) trades=141 sel(va_pnl_max)=0.000099 best=pnl=0.002081@ep10\n",
      "[dir] ep 16 lr=5.00e-05 tr_loss=0.7325 va_loss=0.7009 f1m=0.321 auc=0.609 pnl_max=0.000006 thr=(0.65,0.55) trades=144 sel(va_pnl_max)=0.000006 best=pnl=0.002081@ep10\n",
      "[dir] ep 17 lr=5.00e-05 tr_loss=0.7351 va_loss=0.6997 f1m=0.321 auc=0.604 pnl_max=0.000151 thr=(0.50,0.55) trades=137 sel(va_pnl_max)=0.000151 best=pnl=0.002081@ep10\n",
      "[dir] ep 18 lr=5.00e-05 tr_loss=0.7035 va_loss=0.6979 f1m=0.321 auc=0.602 pnl_max=0.000890 thr=(0.50,0.55) trades=100 sel(va_pnl_max)=0.000890 best=pnl=0.002081@ep10\n",
      "PnL on fold-test: | thr_trade= 0.65 | thr_dir= 0.5 | pnl_mean= 0.0003767073794733733 | trades= 26.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.428922</td>\n",
       "      <td>0.344048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.233553</td>\n",
       "      <td>0.446432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.120755</td>\n",
       "      <td>0.356822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.488186</td>\n",
       "      <td>0.506770</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.111588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.428922      0.344048       0.000000            0.50   \n",
       "1     2        0.233553      0.446432       0.000000            0.50   \n",
       "2     3        0.120755      0.356822       0.000000            0.50   \n",
       "3     4        0.488186      0.506770       0.000377            0.65   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0           0.5            0.0         0.000000  \n",
       "1           0.5            0.0         0.000000  \n",
       "2           0.5            0.0         0.000000  \n",
       "3           0.5           26.0         0.111588  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN (fold-test внутри CV-part):\n",
      "fold               2.500000\n",
      "trade_test_f1m     0.317854\n",
      "dir_test_f1m       0.413518\n",
      "best_pnl_mean      0.000094\n",
      "best_thr_trade     0.537500\n",
      "best_thr_dir       0.500000\n",
      "n_trades_best      6.500000\n",
      "trade_rate_best    0.027897\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training (ONLY on CV-part)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold (fit only on train times)\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples (по AUC)\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\",\n",
    "        select_metric=\"va_auc\",\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples (train/val/test индексы фильтруем)\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "            \"trade_rate_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # dir: учим на trade-only, но PnL-proxy считаем на полном idx_va (full val)\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\",\n",
    "        select_metric=\"va_pnl_max\",\n",
    "        trade_model_for_pnl=m_trade,\n",
    "        idx_val_pnl=idx_va,   # <-- полный val для pnl-proxy\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on fold TEST\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te, CFG)\n",
    "    prob_dir_te, _       = predict_probs_on_indices(m_dir,   X_scaled, edge_feat, idx_te, CFG)\n",
    "\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on fold-test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN (fold-test внутри CV-part):\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": [
    "## 11. Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50d16463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL TRAIN/TEST (CV=90% | FINAL=10%)\n",
      "Final split sizes:\n",
      "  train_final: 2104\n",
      "  val_final  : 233\n",
      "  FINAL test : 260\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : -0.0011621993035078049\n",
      "  pnl_sum  : -0.30217182636260986\n",
      "  n_trades : 168\n",
      "  trade_rate: 0.6461538461538462\n",
      "  sharpe (per-bar proxy): -2.972517084561294\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.5 thr_dir: 0.6\n",
      "  pnl_mean : 0.0 trades: 0.0\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Final train on CV(90%) and evaluate once on FINAL(10%)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAIN/TEST (CV=90% | FINAL=10%)\")\n",
    "\n",
    "# 1) final train/val split внутри CV-part (по времени)\n",
    "val_w_final = max(1, int(CFG[\"val_window_frac\"] * n_samples_cv))\n",
    "train_end = n_samples_cv - val_w_final\n",
    "\n",
    "idx_train_final = np.arange(0, train_end, dtype=np.int64)\n",
    "idx_val_final   = np.arange(train_end, n_samples_cv, dtype=np.int64)\n",
    "idx_test_final  = idx_final_test.astype(np.int64)  # финальный holdout\n",
    "\n",
    "print(\"Final split sizes:\")\n",
    "print(\"  train_final:\", len(idx_train_final))\n",
    "print(\"  val_final  :\", len(idx_val_final))\n",
    "print(\"  FINAL test :\", len(idx_test_final))\n",
    "\n",
    "# 2) scaling (fit only on train_final)\n",
    "X_scaled_final, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train_final, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=summary['best_thr_trade'][3],\n",
    "    thr_dir=summary['best_thr_dir'][3],\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c4946a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8149 va_loss=0.6645 f1m=0.467 auc=0.557 sel(va_auc)=0.556643 best=0.556643@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7353 va_loss=0.6609 f1m=0.380 auc=0.564 sel(va_auc)=0.563947 best=0.563947@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7083 va_loss=0.6686 f1m=0.473 auc=0.542 sel(va_auc)=0.541880 best=0.563947@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6835 va_loss=0.6794 f1m=0.561 auc=0.538 sel(va_auc)=0.538306 best=0.563947@ep02\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6729 va_loss=0.7333 f1m=0.498 auc=0.541 sel(va_auc)=0.540793 best=0.563947@ep02\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6558 va_loss=0.6957 f1m=0.558 auc=0.543 sel(va_auc)=0.543434 best=0.563947@ep02\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6491 va_loss=0.7600 f1m=0.529 auc=0.557 sel(va_auc)=0.557265 best=0.563947@ep02\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6396 va_loss=0.7102 f1m=0.574 auc=0.564 sel(va_auc)=0.564258 best=0.564258@ep08\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6479 va_loss=0.7289 f1m=0.556 auc=0.567 sel(va_auc)=0.566822 best=0.566822@ep09\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.6446 va_loss=0.7145 f1m=0.562 auc=0.567 sel(va_auc)=0.567211 best=0.567211@ep10\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.6451 va_loss=0.7041 f1m=0.546 auc=0.570 sel(va_auc)=0.570241 best=0.570241@ep11\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.6366 va_loss=0.7093 f1m=0.565 auc=0.573 sel(va_auc)=0.573193 best=0.573193@ep12\n",
      "[trade] ep 13 lr=1.00e-04 tr_loss=0.6371 va_loss=0.7523 f1m=0.519 auc=0.570 sel(va_auc)=0.570319 best=0.573193@ep12\n",
      "[trade] ep 14 lr=1.00e-04 tr_loss=0.6398 va_loss=0.6986 f1m=0.539 auc=0.577 sel(va_auc)=0.576923 best=0.576923@ep14\n",
      "[trade] ep 15 lr=1.00e-04 tr_loss=0.6308 va_loss=0.7038 f1m=0.565 auc=0.575 sel(va_auc)=0.575291 best=0.576923@ep14\n",
      "[trade] ep 16 lr=1.00e-04 tr_loss=0.6412 va_loss=0.7102 f1m=0.566 auc=0.576 sel(va_auc)=0.576146 best=0.576923@ep14\n",
      "[trade] ep 17 lr=1.00e-04 tr_loss=0.6309 va_loss=0.7256 f1m=0.557 auc=0.576 sel(va_auc)=0.575758 best=0.576923@ep14\n",
      "[trade] ep 18 lr=1.00e-04 tr_loss=0.6279 va_loss=0.6985 f1m=0.536 auc=0.576 sel(va_auc)=0.576146 best=0.576923@ep14\n",
      "[trade] ep 19 lr=5.00e-05 tr_loss=0.6285 va_loss=0.7224 f1m=0.557 auc=0.576 sel(va_auc)=0.576146 best=0.576923@ep14\n",
      "[trade] ep 20 lr=5.00e-05 tr_loss=0.6340 va_loss=0.7372 f1m=0.540 auc=0.576 sel(va_auc)=0.575602 best=0.576923@ep14\n",
      "[trade] ep 21 lr=5.00e-05 tr_loss=0.6312 va_loss=0.7835 f1m=0.484 auc=0.576 sel(va_auc)=0.575913 best=0.576923@ep14\n",
      "[trade] ep 22 lr=5.00e-05 tr_loss=0.6326 va_loss=0.7243 f1m=0.552 auc=0.576 sel(va_auc)=0.575602 best=0.576923@ep14\n",
      "Trade-only sizes for DIR:\n",
      "  train_final_T: 963\n",
      "  val_final_T  : 143\n",
      "  test_final_T : 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9104 va_loss=0.6827 f1m=0.344 auc=0.700 pnl_max=-0.000011 thr=(0.70,0.55) trades=25 sel(va_pnl_max)=-0.000011 best=pnl=-0.000011@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8443 va_loss=0.6966 f1m=0.350 auc=0.492 pnl_max=0.000988 thr=(0.65,0.55) trades=61 sel(va_pnl_max)=0.000988 best=pnl=0.000988@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7795 va_loss=0.6902 f1m=0.467 auc=0.513 pnl_max=0.001205 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.001205 best=pnl=0.001205@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7545 va_loss=0.6878 f1m=0.536 auc=0.532 pnl_max=0.000883 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.000883 best=pnl=0.001205@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7543 va_loss=0.6904 f1m=0.350 auc=0.520 pnl_max=0.000885 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.000885 best=pnl=0.001205@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7385 va_loss=0.6924 f1m=0.350 auc=0.531 pnl_max=0.001262 thr=(0.65,0.55) trades=85 sel(va_pnl_max)=0.001262 best=pnl=0.001262@ep06\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.7404 va_loss=0.6888 f1m=0.350 auc=0.539 pnl_max=0.001168 thr=(0.65,0.55) trades=70 sel(va_pnl_max)=0.001168 best=pnl=0.001262@ep06\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.7427 va_loss=0.6873 f1m=0.350 auc=0.552 pnl_max=0.000885 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.000885 best=pnl=0.001262@ep06\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.7241 va_loss=0.6884 f1m=0.350 auc=0.555 pnl_max=0.000885 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.000885 best=pnl=0.001262@ep06\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.7293 va_loss=0.6884 f1m=0.350 auc=0.551 pnl_max=0.000885 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.000885 best=pnl=0.001262@ep06\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.7157 va_loss=0.6886 f1m=0.350 auc=0.560 pnl_max=0.000885 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.000885 best=pnl=0.001262@ep06\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.7186 va_loss=0.6890 f1m=0.350 auc=0.560 pnl_max=0.000958 thr=(0.65,0.55) trades=49 sel(va_pnl_max)=0.000958 best=pnl=0.001262@ep06\n",
      "[dir] ep 13 lr=1.00e-04 tr_loss=0.7157 va_loss=0.6885 f1m=0.350 auc=0.567 pnl_max=0.000885 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.000885 best=pnl=0.001262@ep06\n",
      "[dir] ep 14 lr=1.00e-04 tr_loss=0.7071 va_loss=0.6883 f1m=0.350 auc=0.561 pnl_max=0.000885 thr=(0.65,0.50) trades=97 sel(va_pnl_max)=0.000885 best=pnl=0.001262@ep06\n",
      "\n",
      "Chosen thresholds on val_final:\n",
      "  thr_trade*: 0.65\n",
      "  thr_dir*  : 0.55\n",
      "  val pnl_mean: 0.0012617239262908697 | val trades: 85\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : -0.001126012415625155\n",
      "  pnl_sum  : -0.29276323318481445\n",
      "  n_trades : 183\n",
      "  trade_rate: 0.7038461538461539\n",
      "  sharpe (per-bar proxy): -2.781963090248628\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.5 thr_dir: 0.6\n",
      "  pnl_mean : 3.3629174140514806e-05 trades: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3) train TRADE on train_final, select by AUC on val_final\n",
    "m_trade_final, r_trade_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final, idx_val_final, idx_test_final,\n",
    "    CFG,\n",
    "    stage_name=\"trade\",\n",
    "    select_metric=\"va_auc\",\n",
    ")\n",
    "\n",
    "# 4) train DIR on trade-only samples (train/val/test filtered),\n",
    "#    but pnl-proxy computed on full val_final; selector hard-fallback already inside\n",
    "idx_train_final_T = subset_trade_indices(idx_train_final, sample_t, y_trade)\n",
    "idx_val_final_T   = subset_trade_indices(idx_val_final,   sample_t, y_trade)\n",
    "idx_test_final_T  = subset_trade_indices(idx_test_final,  sample_t, y_trade)\n",
    "\n",
    "print(\"Trade-only sizes for DIR:\")\n",
    "print(\"  train_final_T:\", len(idx_train_final_T))\n",
    "print(\"  val_final_T  :\", len(idx_val_final_T))\n",
    "print(\"  test_final_T :\", len(idx_test_final_T))\n",
    "\n",
    "m_dir_final, r_dir_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final_T, idx_val_final_T, idx_test_final_T,\n",
    "    CFG,\n",
    "    stage_name=\"dir\",\n",
    "    select_metric=\"va_pnl_max\",\n",
    "    trade_model_for_pnl=m_trade_final,\n",
    "    idx_val_pnl=idx_val_final,   # pnl-proxy на полном val_final\n",
    ")\n",
    "\n",
    "# 5) выбрать пороги по val_final (grid sweep)\n",
    "prob_trade_val, er_val = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "prob_dir_val, _        = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "\n",
    "sweep_val = sweep_thresholds(prob_trade_val, prob_dir_val, er_val, CFG)\n",
    "best_val = sweep_val.iloc[0].to_dict()\n",
    "thr_trade_star = float(best_val[\"thr_trade\"])\n",
    "thr_dir_star   = float(best_val[\"thr_dir\"])\n",
    "\n",
    "print(\"\\nChosen thresholds on val_final:\")\n",
    "print(\"  thr_trade*:\", thr_trade_star)\n",
    "print(\"  thr_dir*  :\", thr_dir_star)\n",
    "print(\"  val pnl_mean:\", float(best_val[\"pnl_mean\"]), \"| val trades:\", int(best_val[\"n_trades\"]))\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=thr_trade_star,\n",
    "    thr_dir=thr_dir_star,\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
