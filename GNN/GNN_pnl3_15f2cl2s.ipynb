{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),  \n",
    "    # NEW: holdout final test split (по времени, на sample-space)\n",
    "    \"final_test_frac\": 0.10, \n",
    "\n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 84],  # 30m,1h,2h,4h,7h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 1*12,       # 1h     # нужен для sample_t (чтобы TB-exit не вылезал за конец)\n",
    "    \"lookback\": 7*12,   \n",
    "    \"tb_pt_mult\": 1.2,\n",
    "    \"tb_sl_mult\": 1.1,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "    # training (общие)\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.2,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "\n",
    "    # ---- PnL proxy during DIR training (grid selector)\n",
    "    # можно сделать уже/шире, но по умолчанию переиспользуем thr_*_grid\n",
    "    \"proxy_thr_trade_grid\": None,  # None -> использовать thr_trade_grid\n",
    "    \"proxy_thr_dir_grid\":   None,  # None -> использовать thr_dir_grid\n",
    "    \"proxy_min_trades\": 50,        # защита от \"лучший pnl = 0 потому что 0 трейдов\"\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "print(\"EDGE_INDEX:\", EDGE_INDEX.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (2693, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int, part = [0,100]) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.iloc[int(len(df)*part[0]/100) : int(len(df)*part[1]/100)]\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels, part = [0, 80]), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels, part = [0, 80]), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels, part = [0, 80]), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (2693, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [ 655 1311  727]\n",
      "Trade ratio: 0.5131823245451169\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=1*12, \n",
    "    vol_window=7*12,\n",
    "    pt_mult=1.2,\n",
    "    sl_mult=1.1,\n",
    "    min_barrier=0.001,\n",
    "    max_barrier=0.006,\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (2693, 3, 15) edge_feat: (2693, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 2597 t range: 83 2679\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb5de4",
   "metadata": {},
   "source": [
    "## Train (folds) - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9bad799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout split:\n",
      "  n_samples total: 2597\n",
      "  n_samples CV   : 2337 (90.0%)\n",
      "  n_samples FINAL: 260 (10.0%)\n",
      "  CV range   : 0 2336\n",
      "  FINAL range: 2337 2596\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: final holdout split (90% CV + 10% final test), time-ordered\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_final_holdout_split(n_samples: int, final_test_frac: float):\n",
    "    if not (0.0 < final_test_frac < 0.5):\n",
    "        raise ValueError(\"final_test_frac should be in (0, 0.5)\")\n",
    "\n",
    "    n_final = max(1, int(round(final_test_frac * n_samples)))\n",
    "    n_cv = n_samples - n_final\n",
    "    if n_cv <= 10:\n",
    "        raise ValueError(\"Too few samples left for CV after holdout split.\")\n",
    "\n",
    "    idx_cv = np.arange(0, n_cv, dtype=np.int64)\n",
    "    idx_final = np.arange(n_cv, n_samples, dtype=np.int64)\n",
    "    return idx_cv, idx_final, n_cv, n_final\n",
    "\n",
    "idx_cv_all, idx_final_test, n_samples_cv, n_samples_final = make_final_holdout_split(\n",
    "    n_samples=n_samples,\n",
    "    final_test_frac=CFG[\"final_test_frac\"],\n",
    ")\n",
    "\n",
    "print(\"Holdout split:\")\n",
    "print(\"  n_samples total:\", n_samples)\n",
    "print(\"  n_samples CV   :\", n_samples_cv, f\"({100*(n_samples_cv/n_samples):.1f}%)\")\n",
    "print(\"  n_samples FINAL:\", n_samples_final, f\"({100*(n_samples_final/n_samples):.1f}%)\")\n",
    "print(\"  CV range   :\", idx_cv_all[0], idx_cv_all[-1])\n",
    "print(\"  FINAL range:\", idx_final_test[0], idx_final_test[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1168 | val 233 | test 233\n",
      " fold 2: train 1401 | val 233 | test 233\n",
      " fold 3: train 1634 | val 233 | test 233\n",
      " fold 4: train 1867 | val 233 | test 233\n",
      "\n",
      "FINAL HOLDOUT:\n",
      " final_test size: 260\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test) on CV-part only\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "\n",
    "        idx_train = np.arange(0, tr_end, dtype=np.int64)\n",
    "        idx_val   = np.arange(tr_end, va_end, dtype=np.int64)\n",
    "        idx_test  = np.arange(va_end, te_end, dtype=np.int64)\n",
    "\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "\n",
    "    return splits\n",
    "\n",
    "# IMPORTANT: строим сплиты только на 90% (CV-part)\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples_cv,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "for i, (a, b, c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT:\")\n",
    "print(\" final_test size:\", len(idx_final_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: GNN + LSTM classifier (универсальный под 2 класса)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class EdgeGatedMP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_proj = nn.Linear(in_dim, hidden)\n",
    "        self.ln0 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden + edge_dim, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden + 1)  # msg(hidden) + gate(1)\n",
    "        )\n",
    "\n",
    "        self.upd = nn.Sequential(\n",
    "            nn.Linear(2*hidden, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward_once(self, x_t, edge_attr_t, edge_index):\n",
    "        B, N, _ = x_t.shape\n",
    "        E = edge_index.shape[0]\n",
    "\n",
    "        h = self.ln0(self.node_proj(x_t))  # (B,N,H)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        agg = torch.zeros((B, N, h.shape[-1]), device=h.device, dtype=h.dtype)\n",
    "\n",
    "        for e in range(E):\n",
    "            src = edge_index[e, 0].item()\n",
    "            dst = edge_index[e, 1].item()\n",
    "            h_src = h[:, src, :]\n",
    "            h_dst = h[:, dst, :]\n",
    "            ea = edge_attr_t[:, e, :]\n",
    "\n",
    "            z = torch.cat([h_src, h_dst, ea], dim=-1)\n",
    "            out = self.edge_mlp(z)\n",
    "            msg = out[:, :-1]\n",
    "            gate = torch.sigmoid(out[:, -1:])\n",
    "\n",
    "            agg[:, dst, :] += msg * gate\n",
    "\n",
    "        h2 = self.upd(torch.cat([h, agg], dim=-1))\n",
    "        h2 = self.ln1(h + self.dropout(h2))\n",
    "        h2 = torch.nan_to_num(h2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return h2\n",
    "\n",
    "    def forward(self, x_seq, e_seq, edge_index):\n",
    "        B, L, N, Fin = x_seq.shape\n",
    "        h_out = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            h_out.append(ht)\n",
    "        return torch.stack(h_out, dim=1)  # (B,L,N,H)\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = target_node\n",
    "\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(gnn_layers):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(EdgeGatedMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, dropout=dropout))\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(lstm_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, lstm_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, n_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        out, _ = self.lstm(h_tgt)\n",
    "        last = out[:, -1, :]\n",
    "        logits = self.head(last)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"Model ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn, y_key: str = \"trade\"):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        y = (y_trade_b if y_key == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "\n",
    "    ys = np.concatenate(ys) if len(ys) else np.array([], dtype=np.int64)\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, None, ys, probs, ers\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:, 1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss / max(n, 1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_only(model, loader):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "    return probs, ers\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps, min_trades: int = 0):\n",
    "    \"\"\"\n",
    "    Возвращает лучший pnl_mean по grid (per-bar), плюс пороги и статистику.\n",
    "    min_trades используется как фильтр: комбинации, где сделок меньше, пропускаются.\n",
    "    Если ни одна комбинация не прошла min_trades — вернём best без фильтра (но это будет fallback-сценарий).\n",
    "    \"\"\"\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    sign = np.where(p_up >= 0.5, 1.0, -1.0).astype(np.float32)\n",
    "    cost = float(cost_bps) * 1e-4\n",
    "    N = len(exit_ret)\n",
    "\n",
    "    best = {\n",
    "        \"pnl_mean\": -1e18,\n",
    "        \"pnl_sum\": -1e18,\n",
    "        \"thr_trade\": None,\n",
    "        \"thr_dir\": None,\n",
    "        \"n_trades\": 0,\n",
    "        \"trade_rate\": 0.0,\n",
    "        \"min_trades_used\": int(min_trades),\n",
    "        \"passed_min_trades\": False,\n",
    "    }\n",
    "\n",
    "    # 1) строгий проход (>=min_trades)\n",
    "    for thr_t in thr_trade_grid:\n",
    "        mt = (p_trade >= thr_t)\n",
    "        for thr_d in thr_dir_grid:\n",
    "            mask = mt & (conf_dir >= thr_d)\n",
    "            n_tr = int(mask.sum())\n",
    "            if n_tr < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "            pnl_sum = float(pnl.sum())\n",
    "            pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "            if pnl_mean > best[\"pnl_mean\"]:\n",
    "                best.update({\n",
    "                    \"pnl_mean\": pnl_mean,\n",
    "                    \"pnl_sum\": pnl_sum,\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": n_tr,\n",
    "                    \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                    \"passed_min_trades\": True,\n",
    "                })\n",
    "\n",
    "    # 2) если ничего не прошло min_trades — найдём best без фильтра (для fallback-логов)\n",
    "    if best[\"thr_trade\"] is None:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            mt = (p_trade >= thr_t)\n",
    "            for thr_d in thr_dir_grid:\n",
    "                mask = mt & (conf_dir >= thr_d)\n",
    "                n_tr = int(mask.sum())\n",
    "                pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "                pnl_sum = float(pnl.sum())\n",
    "                pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "                if pnl_mean > best[\"pnl_mean\"]:\n",
    "                    best.update({\n",
    "                        \"pnl_mean\": pnl_mean,\n",
    "                        \"pnl_sum\": pnl_sum,\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": n_tr,\n",
    "                        \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "    select_metric: str | None = None,        # \"va_auc\" | \"va_f1m\" | \"va_pnl_max\"\n",
    "    trade_model_for_pnl=None,                # для stage=\"dir\": фиксированная trade-модель\n",
    "    idx_val_pnl=None,                        # индексы (sample-space) для pnl-proxy, обычно полный idx_val\n",
    "):\n",
    "    \"\"\"\n",
    "    Градиентами оптимизируем: CrossEntropyLoss.\n",
    "    Селектор best checkpoint:\n",
    "      - trade: обычно va_auc\n",
    "      - dir:   va_pnl_max, но если best trades < proxy_min_trades => fallback на va_auc\n",
    "              (реализовано как: best_pnl если были эпохи с trades>=min, иначе best_auc)\n",
    "    \"\"\"\n",
    "    if select_metric is None:\n",
    "        select_metric = \"va_auc\"\n",
    "    if select_metric not in (\"va_auc\", \"va_f1m\", \"va_pnl_max\"):\n",
    "        raise ValueError(\"select_metric must be one of: 'va_auc', 'va_f1m', 'va_pnl_max'\")\n",
    "\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if stage_name != \"dir\":\n",
    "            raise ValueError(\"select_metric='va_pnl_max' supported only for stage_name='dir'\")\n",
    "        if trade_model_for_pnl is None or idx_val_pnl is None:\n",
    "            raise ValueError(\"For va_pnl_max you must pass trade_model_for_pnl and idx_val_pnl (full val indices).\")\n",
    "\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val,   L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test,  L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True,  drop_last=True, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    va_pnl_loader = None\n",
    "    if stage_name == \"dir\" and (idx_val_pnl is not None):\n",
    "        va_pnl_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val_pnl, L)\n",
    "        va_pnl_loader = DataLoader(va_pnl_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\"))\n",
    "\n",
    "    # --- trade-prob на полном val для PnL proxy (считаем 1 раз)\n",
    "    prob_trade_val_pnl = None\n",
    "    if stage_name == \"dir\" and (trade_model_for_pnl is not None) and (va_pnl_loader is not None):\n",
    "        prob_trade_val_pnl, _ = predict_probs_only(trade_model_for_pnl, va_pnl_loader)\n",
    "\n",
    "    thr_trade_grid_proxy = cfg.get(\"proxy_thr_trade_grid\") or cfg.get(\"thr_trade_grid\", [0.5])\n",
    "    thr_dir_grid_proxy   = cfg.get(\"proxy_thr_dir_grid\")   or cfg.get(\"thr_dir_grid\",   [0.5])\n",
    "    proxy_min_trades = int(cfg.get(\"proxy_min_trades\", 0))\n",
    "\n",
    "    # --- best trackers\n",
    "    best_score = -1e18\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "    best_used = select_metric\n",
    "\n",
    "    # специальные трекеры для va_pnl_max с fallback\n",
    "    best_score_auc = -1e18\n",
    "    best_state_auc = None\n",
    "    best_epoch_auc = -1\n",
    "\n",
    "    best_score_pnl = -1e18\n",
    "    best_state_pnl = None\n",
    "    best_epoch_pnl = -1\n",
    "\n",
    "    seen_pnl_ok = False\n",
    "\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\n",
    "        \"tr_loss\": [], \"va_loss\": [],\n",
    "        \"va_f1m\": [], \"va_auc\": [],\n",
    "        \"va_pnl_max\": [],\n",
    "        \"va_pnl_thr_trade\": [],\n",
    "        \"va_pnl_thr_dir\": [],\n",
    "        \"va_pnl_n_trades\": [],\n",
    "        \"va_sel\": [],\n",
    "        \"va_sel_mode\": []\n",
    "    }\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"] + 1):\n",
    "        # ---- TRAIN\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for x, e, y_trade_b, y_dir_b, er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            y = (y_trade_b if stage_name == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot / max(n, 1)\n",
    "\n",
    "        # ---- VAL classification metrics\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, va_loader, loss_fn, y_key=stage_name\n",
    "        )\n",
    "\n",
    "        # ---- VAL PnL proxy (dir only)\n",
    "        va_pnl_best = {\"pnl_mean\": np.nan, \"thr_trade\": np.nan, \"thr_dir\": np.nan, \"n_trades\": 0, \"trade_rate\": np.nan,\n",
    "                       \"passed_min_trades\": False, \"min_trades_used\": proxy_min_trades}\n",
    "\n",
    "        if stage_name == \"dir\" and (prob_trade_val_pnl is not None) and (va_pnl_loader is not None):\n",
    "            prob_dir_val_pnl, er_dir_val_pnl = predict_probs_only(model, va_pnl_loader)\n",
    "\n",
    "            va_pnl_best = pnl_proxy_grid_max(\n",
    "                prob_trade=prob_trade_val_pnl,\n",
    "                prob_dir=prob_dir_val_pnl,\n",
    "                exit_ret=er_dir_val_pnl,\n",
    "                thr_trade_grid=thr_trade_grid_proxy,\n",
    "                thr_dir_grid=thr_dir_grid_proxy,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "                min_trades=proxy_min_trades,\n",
    "            )\n",
    "\n",
    "        # ---- selection\n",
    "        sel_val = np.nan\n",
    "        sel_mode = select_metric\n",
    "\n",
    "        if select_metric in (\"va_auc\", \"va_f1m\"):\n",
    "            sel_val = (va_auc if select_metric == \"va_auc\" else va_f1m)\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "\n",
    "            # единый best\n",
    "            prev_best = best_score\n",
    "            if sel_val > best_score:\n",
    "                best_score = sel_val\n",
    "                best_epoch = ep\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "        else:\n",
    "            # select_metric == \"va_pnl_max\" (dir only) with hard fallback\n",
    "            pnl_mean = float(va_pnl_best[\"pnl_mean\"])\n",
    "            n_tr = int(va_pnl_best[\"n_trades\"])\n",
    "            pnl_ok = (np.isfinite(pnl_mean) and (n_tr >= proxy_min_trades))\n",
    "\n",
    "            # обновим best_auc (fallback) всегда\n",
    "            if np.isfinite(va_auc) and (va_auc > best_score_auc):\n",
    "                best_score_auc = float(va_auc)\n",
    "                best_epoch_auc = ep\n",
    "                best_state_auc = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            # обновим best_pnl только если pnl_ok\n",
    "            if pnl_ok and (pnl_mean > best_score_pnl):\n",
    "                best_score_pnl = pnl_mean\n",
    "                best_epoch_pnl = ep\n",
    "                best_state_pnl = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            if pnl_ok:\n",
    "                seen_pnl_ok = True\n",
    "                sel_val = pnl_mean\n",
    "                sel_mode = \"va_pnl_max\"\n",
    "            else:\n",
    "                sel_val = float(va_auc) if np.isfinite(va_auc) else -1e18\n",
    "                sel_mode = f\"va_auc_fallback({n_tr}/{proxy_min_trades})\"\n",
    "\n",
    "            # scheduler всегда по текущему sel_val\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "            # early stop: до первой валидной pnl-эпохи -> по AUC, после -> по PnL\n",
    "            improved = False\n",
    "            if not seen_pnl_ok:\n",
    "                # следим за ростом AUC\n",
    "                improved = (np.isfinite(va_auc) and (float(va_auc) >= best_score_auc))\n",
    "            else:\n",
    "                # следим за ростом PnL (только когда pnl_ok)\n",
    "                improved = pnl_ok and (pnl_mean >= best_score_pnl)\n",
    "\n",
    "            if improved:\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "        # если не pnl-метрика — scheduler тут\n",
    "        if select_metric != \"va_pnl_max\":\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "        # ---- logging + hist\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "\n",
    "        hist[\"va_pnl_max\"].append(float(va_pnl_best[\"pnl_mean\"]) if np.isfinite(va_pnl_best[\"pnl_mean\"]) else np.nan)\n",
    "        hist[\"va_pnl_thr_trade\"].append(float(va_pnl_best[\"thr_trade\"]) if va_pnl_best[\"thr_trade\"] is not None else np.nan)\n",
    "        hist[\"va_pnl_thr_dir\"].append(float(va_pnl_best[\"thr_dir\"]) if va_pnl_best[\"thr_dir\"] is not None else np.nan)\n",
    "        hist[\"va_pnl_n_trades\"].append(int(va_pnl_best[\"n_trades\"]))\n",
    "        hist[\"va_sel\"].append(float(sel_val) if np.isfinite(sel_val) else np.nan)\n",
    "        hist[\"va_sel_mode\"].append(sel_mode)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "\n",
    "        # красивый best_str\n",
    "        if select_metric == \"va_pnl_max\":\n",
    "            if best_state_pnl is not None:\n",
    "                best_str = f\"pnl={best_score_pnl:.6f}@ep{best_epoch_pnl:02d}\"\n",
    "            else:\n",
    "                best_str = f\"auc={best_score_auc:.6f}@ep{best_epoch_auc:02d}\"\n",
    "        else:\n",
    "            best_str = f\"{best_score:.6f}@ep{best_epoch:02d}\" if best_epoch > 0 else \"none\"\n",
    "\n",
    "        if stage_name == \"dir\":\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"pnl_max={va_pnl_best['pnl_mean']:.6f} \"\n",
    "                f\"thr=({va_pnl_best['thr_trade']:.2f},{va_pnl_best['thr_dir']:.2f}) \"\n",
    "                f\"trades={va_pnl_best['n_trades']} \"\n",
    "                f\"sel({sel_mode})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"sel({select_metric})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "\n",
    "        if bad >= patience:\n",
    "            break\n",
    "\n",
    "    # ---- choose final best state\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if best_state_pnl is not None:\n",
    "            model.load_state_dict(best_state_pnl)\n",
    "            best_score = best_score_pnl\n",
    "            best_epoch = best_epoch_pnl\n",
    "            best_used = \"va_pnl_max\"\n",
    "        else:\n",
    "            model.load_state_dict(best_state_auc)\n",
    "            best_score = best_score_auc\n",
    "            best_epoch = best_epoch_auc\n",
    "            best_used = \"va_auc_fallback_only\"\n",
    "    else:\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "            best_used = select_metric\n",
    "\n",
    "    # финальные VAL/TEST по best_state\n",
    "    va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "        model, va_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(\n",
    "        model, te_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": float(best_score),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"select_metric\": select_metric,\n",
    "        \"best_used\": best_used,\n",
    "\n",
    "        \"val_loss\": va_loss,\n",
    "        \"val_acc\": va_acc,\n",
    "        \"val_f1m\": va_f1m,\n",
    "        \"val_auc\": va_auc,\n",
    "        \"val_cm\": va_cm,\n",
    "        \"val_y\": va_y,\n",
    "        \"val_prob\": va_prob,\n",
    "        \"val_er\": va_er,\n",
    "\n",
    "        \"test_loss\": te_loss,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_f1m\": te_f1m,\n",
    "        \"test_auc\": te_auc,\n",
    "        \"test_cm\": te_cm,\n",
    "        \"test_y\": te_y,\n",
    "        \"test_prob\": te_prob,\n",
    "        \"test_er\": te_er,\n",
    "\n",
    "        \"hist\": hist,\n",
    "    }\n",
    "    return model, res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: PnL по порогам уверенности (two-stage)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade,          # (N,2) softmax: [:,1]=p_trade\n",
    "    prob_dir,            # (N,2) softmax: [:,1]=p_up\n",
    "    exit_ret,            # (N,) realized log-ret to TB exit\n",
    "    thr_trade: float,\n",
    "    thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:,1]\n",
    "    p_up = prob_dir[:,1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (cost_bps * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(exit_ret),\n",
    "        \"n_trades\": int(trade_mask.sum()),\n",
    "        \"trade_rate\": float(trade_mask.mean()),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg):\n",
    "    rows = []\n",
    "    for thr_t in cfg[\"thr_trade_grid\"]:\n",
    "        for thr_d in cfg[\"thr_dir_grid\"]:\n",
    "            m = two_stage_pnl_by_threshold(\n",
    "                prob_trade=prob_trade,\n",
    "                prob_dir=prob_dir,\n",
    "                exit_ret=exit_ret,\n",
    "                thr_trade=thr_t,\n",
    "                thr_dir=thr_d,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "            )\n",
    "            rows.append({\"thr_trade\":thr_t, \"thr_dir\":thr_d, **m})\n",
    "    return pd.DataFrame(rows).sort_values([\"pnl_mean\",\"pnl_sum\"], ascending=False)\n",
    "\n",
    "print(\"Two-stage PnL threshold utils ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f5c430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: shared helper for probs on arbitrary indices\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_on_indices(model, X_scaled, edge_feat, indices, cfg):\n",
    "    ds = LobGraphSequenceDataset2Stage(\n",
    "        X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, cfg[\"lookback\"]\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, yt, yd, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(probs), np.concatenate(ers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1168 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8495 va_loss=0.7071 f1m=0.478 auc=0.562 sel(va_auc)=0.561927 best=0.561927@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7139 va_loss=0.6816 f1m=0.512 auc=0.557 sel(va_auc)=0.557420 best=0.561927@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6927 va_loss=0.6778 f1m=0.518 auc=0.556 sel(va_auc)=0.556255 best=0.561927@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7007 va_loss=0.6785 f1m=0.385 auc=0.575 sel(va_auc)=0.575214 best=0.575214@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6380 va_loss=0.6726 f1m=0.486 auc=0.572 sel(va_auc)=0.571795 best=0.575214@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6412 va_loss=0.6731 f1m=0.469 auc=0.582 sel(va_auc)=0.582207 best=0.582207@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6312 va_loss=0.6689 f1m=0.503 auc=0.589 sel(va_auc)=0.588500 best=0.588500@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6320 va_loss=0.6776 f1m=0.486 auc=0.574 sel(va_auc)=0.573504 best=0.588500@ep07\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6230 va_loss=0.6782 f1m=0.483 auc=0.582 sel(va_auc)=0.581740 best=0.588500@ep07\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6301 va_loss=0.6763 f1m=0.509 auc=0.585 sel(va_auc)=0.584538 best=0.588500@ep07\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.6025 va_loss=0.6845 f1m=0.520 auc=0.566 sel(va_auc)=0.565734 best=0.588500@ep07\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.5828 va_loss=0.6939 f1m=0.529 auc=0.565 sel(va_auc)=0.564957 best=0.588500@ep07\n",
      "[trade] ep 13 lr=1.00e-04 tr_loss=0.5834 va_loss=0.6943 f1m=0.564 auc=0.567 sel(va_auc)=0.566744 best=0.588500@ep07\n",
      "[trade] ep 14 lr=1.00e-04 tr_loss=0.5660 va_loss=0.7012 f1m=0.537 auc=0.555 sel(va_auc)=0.555012 best=0.588500@ep07\n",
      "[trade] ep 15 lr=1.00e-04 tr_loss=0.5653 va_loss=0.7081 f1m=0.538 auc=0.549 sel(va_auc)=0.549495 best=0.588500@ep07\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8262 va_loss=0.7449 f1m=0.519 auc=0.492 pnl_max=0.000037 thr=(0.60,0.65) trades=3 sel(va_auc_fallback(3/50))=0.492500 best=auc=0.492500@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7478 va_loss=0.7848 f1m=0.378 auc=0.422 pnl_max=0.000039 thr=(0.60,0.70) trades=1 sel(va_auc_fallback(1/50))=0.422000 best=auc=0.492500@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7072 va_loss=0.7861 f1m=0.409 auc=0.415 pnl_max=0.000039 thr=(0.60,0.70) trades=1 sel(va_auc_fallback(1/50))=0.415000 best=auc=0.492500@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6766 va_loss=0.7742 f1m=0.442 auc=0.429 pnl_max=0.000039 thr=(0.60,0.70) trades=1 sel(va_auc_fallback(1/50))=0.428500 best=auc=0.492500@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6425 va_loss=0.7629 f1m=0.476 auc=0.448 pnl_max=0.000039 thr=(0.60,0.70) trades=1 sel(va_auc_fallback(1/50))=0.448000 best=auc=0.492500@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr_loss=0.6152 va_loss=0.7616 f1m=0.476 auc=0.466 pnl_max=0.000027 thr=(0.65,0.70) trades=2 sel(va_auc_fallback(2/50))=0.465500 best=auc=0.492500@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.6410 va_loss=0.7740 f1m=0.422 auc=0.464 pnl_max=0.000027 thr=(0.65,0.70) trades=2 sel(va_auc_fallback(2/50))=0.464000 best=auc=0.492500@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6299 va_loss=0.7792 f1m=0.476 auc=0.464 pnl_max=0.000027 thr=(0.65,0.70) trades=2 sel(va_auc_fallback(2/50))=0.463500 best=auc=0.492500@ep01\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6504 va_loss=0.7783 f1m=0.517 auc=0.465 pnl_max=0.000027 thr=(0.65,0.70) trades=2 sel(va_auc_fallback(2/50))=0.465000 best=auc=0.492500@ep01\n",
      "PnL on fold-test: | thr_trade= 0.7 | thr_dir= 0.55 | pnl_mean= 1.8965336494147778e-05 | trades= 5.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1401 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8988 va_loss=0.6244 f1m=0.474 auc=0.462 sel(va_auc)=0.461970 best=0.461970@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7906 va_loss=0.6159 f1m=0.425 auc=0.414 sel(va_auc)=0.413892 best=0.461970@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7328 va_loss=0.6295 f1m=0.412 auc=0.397 sel(va_auc)=0.396650 best=0.461970@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6838 va_loss=0.6294 f1m=0.415 auc=0.380 sel(va_auc)=0.379803 best=0.461970@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6889 va_loss=0.6357 f1m=0.417 auc=0.402 sel(va_auc)=0.401773 best=0.461970@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.6708 va_loss=0.6180 f1m=0.417 auc=0.411 sel(va_auc)=0.411133 best=0.461970@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6418 va_loss=0.6351 f1m=0.436 auc=0.409 sel(va_auc)=0.409360 best=0.461970@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6448 va_loss=0.6294 f1m=0.441 auc=0.403 sel(va_auc)=0.402956 best=0.461970@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6342 va_loss=0.6267 f1m=0.440 auc=0.414 sel(va_auc)=0.413695 best=0.461970@ep01\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9678 va_loss=0.8805 f1m=0.353 auc=0.531 pnl_max=0.000103 thr=(0.50,0.50) trades=21 sel(va_auc_fallback(21/50))=0.530612 best=auc=0.530612@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7903 va_loss=1.0521 f1m=0.218 auc=0.447 pnl_max=0.000023 thr=(0.60,0.55) trades=5 sel(va_auc_fallback(5/50))=0.446712 best=auc=0.530612@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7701 va_loss=1.0106 f1m=0.276 auc=0.383 pnl_max=0.000023 thr=(0.65,0.65) trades=3 sel(va_auc_fallback(3/50))=0.383220 best=auc=0.530612@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7189 va_loss=0.9159 f1m=0.323 auc=0.356 pnl_max=0.000026 thr=(0.60,0.65) trades=4 sel(va_auc_fallback(4/50))=0.356009 best=auc=0.530612@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7273 va_loss=0.8551 f1m=0.323 auc=0.385 pnl_max=0.000031 thr=(0.50,0.65) trades=7 sel(va_auc_fallback(7/50))=0.385488 best=auc=0.530612@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr_loss=0.6895 va_loss=0.8655 f1m=0.307 auc=0.410 pnl_max=0.000020 thr=(0.60,0.60) trades=6 sel(va_auc_fallback(6/50))=0.410431 best=auc=0.530612@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.6800 va_loss=0.8860 f1m=0.307 auc=0.392 pnl_max=0.000025 thr=(0.50,0.60) trades=13 sel(va_auc_fallback(13/50))=0.392290 best=auc=0.530612@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6453 va_loss=0.8707 f1m=0.288 auc=0.392 pnl_max=0.000020 thr=(0.60,0.60) trades=6 sel(va_auc_fallback(6/50))=0.392290 best=auc=0.530612@ep01\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6403 va_loss=0.8488 f1m=0.303 auc=0.388 pnl_max=0.000030 thr=(0.50,0.65) trades=10 sel(va_auc_fallback(10/50))=0.387755 best=auc=0.530612@ep01\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0002129700151272118 | trades= 52.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 1634 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8283 va_loss=0.8126 f1m=0.429 auc=0.489 sel(va_auc)=0.488524 best=0.488524@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7318 va_loss=0.7728 f1m=0.403 auc=0.473 sel(va_auc)=0.472527 best=0.488524@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6946 va_loss=0.7409 f1m=0.472 auc=0.515 sel(va_auc)=0.515302 best=0.515302@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6837 va_loss=0.7272 f1m=0.463 auc=0.520 sel(va_auc)=0.519562 best=0.519562@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6591 va_loss=0.7278 f1m=0.510 auc=0.549 sel(va_auc)=0.549296 best=0.549296@ep05\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6585 va_loss=0.7330 f1m=0.510 auc=0.558 sel(va_auc)=0.558338 best=0.558338@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6304 va_loss=0.6990 f1m=0.504 auc=0.559 sel(va_auc)=0.559468 best=0.559468@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6221 va_loss=0.7257 f1m=0.506 auc=0.585 sel(va_auc)=0.584768 best=0.584768@ep08\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6072 va_loss=0.6833 f1m=0.560 auc=0.625 sel(va_auc)=0.625456 best=0.625456@ep09\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6034 va_loss=0.7531 f1m=0.543 auc=0.607 sel(va_auc)=0.606764 best=0.625456@ep09\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.5936 va_loss=0.8038 f1m=0.498 auc=0.602 sel(va_auc)=0.601721 best=0.625456@ep09\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.5717 va_loss=0.7611 f1m=0.564 auc=0.645 sel(va_auc)=0.645105 best=0.645105@ep12\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.5655 va_loss=0.7484 f1m=0.565 auc=0.643 sel(va_auc)=0.643279 best=0.645105@ep12\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.5354 va_loss=0.8071 f1m=0.551 auc=0.618 sel(va_auc)=0.618066 best=0.645105@ep12\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.5333 va_loss=0.7801 f1m=0.567 auc=0.642 sel(va_auc)=0.641975 best=0.645105@ep12\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.5120 va_loss=0.8874 f1m=0.535 auc=0.646 sel(va_auc)=0.646062 best=0.646062@ep16\n",
      "[trade] ep 17 lr=2.00e-04 tr_loss=0.4866 va_loss=1.1671 f1m=0.468 auc=0.645 sel(va_auc)=0.645453 best=0.646062@ep16\n",
      "[trade] ep 18 lr=2.00e-04 tr_loss=0.4884 va_loss=1.0362 f1m=0.510 auc=0.626 sel(va_auc)=0.625804 best=0.646062@ep16\n",
      "[trade] ep 19 lr=2.00e-04 tr_loss=0.4676 va_loss=1.1506 f1m=0.502 auc=0.610 sel(va_auc)=0.609894 best=0.646062@ep16\n",
      "[trade] ep 20 lr=2.00e-04 tr_loss=0.4469 va_loss=1.4242 f1m=0.420 auc=0.611 sel(va_auc)=0.610676 best=0.646062@ep16\n",
      "[trade] ep 21 lr=1.00e-04 tr_loss=0.4322 va_loss=1.0864 f1m=0.514 auc=0.625 sel(va_auc)=0.625456 best=0.646062@ep16\n",
      "[trade] ep 22 lr=1.00e-04 tr_loss=0.4255 va_loss=1.0767 f1m=0.533 auc=0.625 sel(va_auc)=0.624848 best=0.646062@ep16\n",
      "[trade] ep 23 lr=1.00e-04 tr_loss=0.3999 va_loss=1.3247 f1m=0.469 auc=0.628 sel(va_auc)=0.627543 best=0.646062@ep16\n",
      "[trade] ep 24 lr=1.00e-04 tr_loss=0.3764 va_loss=1.2463 f1m=0.493 auc=0.627 sel(va_auc)=0.627369 best=0.646062@ep16\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9213 va_loss=0.7284 f1m=0.454 auc=0.559 pnl_max=0.000262 thr=(0.50,0.65) trades=54 sel(va_pnl_max)=0.000262 best=pnl=0.000262@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7985 va_loss=0.7142 f1m=0.469 auc=0.540 pnl_max=0.000260 thr=(0.50,0.55) trades=71 sel(va_pnl_max)=0.000260 best=pnl=0.000262@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7923 va_loss=0.7189 f1m=0.501 auc=0.518 pnl_max=0.000102 thr=(0.50,0.55) trades=71 sel(va_pnl_max)=0.000102 best=pnl=0.000262@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7492 va_loss=0.7330 f1m=0.471 auc=0.498 pnl_max=-0.000055 thr=(0.50,0.60) trades=50 sel(va_pnl_max)=-0.000055 best=pnl=0.000262@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7082 va_loss=0.7332 f1m=0.500 auc=0.484 pnl_max=-0.000161 thr=(0.50,0.50) trades=82 sel(va_pnl_max)=-0.000161 best=pnl=0.000262@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr_loss=0.6632 va_loss=0.7077 f1m=0.488 auc=0.507 pnl_max=-0.000052 thr=(0.50,0.55) trades=67 sel(va_pnl_max)=-0.000052 best=pnl=0.000262@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.6574 va_loss=0.7124 f1m=0.489 auc=0.514 pnl_max=0.000054 thr=(0.50,0.55) trades=71 sel(va_pnl_max)=0.000054 best=pnl=0.000262@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6661 va_loss=0.7205 f1m=0.504 auc=0.510 pnl_max=0.000076 thr=(0.50,0.50) trades=82 sel(va_pnl_max)=0.000076 best=pnl=0.000262@ep01\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6126 va_loss=0.7292 f1m=0.509 auc=0.509 pnl_max=0.000040 thr=(0.50,0.50) trades=82 sel(va_pnl_max)=0.000040 best=pnl=0.000262@ep01\n",
      "PnL on fold-test: | thr_trade= 0.55 | thr_dir= 0.5 | pnl_mean= 0.0003149497788399458 | trades= 122.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 1867 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8213 va_loss=0.7324 f1m=0.413 auc=0.518 sel(va_auc)=0.518190 best=0.518190@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7252 va_loss=0.6450 f1m=0.503 auc=0.555 sel(va_auc)=0.554726 best=0.554726@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6873 va_loss=0.5787 f1m=0.470 auc=0.565 sel(va_auc)=0.564677 best=0.564677@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6678 va_loss=0.5523 f1m=0.474 auc=0.595 sel(va_auc)=0.595460 best=0.595460@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6552 va_loss=0.5363 f1m=0.481 auc=0.593 sel(va_auc)=0.593439 best=0.595460@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6316 va_loss=0.5325 f1m=0.523 auc=0.614 sel(va_auc)=0.614117 best=0.614117@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6201 va_loss=0.4713 f1m=0.508 auc=0.619 sel(va_auc)=0.618781 best=0.618781@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6115 va_loss=0.4858 f1m=0.524 auc=0.623 sel(va_auc)=0.622668 best=0.622668@ep08\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.5871 va_loss=0.4971 f1m=0.531 auc=0.620 sel(va_auc)=0.620491 best=0.622668@ep08\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.5830 va_loss=0.5242 f1m=0.538 auc=0.635 sel(va_auc)=0.634639 best=0.634639@ep10\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.5559 va_loss=0.5134 f1m=0.550 auc=0.635 sel(va_auc)=0.635106 best=0.635106@ep11\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.5498 va_loss=0.5972 f1m=0.532 auc=0.652 sel(va_auc)=0.651586 best=0.651586@ep12\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.5457 va_loss=0.6329 f1m=0.517 auc=0.646 sel(va_auc)=0.645989 best=0.651586@ep12\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.5280 va_loss=0.5571 f1m=0.507 auc=0.642 sel(va_auc)=0.642257 best=0.651586@ep12\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.5085 va_loss=0.7078 f1m=0.500 auc=0.648 sel(va_auc)=0.648165 best=0.651586@ep12\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.5012 va_loss=0.5832 f1m=0.510 auc=0.637 sel(va_auc)=0.636816 best=0.651586@ep12\n",
      "[trade] ep 17 lr=1.00e-04 tr_loss=0.4820 va_loss=0.8333 f1m=0.498 auc=0.645 sel(va_auc)=0.645367 best=0.651586@ep12\n",
      "[trade] ep 18 lr=1.00e-04 tr_loss=0.4656 va_loss=0.7123 f1m=0.513 auc=0.642 sel(va_auc)=0.642257 best=0.651586@ep12\n",
      "[trade] ep 19 lr=1.00e-04 tr_loss=0.4592 va_loss=0.7006 f1m=0.506 auc=0.649 sel(va_auc)=0.648787 best=0.651586@ep12\n",
      "[trade] ep 20 lr=1.00e-04 tr_loss=0.4398 va_loss=0.6603 f1m=0.496 auc=0.641 sel(va_auc)=0.641480 best=0.651586@ep12\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7740 va_loss=0.7575 f1m=0.417 auc=0.491 pnl_max=-0.000103 thr=(0.50,0.70) trades=59 sel(va_pnl_max)=-0.000103 best=pnl=-0.000103@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.6995 va_loss=0.7432 f1m=0.412 auc=0.479 pnl_max=0.000050 thr=(0.50,0.65) trades=66 sel(va_pnl_max)=0.000050 best=pnl=0.000050@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.6878 va_loss=0.7476 f1m=0.452 auc=0.471 pnl_max=0.000039 thr=(0.50,0.65) trades=52 sel(va_pnl_max)=0.000039 best=pnl=0.000050@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6809 va_loss=0.7746 f1m=0.469 auc=0.464 pnl_max=0.000272 thr=(0.70,0.50) trades=136 sel(va_pnl_max)=0.000272 best=pnl=0.000272@ep04\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6445 va_loss=0.7980 f1m=0.433 auc=0.455 pnl_max=0.000075 thr=(0.70,0.50) trades=136 sel(va_pnl_max)=0.000075 best=pnl=0.000272@ep04\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6279 va_loss=0.8121 f1m=0.458 auc=0.446 pnl_max=0.000245 thr=(0.70,0.50) trades=136 sel(va_pnl_max)=0.000245 best=pnl=0.000272@ep04\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6030 va_loss=0.8247 f1m=0.481 auc=0.451 pnl_max=0.000167 thr=(0.70,0.50) trades=136 sel(va_pnl_max)=0.000167 best=pnl=0.000272@ep04\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.6289 va_loss=0.8602 f1m=0.416 auc=0.452 pnl_max=0.000025 thr=(0.70,0.60) trades=102 sel(va_pnl_max)=0.000025 best=pnl=0.000272@ep04\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6011 va_loss=0.8580 f1m=0.475 auc=0.447 pnl_max=0.000169 thr=(0.70,0.50) trades=136 sel(va_pnl_max)=0.000169 best=pnl=0.000272@ep04\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.5871 va_loss=0.8797 f1m=0.454 auc=0.445 pnl_max=0.000070 thr=(0.50,0.55) trades=144 sel(va_pnl_max)=0.000070 best=pnl=0.000272@ep04\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.5735 va_loss=0.9130 f1m=0.436 auc=0.446 pnl_max=0.000080 thr=(0.70,0.60) trades=104 sel(va_pnl_max)=0.000080 best=pnl=0.000272@ep04\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.5604 va_loss=0.9204 f1m=0.442 auc=0.447 pnl_max=0.000072 thr=(0.70,0.60) trades=108 sel(va_pnl_max)=0.000072 best=pnl=0.000272@ep04\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.7 | pnl_mean= 4.164447091170587e-06 | trades= 16.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.474256</td>\n",
       "      <td>0.415504</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.021459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.429684</td>\n",
       "      <td>0.456707</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.223176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.431644</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.523605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.464368</td>\n",
       "      <td>0.501374</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.474256      0.415504       0.000019            0.70   \n",
       "1     2        0.429684      0.456707       0.000213            0.50   \n",
       "2     3        0.431644      0.384911       0.000315            0.55   \n",
       "3     4        0.464368      0.501374       0.000004            0.50   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0          0.55            5.0         0.021459  \n",
       "1          0.50           52.0         0.223176  \n",
       "2          0.50          122.0         0.523605  \n",
       "3          0.70           16.0         0.068670  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN (fold-test внутри CV-part):\n",
      "fold                2.500000\n",
      "trade_test_f1m      0.449988\n",
      "dir_test_f1m        0.439624\n",
      "best_pnl_mean       0.000138\n",
      "best_thr_trade      0.562500\n",
      "best_thr_dir        0.562500\n",
      "n_trades_best      48.750000\n",
      "trade_rate_best     0.209227\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training (ONLY on CV-part)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold (fit only on train times)\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples (по AUC)\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\",\n",
    "        select_metric=\"va_auc\",\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples (train/val/test индексы фильтруем)\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "            \"trade_rate_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # dir: учим на trade-only, но PnL-proxy считаем на полном idx_va (full val)\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\",\n",
    "        select_metric=\"va_pnl_max\",\n",
    "        trade_model_for_pnl=m_trade,\n",
    "        idx_val_pnl=idx_va,   # <-- полный val для pnl-proxy\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on fold TEST\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te, CFG)\n",
    "    prob_dir_te, _       = predict_probs_on_indices(m_dir,   X_scaled, edge_feat, idx_te, CFG)\n",
    "\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on fold-test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN (fold-test внутри CV-part):\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": [
    "## 11. Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50d16463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL TRAIN/TEST (CV=90% | FINAL=10%)\n",
      "Final split sizes:\n",
      "  train_final: 2104\n",
      "  val_final  : 233\n",
      "  FINAL test : 260\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : 0.00046820880379527807\n",
      "  pnl_sum  : 0.12173429131507874\n",
      "  n_trades : 69\n",
      "  trade_rate: 0.2653846153846154\n",
      "  sharpe (per-bar proxy): 1.887329722877952\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.7 thr_dir: 0.65\n",
      "  pnl_mean : 0.000663473445456475 trades: 71.0\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Final train on CV(90%) and evaluate once on FINAL(10%)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAIN/TEST (CV=90% | FINAL=10%)\")\n",
    "\n",
    "# 1) final train/val split внутри CV-part (по времени)\n",
    "val_w_final = max(1, int(CFG[\"val_window_frac\"] * n_samples_cv))\n",
    "train_end = n_samples_cv - val_w_final\n",
    "\n",
    "idx_train_final = np.arange(0, train_end, dtype=np.int64)\n",
    "idx_val_final   = np.arange(train_end, n_samples_cv, dtype=np.int64)\n",
    "idx_test_final  = idx_final_test.astype(np.int64)  # финальный holdout\n",
    "\n",
    "print(\"Final split sizes:\")\n",
    "print(\"  train_final:\", len(idx_train_final))\n",
    "print(\"  val_final  :\", len(idx_val_final))\n",
    "print(\"  FINAL test :\", len(idx_test_final))\n",
    "\n",
    "# 2) scaling (fit only on train_final)\n",
    "X_scaled_final, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train_final, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=summary['best_thr_trade'][3],\n",
    "    thr_dir=summary['best_thr_dir'][3],\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c4946a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7861 va_loss=0.7133 f1m=0.518 auc=0.527 sel(va_auc)=0.526651 best=0.526651@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7044 va_loss=0.7149 f1m=0.549 auc=0.547 sel(va_auc)=0.546931 best=0.546931@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6535 va_loss=0.7303 f1m=0.561 auc=0.557 sel(va_auc)=0.556721 best=0.556721@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6376 va_loss=0.7483 f1m=0.593 auc=0.559 sel(va_auc)=0.558741 best=0.558741@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6219 va_loss=0.7552 f1m=0.583 auc=0.554 sel(va_auc)=0.554235 best=0.558741@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6035 va_loss=0.7769 f1m=0.567 auc=0.548 sel(va_auc)=0.548174 best=0.558741@ep04\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.5803 va_loss=0.8076 f1m=0.559 auc=0.545 sel(va_auc)=0.545455 best=0.558741@ep04\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.5936 va_loss=0.8146 f1m=0.578 auc=0.551 sel(va_auc)=0.550894 best=0.558741@ep04\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.5805 va_loss=0.8042 f1m=0.570 auc=0.549 sel(va_auc)=0.549184 best=0.558741@ep04\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.5552 va_loss=0.8478 f1m=0.571 auc=0.550 sel(va_auc)=0.549961 best=0.558741@ep04\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.5578 va_loss=0.8557 f1m=0.559 auc=0.534 sel(va_auc)=0.534499 best=0.558741@ep04\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.5443 va_loss=0.8674 f1m=0.569 auc=0.547 sel(va_auc)=0.547397 best=0.558741@ep04\n",
      "Trade-only sizes for DIR:\n",
      "  train_final_T: 963\n",
      "  val_final_T  : 143\n",
      "  test_final_T : 207\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8650 va_loss=0.7671 f1m=0.401 auc=0.466 pnl_max=0.000475 thr=(0.65,0.50) trades=103 sel(va_pnl_max)=0.000475 best=pnl=0.000475@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7621 va_loss=0.7406 f1m=0.410 auc=0.480 pnl_max=0.000571 thr=(0.50,0.55) trades=117 sel(va_pnl_max)=0.000571 best=pnl=0.000571@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7363 va_loss=0.7473 f1m=0.412 auc=0.458 pnl_max=0.000340 thr=(0.50,0.50) trades=143 sel(va_pnl_max)=0.000340 best=pnl=0.000571@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6999 va_loss=0.7389 f1m=0.461 auc=0.483 pnl_max=0.000312 thr=(0.50,0.50) trades=143 sel(va_pnl_max)=0.000312 best=pnl=0.000571@ep02\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6931 va_loss=0.7404 f1m=0.470 auc=0.490 pnl_max=0.000500 thr=(0.50,0.50) trades=143 sel(va_pnl_max)=0.000500 best=pnl=0.000571@ep02\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6978 va_loss=0.7342 f1m=0.487 auc=0.498 pnl_max=0.000364 thr=(0.50,0.55) trades=115 sel(va_pnl_max)=0.000364 best=pnl=0.000571@ep02\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.6499 va_loss=0.7370 f1m=0.494 auc=0.499 pnl_max=0.000056 thr=(0.50,0.50) trades=143 sel(va_pnl_max)=0.000056 best=pnl=0.000571@ep02\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6427 va_loss=0.7356 f1m=0.505 auc=0.506 pnl_max=0.000151 thr=(0.50,0.60) trades=76 sel(va_pnl_max)=0.000151 best=pnl=0.000571@ep02\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6510 va_loss=0.7387 f1m=0.507 auc=0.508 pnl_max=0.000137 thr=(0.50,0.50) trades=143 sel(va_pnl_max)=0.000137 best=pnl=0.000571@ep02\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.6314 va_loss=0.7356 f1m=0.497 auc=0.518 pnl_max=0.000175 thr=(0.50,0.55) trades=113 sel(va_pnl_max)=0.000175 best=pnl=0.000571@ep02\n",
      "\n",
      "Chosen thresholds on val_final:\n",
      "  thr_trade*: 0.5\n",
      "  thr_dir*  : 0.55\n",
      "  val pnl_mean: 0.0005712546990253031 | val trades: 117\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : -0.0002053699572570622\n",
      "  pnl_sum  : -0.05339618772268295\n",
      "  n_trades : 162\n",
      "  trade_rate: 0.6230769230769231\n",
      "  sharpe (per-bar proxy): -0.4764884141479107\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.65 thr_dir: 0.6\n",
      "  pnl_mean : -6.121279875515029e-05 trades: 111.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3) train TRADE on train_final, select by AUC on val_final\n",
    "m_trade_final, r_trade_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final, idx_val_final, idx_test_final,\n",
    "    CFG,\n",
    "    stage_name=\"trade\",\n",
    "    select_metric=\"va_auc\",\n",
    ")\n",
    "\n",
    "# 4) train DIR on trade-only samples (train/val/test filtered),\n",
    "#    but pnl-proxy computed on full val_final; selector hard-fallback already inside\n",
    "idx_train_final_T = subset_trade_indices(idx_train_final, sample_t, y_trade)\n",
    "idx_val_final_T   = subset_trade_indices(idx_val_final,   sample_t, y_trade)\n",
    "idx_test_final_T  = subset_trade_indices(idx_test_final,  sample_t, y_trade)\n",
    "\n",
    "print(\"Trade-only sizes for DIR:\")\n",
    "print(\"  train_final_T:\", len(idx_train_final_T))\n",
    "print(\"  val_final_T  :\", len(idx_val_final_T))\n",
    "print(\"  test_final_T :\", len(idx_test_final_T))\n",
    "\n",
    "m_dir_final, r_dir_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final_T, idx_val_final_T, idx_test_final_T,\n",
    "    CFG,\n",
    "    stage_name=\"dir\",\n",
    "    select_metric=\"va_pnl_max\",\n",
    "    trade_model_for_pnl=m_trade_final,\n",
    "    idx_val_pnl=idx_val_final,   # pnl-proxy на полном val_final\n",
    ")\n",
    "\n",
    "# 5) выбрать пороги по val_final (grid sweep)\n",
    "prob_trade_val, er_val = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "prob_dir_val, _        = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "\n",
    "sweep_val = sweep_thresholds(prob_trade_val, prob_dir_val, er_val, CFG)\n",
    "best_val = sweep_val.iloc[0].to_dict()\n",
    "thr_trade_star = float(best_val[\"thr_trade\"])\n",
    "thr_dir_star   = float(best_val[\"thr_dir\"])\n",
    "\n",
    "print(\"\\nChosen thresholds on val_final:\")\n",
    "print(\"  thr_trade*:\", thr_trade_star)\n",
    "print(\"  thr_dir*  :\", thr_dir_star)\n",
    "print(\"  val pnl_mean:\", float(best_val[\"pnl_mean\"]), \"| val trades:\", int(best_val[\"n_trades\"]))\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=thr_trade_star,\n",
    "    thr_dir=thr_dir_star,\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
