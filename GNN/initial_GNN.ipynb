{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82200431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "def load_asset(asset):\n",
    "    freq = '5min'\n",
    "    DATA_DIR = Path('../dataset')\n",
    "    path = DATA_DIR / f\"{asset}_{freq}.csv\"\n",
    "\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df['timestamp'] = pd.to_datetime(df[\"system_time\"])\n",
    "    df['timestamp'] = df['timestamp'].dt.round('min')\n",
    "    df = df.sort_values('timestamp').set_index('timestamp')\n",
    "\n",
    "    return df\n",
    "\n",
    "df_ADA = load_asset(\"ADA\")\n",
    "df_BTC = load_asset(\"BTC\")\n",
    "df_ETH = load_asset(\"ETH\")\n",
    "\n",
    "# Align by timestamp\n",
    "df = df_ADA[['midpoint']] \\\n",
    "    .join(df_BTC[['midpoint']], rsuffix='_BTC') \\\n",
    "    .join(df_ETH[['midpoint']], rsuffix='_ETH')\n",
    "\n",
    "# You will add features next\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, pre_transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        super().__init__(None, transform, pre_transform)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.dataframe) - 1\n",
    "\n",
    "    def get(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        next_row = self.dataframe.iloc[idx + 1]\n",
    "\n",
    "        x = torch.tensor(row.values, dtype=torch.float).unsqueeze(0)\n",
    "        y = torch.tensor(next_row.values, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "        edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "\n",
    "        data = Data(x=x, y=y, edge_index=edge_index)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1fb9a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df[\"imbalance_trades\"] = (df[\"buys\"] - df[\"sells\"]) / (df[\"buys\"] + df[\"sells\"] + 1e-6)\n",
    "    \n",
    "    df[\"bid_liq_near\"] = df[[f\"bids_notional_{i}\" for i in range(3)]].sum(axis=1)\n",
    "    df[\"ask_liq_near\"] = df[[f\"asks_notional_{i}\" for i in range(3)]].sum(axis=1)\n",
    "    \n",
    "    df[\"lob_imbalance\"] = (df[\"bid_liq_near\"] - df[\"ask_liq_near\"]) / \\\n",
    "                          (df[\"bid_liq_near\"] + df[\"ask_liq_near\"] + 1e-6)\n",
    "    \n",
    "    keep = [\n",
    "        \"midpoint\", \"spread\", \"buys\", \"sells\",\n",
    "        \"imbalance_trades\",\n",
    "        \"bid_liq_near\", \"ask_liq_near\", \"lob_imbalance\",\n",
    "        \"bids_distance_0\", \"bids_distance_1\", \"bids_distance_2\",\n",
    "        \"asks_distance_0\", \"asks_distance_1\", \"asks_distance_2\",\n",
    "    ]\n",
    "    \n",
    "    return df[keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a36e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAssetDataset(Dataset):\n",
    "    def __init__(self, df_ADA, df_BTC, df_ETH, window=24):\n",
    "        super().__init__()\n",
    "        self.window = window\n",
    "        \n",
    "        A = add_features(df_ADA)\n",
    "        B = add_features(df_BTC)\n",
    "        C = add_features(df_ETH)\n",
    "        \n",
    "        merged = A.join(B, rsuffix=\"_BTC\").join(C, rsuffix=\"_ETH\")\n",
    "        self.features = merged.dropna()\n",
    "        \n",
    "        midpoint = self.features[\"midpoint\"]\n",
    "        self.y = (midpoint.shift(-1) > midpoint).astype(int)\n",
    "        self.y = self.y.iloc[window:]\n",
    "        \n",
    "        self.features = self.features.iloc[:-1]  # align\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def get(self, idx):\n",
    "        x_window = self.features.iloc[idx:idx+self.window]\n",
    "        \n",
    "        # for each timestep: 3 nodes Ã— feature_dim\n",
    "        node_feats = []\n",
    "        for t in range(self.window):\n",
    "            row = x_window.iloc[t]\n",
    "            ada = row[[c for c in row.index if not c.endswith(\"_BTC\") and not c.endswith(\"_ETH\")]].values\n",
    "            btc = row[[c for c in row.index if c.endswith(\"_BTC\")]].values\n",
    "            eth = row[[c for c in row.index if c.endswith(\"_ETH\")]].values\n",
    "            node_feats.append(np.vstack([ada, btc, eth]))\n",
    "        \n",
    "        x = torch.tensor(np.array(node_feats), dtype=torch.float)\n",
    "\n",
    "        edge_index = torch.tensor([[0,1,0,2,1,2],[1,0,2,0,2,1]], dtype=torch.long)\n",
    "\n",
    "        return Data(\n",
    "            x=x, \n",
    "            edge_index=edge_index, \n",
    "            y=torch.tensor(self.y.iloc[idx], dtype=torch.long)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d557cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "class TemporalGNN(nn.Module):\n",
    "    def __init__(self, node_features, gnn_hidden=64, lstm_hidden=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gnn = GATv2Conv(node_features, gnn_hidden, heads=2, concat=False)\n",
    "        self.lstm = nn.LSTM(gnn_hidden*3, lstm_hidden, batch_first=True)\n",
    "        self.out = nn.Linear(lstm_hidden, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # x: [T, 3, F]\n",
    "        T = x.size(0)\n",
    "        \n",
    "        gnn_outputs = []\n",
    "        for t in range(T):\n",
    "            h = self.gnn(x[t], edge_index)  # [3, hidden]\n",
    "            gnn_outputs.append(h.reshape(1, -1))\n",
    "        \n",
    "        h = torch.cat(gnn_outputs, dim=0).unsqueeze(0)  # [1, T, 3*hidden]\n",
    "        out, _ = self.lstm(h)\n",
    "        final = out[:, -1, :]\n",
    "        \n",
    "        return self.out(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc6524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.7007795692650144\n",
      "Epoch 1 loss 0.6970860327343027\n",
      "Epoch 2 loss 0.6957824012119613\n",
      "Epoch 3 loss 0.6954976568678896\n",
      "Epoch 4 loss 0.6972960884431879\n",
      "Epoch 5 loss 0.6973480282161764\n",
      "Epoch 6 loss 0.697908770163616\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m pred = model(batch)\n\u001b[32m     13\u001b[39m loss = criterion(pred, batch.y)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m optim.step()\n\u001b[32m     16\u001b[39m total += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dataset = MultiAssetDataset(df_ADA, df_BTC, df_ETH)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = TemporalGNN(node_features=14)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    total = 0\n",
    "    for batch in loader:\n",
    "        optim.zero_grad()\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch.y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += loss.item()\n",
    "    print(\"Epoch\", epoch, \"loss\", total / len(loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99e75ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal\n",
    "import numpy as np\n",
    "\n",
    "def build_temporal_graph(df_ADA, df_BTC, df_ETH, window=24):\n",
    "    A = add_features(df_ADA)\n",
    "    B = add_features(df_BTC)\n",
    "    C = add_features(df_ETH)\n",
    "\n",
    "    merged = A.join(B, rsuffix=\"_BTC\").join(C, rsuffix=\"_ETH\").dropna()\n",
    "\n",
    "    # labels\n",
    "    midpoint = merged[\"midpoint\"]\n",
    "    y = (midpoint.shift(-1) > midpoint).astype(int).dropna()\n",
    "    merged = merged.iloc[:-1]\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    E = []\n",
    "    EI = []\n",
    "\n",
    "    # fixed fully connected graph\n",
    "    edge_index = np.array([[0,1,0,2,1,2],[1,0,2,0,2,1]])\n",
    "\n",
    "    for i in range(len(merged)-window):\n",
    "        block = merged.iloc[i:i+window]\n",
    "        # create node features per timestep\n",
    "        X_t = []\n",
    "        for t in range(window):\n",
    "            row = block.iloc[t]\n",
    "\n",
    "            ada = row[[c for c in block.columns if not (c.endswith(\"_BTC\") or c.endswith(\"_ETH\"))]].values\n",
    "            btc = row[[c for c in block.columns if c.endswith(\"_BTC\")]].values\n",
    "            eth = row[[c for c in block.columns if c.endswith(\"_ETH\")]].values\n",
    "\n",
    "            X_t.append(np.vstack([ada, btc, eth]))  # shape: [3, F]\n",
    "\n",
    "        X.append(np.array(X_t))          # [T, 3, F]\n",
    "        EI.append(edge_index)            # constant edges\n",
    "        Y.append(y.iloc[i+window-1])\n",
    "\n",
    "    return DynamicGraphTemporalSignal(\n",
    "        edge_indices=EI,\n",
    "        edge_weights=[None]*len(EI),\n",
    "        features=X,\n",
    "        targets=np.array(Y)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4796c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric_temporal.nn import A3TGCN\n",
    "\n",
    "class PriceDirectionTGAT(nn.Module):\n",
    "    def __init__(self, node_features, out_channels=32, periods=24):\n",
    "        super().__init__()\n",
    "        self.tgat = A3TGCN(in_channels=node_features, out_channels=out_channels, periods=periods)\n",
    "        self.fc = nn.Linear(out_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x shape: [T, num_nodes, F]\n",
    "        h = self.tgat(x, edge_index)  # output per timestep: [num_nodes, out_channels]\n",
    "        h_last = h[-1].reshape(-1)    # flatten nodes at last step\n",
    "        return self.fc(h_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f950a809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/1b5sy3xs1_50rf2v8vnv0s9c0000gn/T/ipykernel_38237/4217789532.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(snapshot.x, dtype=torch.float)\n",
      "/var/folders/fs/1b5sy3xs1_50rf2v8vnv0s9c0000gn/T/ipykernel_38237/4217789532.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_idx = torch.tensor(snapshot.edge_index, dtype=torch.long)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (24x3 and 14x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m y = torch.tensor([snapshot.y], dtype=torch.long)\n\u001b[32m     17\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m loss = criterion(pred, y)\n\u001b[32m     20\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mPriceDirectionTGAT.forward\u001b[39m\u001b[34m(self, x, edge_index)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# x shape: [T, num_nodes, F]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtgat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# output per timestep: [num_nodes, out_channels]\u001b[39;00m\n\u001b[32m     14\u001b[39m     h_last = h[-\u001b[32m1\u001b[39m].reshape(-\u001b[32m1\u001b[39m)    \u001b[38;5;66;03m# flatten nodes at last step\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc(h_last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch_geometric_temporal/nn/recurrent/attentiontemporalgcn.py:76\u001b[39m, in \u001b[36mA3TGCN.forward\u001b[39m\u001b[34m(self, X, edge_index, edge_weight, H)\u001b[39m\n\u001b[32m     74\u001b[39m probs = torch.nn.functional.softmax(\u001b[38;5;28mself\u001b[39m._attention, dim=\u001b[32m0\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m period \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.periods):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     H_accum = H_accum + probs[period] * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_base_tgcn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m H_accum\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch_geometric_temporal/nn/recurrent/temporalgcn.py:126\u001b[39m, in \u001b[36mTGCN.forward\u001b[39m\u001b[34m(self, X, edge_index, edge_weight, H)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03mMaking a forward pass. If edge weights are not present the forward pass\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03mdefaults to an unweighted graph. If the hidden state matrix is not present\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \u001b[33;03m    * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m H = \u001b[38;5;28mself\u001b[39m._set_hidden_state(X, H)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m Z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_update_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m R = \u001b[38;5;28mself\u001b[39m._calculate_reset_gate(X, edge_index, edge_weight, H)\n\u001b[32m    128\u001b[39m H_tilde = \u001b[38;5;28mself\u001b[39m._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch_geometric_temporal/nn/recurrent/temporalgcn.py:83\u001b[39m, in \u001b[36mTGCN._calculate_update_gate\u001b[39m\u001b[34m(self, X, edge_index, edge_weight, H)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_calculate_update_gate\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, edge_index, edge_weight, H):\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     Z = torch.cat([\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m, H], axis=\u001b[32m1\u001b[39m)\n\u001b[32m     84\u001b[39m     Z = \u001b[38;5;28mself\u001b[39m.linear_z(Z)\n\u001b[32m     85\u001b[39m     Z = torch.sigmoid(Z)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:260\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    258\u001b[39m             edge_index = cache\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[32m    263\u001b[39m out = \u001b[38;5;28mself\u001b[39m.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:127\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    122\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (24x3 and 14x32)"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "dataset = build_temporal_graph(df_ADA, df_BTC, df_ETH, window=24)\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "model = PriceDirectionTGAT(node_features=14)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    for snapshot in train_dataset:\n",
    "        x = torch.tensor(snapshot.x, dtype=torch.float)\n",
    "        edge_idx = torch.tensor(snapshot.edge_index, dtype=torch.long)\n",
    "        y = torch.tensor([snapshot.y], dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x, edge_idx)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    print(f\"Epoch {epoch} | loss={np.mean(losses):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
