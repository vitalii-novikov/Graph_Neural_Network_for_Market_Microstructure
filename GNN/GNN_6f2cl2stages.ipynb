{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),\n",
    "\n",
    "    # sequence\n",
    "    \"lookback\": 48,   # L\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 96],  # 30m,1h,2h,4h,8h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 12,       # 1h\n",
    "    \"tb_vol_window\": 48,    # 4h\n",
    "    \"tb_pt_mult\": 1.5,\n",
    "    \"tb_sl_mult\": 1.5,\n",
    "    \"tb_min_barrier\": 0.0005,\n",
    "    \"tb_max_barrier\": 0.002,\n",
    "\n",
    "    # training (общие)\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.15,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "print(\"EDGE_INDEX:\", EDGE_INDEX.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (3367, 22)\n",
      "Columns example: ['timestamp', 'ADA', 'bids_vol_ADA', 'asks_vol_ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'BTC', 'bids_vol_BTC', 'asks_vol_BTC']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "    return df[[\"midpoint\",\"bids_notional_0\",\"asks_notional_0\",\"spread\",\"buys\",\"sells\"]]\n",
    "\n",
    "def load_all_assets():\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "\n",
    "    df_ADA = load_asset(\"ADA\", freq, data_dir).rename(columns={\n",
    "        \"midpoint\":\"ADA\",\"buys\":\"buys_ADA\",\"sells\":\"sells_ADA\",\n",
    "        \"bids_notional_0\":\"bids_vol_ADA\",\"asks_notional_0\":\"asks_vol_ADA\",\"spread\":\"spread_ADA\",\n",
    "    })\n",
    "    df_BTC = load_asset(\"BTC\", freq, data_dir).rename(columns={\n",
    "        \"midpoint\":\"BTC\",\"buys\":\"buys_BTC\",\"sells\":\"sells_BTC\",\n",
    "        \"bids_notional_0\":\"bids_vol_BTC\",\"asks_notional_0\":\"asks_vol_BTC\",\"spread\":\"spread_BTC\",\n",
    "    })\n",
    "    df_ETH = load_asset(\"ETH\", freq, data_dir).rename(columns={\n",
    "        \"midpoint\":\"ETH\",\"buys\":\"buys_ETH\",\"sells\":\"sells_ETH\",\n",
    "        \"bids_notional_0\":\"bids_vol_ETH\",\"asks_notional_0\":\"asks_vol_ETH\",\"spread\":\"spread_ETH\",\n",
    "    })\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Columns example:\", df.columns[:10].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (3367, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [1477  265 1625]\n",
      "Trade ratio: 0.9212949212949213\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=CFG[\"tb_horizon\"],\n",
    "    vol_window=CFG[\"tb_vol_window\"],\n",
    "    pt_mult=CFG[\"tb_pt_mult\"],\n",
    "    sl_mult=CFG[\"tb_sl_mult\"],\n",
    "    min_barrier=CFG[\"tb_min_barrier\"],\n",
    "    max_barrier=CFG[\"tb_max_barrier\"],\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (3367, 3, 8) edge_feat: (3367, 3, 5)\n",
      "n_samples: 3307 t range: 47 3353\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray):\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    feats = []\n",
    "    feat_names = [\"lr\",\"spread\",\"log_bids\",\"log_asks\",\"log_buys\",\"log_sells\",\"ofi\",\"di\"]\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        bids = df[f\"bids_vol_{a}\"].values.astype(np.float32)\n",
    "        asks = df[f\"asks_vol_{a}\"].values.astype(np.float32)\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_bids = safe_log1p(bids).astype(np.float32)\n",
    "        log_asks = safe_log1p(asks).astype(np.float32)\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "        di  = ((bids - asks)  / (bids + asks + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.stack([lr, spread, log_bids, log_asks, log_buys, log_sells, ofi, di], axis=1)\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1653 | val 330 | test 330\n",
      " fold 2: train 1983 | val 330 | test 330\n",
      " fold 3: train 2313 | val 330 | test 330\n",
      " fold 4: train 2643 | val 330 | test 330\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "        idx_train = np.arange(0, tr_end)\n",
    "        idx_val   = np.arange(tr_end, va_end)\n",
    "        idx_test  = np.arange(va_end, te_end)\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "    return splits\n",
    "\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "\n",
    "for i, (a,b,c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: GNN + LSTM classifier (универсальный под 2 класса)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class EdgeGatedMP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_proj = nn.Linear(in_dim, hidden)\n",
    "        self.ln0 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden + edge_dim, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden + 1)  # msg(hidden) + gate(1)\n",
    "        )\n",
    "\n",
    "        self.upd = nn.Sequential(\n",
    "            nn.Linear(2*hidden, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward_once(self, x_t, edge_attr_t, edge_index):\n",
    "        B, N, _ = x_t.shape\n",
    "        E = edge_index.shape[0]\n",
    "\n",
    "        h = self.ln0(self.node_proj(x_t))  # (B,N,H)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        agg = torch.zeros((B, N, h.shape[-1]), device=h.device, dtype=h.dtype)\n",
    "\n",
    "        for e in range(E):\n",
    "            src = edge_index[e, 0].item()\n",
    "            dst = edge_index[e, 1].item()\n",
    "            h_src = h[:, src, :]\n",
    "            h_dst = h[:, dst, :]\n",
    "            ea = edge_attr_t[:, e, :]\n",
    "\n",
    "            z = torch.cat([h_src, h_dst, ea], dim=-1)\n",
    "            out = self.edge_mlp(z)\n",
    "            msg = out[:, :-1]\n",
    "            gate = torch.sigmoid(out[:, -1:])\n",
    "\n",
    "            agg[:, dst, :] += msg * gate\n",
    "\n",
    "        h2 = self.upd(torch.cat([h, agg], dim=-1))\n",
    "        h2 = self.ln1(h + self.dropout(h2))\n",
    "        h2 = torch.nan_to_num(h2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return h2\n",
    "\n",
    "    def forward(self, x_seq, e_seq, edge_index):\n",
    "        B, L, N, Fin = x_seq.shape\n",
    "        h_out = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            h_out.append(ht)\n",
    "        return torch.stack(h_out, dim=1)  # (B,L,N,H)\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = target_node\n",
    "\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(gnn_layers):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(EdgeGatedMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, dropout=dropout))\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(lstm_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, lstm_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, n_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        out, _ = self.lstm(h_tgt)\n",
    "        last = out[:, -1, :]\n",
    "        logits = self.head(last)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"Model ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        er_np = er.cpu().numpy()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))  # (B,2)\n",
    "        # y is passed inside loader by selecting correct field externally\n",
    "        # so here we assume loader yields y in y_trade_b (or y_dir_b) as \"y_trade_b\"\n",
    "        y = y_trade_b.to(DEVICE).long()\n",
    "\n",
    "        loss = loss_fn(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()  # (B,2)\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er_np)\n",
    "\n",
    "    ys = np.concatenate(ys)\n",
    "    probs = np.concatenate(probs)\n",
    "    ers = np.concatenate(ers)\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:,1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss/max(n,1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "def make_pos_weight(y01: np.ndarray):\n",
    "    pos = max(1, int((y01 == 1).sum()))\n",
    "    neg = max(1, int((y01 == 0).sum()))\n",
    "    return float(neg / pos)\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    stage_name:\n",
    "      - \"trade\": обучаем y_trade на всех samples\n",
    "      - \"dir\":   обучаем y_dir только на trade samples (idx_* уже должны быть отфильтрованы)\n",
    "    \"\"\"\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val, L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test, L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True, drop_last=True, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # label extraction for pos_weight\n",
    "    if stage_name == \"trade\":\n",
    "        ytr = y_trade_arr[sample_t[idx_train]]\n",
    "    elif stage_name == \"dir\":\n",
    "        ytr = y_dir_arr[sample_t[idx_train]]\n",
    "    else:\n",
    "        raise ValueError(\"stage_name must be 'trade' or 'dir'\")\n",
    "\n",
    "    pos_w = make_pos_weight(ytr)\n",
    "    loss_fn = nn.CrossEntropyLoss()  # базово CE\n",
    "    # (если хочешь pos_weight, то лучше BCE; но чтобы не усложнять logits->2, оставим CE + баланс через sampler/веса)\n",
    "    # Минимально: просто CE, а дисбаланс компенсируем тем, что Stage B обучается только на trade.\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type==\"cuda\"))\n",
    "\n",
    "    best_score = -1e9\n",
    "    best_state = None\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\"tr_loss\":[], \"va_loss\":[], \"va_f1m\":[], \"va_auc\":[]}\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"]+1):\n",
    "        model.train()\n",
    "        tot = 0.0; n = 0\n",
    "\n",
    "        for x,e,y_trade_b,y_dir_b,er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "\n",
    "            # select labels by stage\n",
    "            y = (y_trade_b if stage_name==\"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type==\"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item()*y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot/max(n,1)\n",
    "\n",
    "        # ---- eval (важно: eval_binary читает y из y_trade_b; поэтому подменяем порядок через wrapper-лоадер нельзя.\n",
    "        # минимально: просто используем loader, но в eval_binary считаем y = y_trade_b.\n",
    "        # => Для dir-stage нужно \"перепаковать\" y_dir в позицию y_trade_b (самый простой минимальный способ).\n",
    "        def wrap_loader_for_stage(loader, stage):\n",
    "            for x,e,y_trade_b,y_dir_b,er in loader:\n",
    "                if stage == \"trade\":\n",
    "                    yield x,e,y_trade_b,y_dir_b,er\n",
    "                else:\n",
    "                    # положить y_dir в slot y_trade_b\n",
    "                    yield x,e,y_dir_b,y_dir_b,er\n",
    "\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, wrap_loader_for_stage(va_loader, stage_name), loss_fn\n",
    "        )\n",
    "\n",
    "        score = va_f1m  # минимально и стабильно\n",
    "        sch.step(score)\n",
    "\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "        print(f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} tr={tr_loss:.4f} va={va_loss:.4f} f1m={va_f1m:.3f} auc={va_auc:.3f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(\n",
    "        model, wrap_loader_for_stage(te_loader, stage_name), loss_fn\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": best_score,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_f1m\": te_f1m,\n",
    "        \"test_auc\": te_auc,\n",
    "        \"test_cm\": te_cm,\n",
    "        \"hist\": hist,\n",
    "        \"test_y\": te_y,\n",
    "        \"test_prob\": te_prob,\n",
    "        \"test_er\": te_er,\n",
    "    }\n",
    "    return model, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: PnL по порогам уверенности (two-stage)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade,          # (N,2) softmax: [:,1]=p_trade\n",
    "    prob_dir,            # (N,2) softmax: [:,1]=p_up\n",
    "    exit_ret,            # (N,) realized log-ret to TB exit\n",
    "    thr_trade: float,\n",
    "    thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:,1]\n",
    "    p_up = prob_dir[:,1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (cost_bps * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(exit_ret),\n",
    "        \"n_trades\": int(trade_mask.sum()),\n",
    "        \"trade_rate\": float(trade_mask.mean()),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg):\n",
    "    rows = []\n",
    "    for thr_t in cfg[\"thr_trade_grid\"]:\n",
    "        for thr_d in cfg[\"thr_dir_grid\"]:\n",
    "            m = two_stage_pnl_by_threshold(\n",
    "                prob_trade=prob_trade,\n",
    "                prob_dir=prob_dir,\n",
    "                exit_ret=exit_ret,\n",
    "                thr_trade=thr_t,\n",
    "                thr_dir=thr_d,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "            )\n",
    "            rows.append({\"thr_trade\":thr_t, \"thr_dir\":thr_d, **m})\n",
    "    return pd.DataFrame(rows).sort_values([\"pnl_mean\",\"pnl_sum\"], ascending=False)\n",
    "\n",
    "print(\"Two-stage PnL threshold utils ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1653 330 330\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.7941 va=0.2110 f1m=0.488 auc=0.577\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.4164 va=0.1861 f1m=0.488 auc=0.563\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.3996 va=0.2017 f1m=0.488 auc=0.600\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.3946 va=0.1988 f1m=0.488 auc=0.607\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.3810 va=0.1894 f1m=0.488 auc=0.600\n",
      "[trade] ep 06 lr=1.00e-04 tr=0.3837 va=0.1946 f1m=0.488 auc=0.637\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.3721 va=0.1906 f1m=0.488 auc=0.649\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.3707 va=0.1847 f1m=0.488 auc=0.646\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.3595 va=0.1879 f1m=0.488 auc=0.646\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.8666 va=0.7063 f1m=0.519 auc=0.501\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7650 va=0.7112 f1m=0.532 auc=0.537\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7374 va=0.6898 f1m=0.518 auc=0.534\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.7258 va=0.6943 f1m=0.510 auc=0.536\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.7091 va=0.6832 f1m=0.479 auc=0.530\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6900 va=0.6834 f1m=0.489 auc=0.529\n",
      "[dir] ep 07 lr=1.00e-04 tr=0.6888 va=0.6869 f1m=0.495 auc=0.519\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6797 va=0.6841 f1m=0.479 auc=0.522\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.6673 va=0.6853 f1m=0.478 auc=0.525\n",
      "[dir] ep 10 lr=1.00e-04 tr=0.6724 va=0.6813 f1m=0.500 auc=0.532\n",
      "Best PnL on test: | thr_trade= 0.5 | thr_dir= 0.55 | pnl_mean= 0.00034066682565025985 | trades= 216.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1983 330 330\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.5067 va=0.1046 f1m=0.495 auc=0.339\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.3934 va=0.1354 f1m=0.495 auc=0.568\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.3678 va=0.1056 f1m=0.495 auc=0.607\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.3592 va=0.1063 f1m=0.495 auc=0.660\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.3587 va=0.1133 f1m=0.495 auc=0.685\n",
      "[trade] ep 06 lr=1.00e-04 tr=0.3449 va=0.1007 f1m=0.495 auc=0.710\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.3456 va=0.1072 f1m=0.495 auc=0.715\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.3467 va=0.1043 f1m=0.495 auc=0.693\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.3273 va=0.1033 f1m=0.495 auc=0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dir] ep 01 lr=2.00e-04 tr=0.7593 va=0.7051 f1m=0.456 auc=0.498\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7248 va=0.6923 f1m=0.447 auc=0.511\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7005 va=0.6917 f1m=0.406 auc=0.483\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.6845 va=0.6908 f1m=0.412 auc=0.488\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6727 va=0.6875 f1m=0.453 auc=0.509\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6819 va=0.6916 f1m=0.481 auc=0.493\n",
      "[dir] ep 07 lr=2.00e-04 tr=0.6785 va=0.6979 f1m=0.476 auc=0.489\n",
      "[dir] ep 08 lr=2.00e-04 tr=0.6746 va=0.6961 f1m=0.475 auc=0.491\n",
      "[dir] ep 09 lr=2.00e-04 tr=0.6701 va=0.6933 f1m=0.493 auc=0.496\n",
      "[dir] ep 10 lr=2.00e-04 tr=0.6590 va=0.6992 f1m=0.470 auc=0.495\n",
      "[dir] ep 11 lr=2.00e-04 tr=0.6532 va=0.7013 f1m=0.487 auc=0.494\n",
      "[dir] ep 12 lr=2.00e-04 tr=0.6594 va=0.7019 f1m=0.502 auc=0.501\n",
      "[dir] ep 13 lr=2.00e-04 tr=0.6523 va=0.7129 f1m=0.474 auc=0.487\n",
      "[dir] ep 14 lr=2.00e-04 tr=0.6413 va=0.7183 f1m=0.486 auc=0.494\n",
      "[dir] ep 15 lr=2.00e-04 tr=0.6400 va=0.7228 f1m=0.479 auc=0.509\n",
      "[dir] ep 16 lr=2.00e-04 tr=0.6402 va=0.7204 f1m=0.468 auc=0.504\n",
      "[dir] ep 17 lr=1.00e-04 tr=0.6331 va=0.7158 f1m=0.482 auc=0.502\n",
      "[dir] ep 18 lr=1.00e-04 tr=0.6164 va=0.7250 f1m=0.476 auc=0.508\n",
      "[dir] ep 19 lr=1.00e-04 tr=0.6203 va=0.7302 f1m=0.475 auc=0.510\n",
      "[dir] ep 20 lr=1.00e-04 tr=0.6081 va=0.7355 f1m=0.500 auc=0.499\n",
      "Best PnL on test: | thr_trade= 0.5 | thr_dir= 0.7 | pnl_mean= -0.0002580495784059167 | trades= 60.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 2313 330 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr=0.5011 va=0.0292 f1m=1.000 auc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 02 lr=2.00e-04 tr=0.3366 va=0.0430 f1m=1.000 auc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 03 lr=2.00e-04 tr=0.3293 va=0.0318 f1m=1.000 auc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 04 lr=2.00e-04 tr=0.3207 va=0.0363 f1m=1.000 auc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 05 lr=2.00e-04 tr=0.3035 va=0.0279 f1m=1.000 auc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 06 lr=1.00e-04 tr=0.3083 va=0.0291 f1m=1.000 auc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 07 lr=1.00e-04 tr=0.3040 va=0.0234 f1m=1.000 auc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 08 lr=1.00e-04 tr=0.2980 va=0.0237 f1m=1.000 auc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 09 lr=1.00e-04 tr=0.2896 va=0.0255 f1m=1.000 auc=nan\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.7840 va=0.7333 f1m=0.447 auc=0.454\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7215 va=0.7060 f1m=0.520 auc=0.522\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7088 va=0.7004 f1m=0.544 auc=0.531\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.7003 va=0.7066 f1m=0.514 auc=0.522\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6810 va=0.7027 f1m=0.530 auc=0.524\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6793 va=0.7146 f1m=0.500 auc=0.503\n",
      "[dir] ep 07 lr=2.00e-04 tr=0.6804 va=0.7208 f1m=0.499 auc=0.495\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6753 va=0.7283 f1m=0.513 auc=0.479\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.6646 va=0.7238 f1m=0.513 auc=0.491\n",
      "[dir] ep 10 lr=1.00e-04 tr=0.6701 va=0.7205 f1m=0.512 auc=0.500\n",
      "[dir] ep 11 lr=1.00e-04 tr=0.6576 va=0.7190 f1m=0.509 auc=0.504\n",
      "Best PnL on test: | thr_trade= 0.5 | thr_dir= 0.7 | pnl_mean= -0.00010295433457940817 | trades= 17.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 2643 330 330\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.3485 va=0.1929 f1m=0.487 auc=0.730\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.3046 va=0.1855 f1m=0.487 auc=0.732\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.2875 va=0.1869 f1m=0.487 auc=0.743\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.2842 va=0.1920 f1m=0.487 auc=0.721\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.2846 va=0.1858 f1m=0.487 auc=0.747\n",
      "[trade] ep 06 lr=1.00e-04 tr=0.2739 va=0.1866 f1m=0.487 auc=0.740\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.2662 va=0.1923 f1m=0.487 auc=0.725\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.2636 va=0.1880 f1m=0.487 auc=0.740\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.2611 va=0.1894 f1m=0.487 auc=0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dir] ep 01 lr=2.00e-04 tr=0.8126 va=0.7326 f1m=0.476 auc=0.551\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7380 va=0.7414 f1m=0.472 auc=0.559\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7235 va=0.7114 f1m=0.527 auc=0.554\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.7175 va=0.7289 f1m=0.480 auc=0.547\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.7012 va=0.7138 f1m=0.524 auc=0.561\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6960 va=0.7107 f1m=0.518 auc=0.545\n",
      "[dir] ep 07 lr=2.00e-04 tr=0.6822 va=0.7194 f1m=0.505 auc=0.533\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6765 va=0.7042 f1m=0.517 auc=0.559\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.6757 va=0.7237 f1m=0.520 auc=0.539\n",
      "[dir] ep 10 lr=1.00e-04 tr=0.6712 va=0.7206 f1m=0.508 auc=0.536\n",
      "[dir] ep 11 lr=1.00e-04 tr=0.6708 va=0.7331 f1m=0.514 auc=0.529\n",
      "Best PnL on test: | thr_trade= 0.5 | thr_dir= 0.55 | pnl_mean= 0.0001443785586161539 | trades= 181.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.550202</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.429379</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.486781</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.051515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.524323</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.548485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.495413      0.550202       0.000341             0.5   \n",
       "1     2        1.000000      0.429379      -0.000258             0.5   \n",
       "2     3        0.486781      0.490682      -0.000103             0.5   \n",
       "3     4        1.000000      0.524323       0.000144             0.5   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0          0.55          216.0         0.654545  \n",
       "1          0.70           60.0         0.181818  \n",
       "2          0.70           17.0         0.051515  \n",
       "3          0.55          181.0         0.548485  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "fold                 2.500000\n",
      "trade_test_f1m       0.745548\n",
      "dir_test_f1m         0.498647\n",
      "best_pnl_mean        0.000031\n",
      "best_thr_trade       0.500000\n",
      "best_thr_dir         0.625000\n",
      "n_trades_best      118.500000\n",
      "trade_rate_best      0.359091\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\"\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    # если в какой-то части trade почти нет — пропускаем fold direction\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\"\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on TEST (в sample-space idx_te)\n",
    "    # Получим probs trade на idx_te (из r_trade) и probs dir на idx_te тоже нужно.\n",
    "    # r_dir тестился на idx_te_T, поэтому мы посчитаем prob_dir на idx_te через прогон модели по idx_te (без фильтра),\n",
    "    # чтобы sweep был по всем точкам (trade-маска будет от модели trade).\n",
    "\n",
    "    # helper: get probs on arbitrary indices\n",
    "    @torch.no_grad()\n",
    "    def predict_probs_on_indices(model, X_scaled, edge_feat, indices, stage_for_label=\"trade\"):\n",
    "        ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, CFG[\"lookback\"])\n",
    "        loader = DataLoader(ds, batch_size=CFG[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "        model.eval()\n",
    "        probs = []\n",
    "        ers = []\n",
    "        for x,e,yt,yd,er in loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            logits = model(x,e,EDGE_INDEX.to(DEVICE))\n",
    "            p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            probs.append(p)\n",
    "            ers.append(er.cpu().numpy())\n",
    "        return np.concatenate(probs), np.concatenate(ers)\n",
    "\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te)\n",
    "    prob_dir_te, _ = predict_probs_on_indices(m_dir, X_scaled, edge_feat, idx_te)\n",
    "\n",
    "    # exit_ret on same points (already in er_te)\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"Best PnL on test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN:\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
