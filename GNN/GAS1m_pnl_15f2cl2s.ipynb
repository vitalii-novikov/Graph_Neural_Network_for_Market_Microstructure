{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX (with self-loops): [[0, 1], [0, 2], [2, 1], [0, 0], [1, 1], [2, 2]]\n",
      "CFG thresholds updated.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"1min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),  \n",
    "    # NEW: holdout final test split (по времени, на sample-space)\n",
    "    \"final_test_frac\": 0.10, \n",
    "\n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6*5, 12*5, 24*5, 48*5, 84*5],  # 30m,1h,2h,4h,7h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 1*15,       # 15 min\n",
    "    \"lookback\": 5*12*5,       # 5 hours\n",
    "    \"tb_pt_mult\": 1.2,\n",
    "    \"tb_sl_mult\": 1.1,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "    # training (общие)\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.25,\n",
    "    \"hidden\": 128,\n",
    "    \"gnn_layers\": 3,\n",
    "    \"lstm_hidden\": 128,\n",
    "    \"lstm_layers\": 2,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 1.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "\n",
    "    \"proxy_min_trades\": 20,        # защита от \"лучший pnl = 0 потому что 0 трейдов\"\n",
    "\n",
    "        # --- GAT (spatial)\n",
    "    \"gat_heads\": 2,          # попробуй 1/2/4 (hidden не обязан делиться идеально)\n",
    "\n",
    "    # --- TCN (temporal)\n",
    "    \"tcn_channels\": 128,      # ширина temporal-канала\n",
    "    \"tcn_layers\": 3,         # число residual TCN блоков\n",
    "    \"tcn_kernel\": 2,         # kernel size\n",
    "    \"tcn_dropout\": 0.25,      # обычно = CFG[\"dropout\"]\n",
    "    \"tcn_causal\": True,      # True = no leakage (рекомендуется)\n",
    "    \"tcn_pool\": \"mean\",      # \"last\" или \"mean\"\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "\n",
    "def add_self_loops_edge_index(edge_index: torch.Tensor, num_nodes: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    edge_index: (E,2) [src,dst]\n",
    "    returns: (E+N,2) with added (i,i)\n",
    "    \"\"\"\n",
    "    loops = torch.arange(num_nodes, dtype=edge_index.dtype).view(-1, 1)\n",
    "    loops = torch.cat([loops, loops], dim=1)  # (N,2) i->i\n",
    "    return torch.cat([edge_index, loops], dim=0)\n",
    "\n",
    "EDGE_INDEX = add_self_loops_edge_index(EDGE_INDEX, num_nodes=len(ASSETS))\n",
    "print(\"EDGE_INDEX (with self-loops):\", EDGE_INDEX.tolist())\n",
    "\n",
    "CFG[\"thr_trade_grid\"] = [ 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "CFG[\"thr_dir_grid\"]   = [0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "\n",
    "# 2) минимальное число сделок, которое мы хотим ВЫНУЖДАТЬ при выборе порогов\n",
    "CFG[\"eval_min_trades\"] = 50           # применяется в sweep на test/val/holdout\n",
    "CFG[\"proxy_min_trades\"] = 100          # оставляем как было, но теперь реально достижимо\n",
    "\n",
    "# 3) динамические целевые уровни сделок (чтобы пороги подстраивались под распределение p_trade)\n",
    "CFG[\"proxy_target_trades\"] = [50, 100]  # будет превращено в пороги по квантилям\n",
    "\n",
    "# 4) что оптимизируем на сетке: pnl_sum обычно стабильнее чем pnl_mean\n",
    "CFG[\"pnl_objective\"] = \"pnl_sum\"      # \"pnl_mean\" тоже можно\n",
    "print(\"CFG thresholds updated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (13687, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int, part = [0,100]) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.iloc[int(len(df)*part[0]/100) : int(len(df)*part[1]/100)]\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels, part = [0, 80]), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels, part = [0, 80]), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels, part = [0, 80]), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (13687, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [2571 8969 2147]\n",
      "Trade ratio: 0.34470665595090233\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=CFG[\"tb_horizon\"], \n",
    "    vol_window=CFG[\"lookback\"],\n",
    "    pt_mult=CFG[\"tb_pt_mult\"],\n",
    "    sl_mult=CFG[\"tb_sl_mult\"],\n",
    "    min_barrier=CFG[\"tb_min_barrier\"],\n",
    "    max_barrier=CFG[\"tb_max_barrier\"],\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (13687, 3, 15) edge_feat: (13687, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 13372 t range: 299 13670\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb5de4",
   "metadata": {},
   "source": [
    "## Train (folds) - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9bad799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout split:\n",
      "  n_samples total: 13372\n",
      "  n_samples CV   : 12035 (90.0%)\n",
      "  n_samples FINAL: 1337 (10.0%)\n",
      "  CV range   : 0 12034\n",
      "  FINAL range: 12035 13371\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: final holdout split (90% CV + 10% final test), time-ordered\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_final_holdout_split(n_samples: int, final_test_frac: float):\n",
    "    if not (0.0 < final_test_frac < 0.5):\n",
    "        raise ValueError(\"final_test_frac should be in (0, 0.5)\")\n",
    "\n",
    "    n_final = max(1, int(round(final_test_frac * n_samples)))\n",
    "    n_cv = n_samples - n_final\n",
    "    if n_cv <= 10:\n",
    "        raise ValueError(\"Too few samples left for CV after holdout split.\")\n",
    "\n",
    "    idx_cv = np.arange(0, n_cv, dtype=np.int64)\n",
    "    idx_final = np.arange(n_cv, n_samples, dtype=np.int64)\n",
    "    return idx_cv, idx_final, n_cv, n_final\n",
    "\n",
    "idx_cv_all, idx_final_test, n_samples_cv, n_samples_final = make_final_holdout_split(\n",
    "    n_samples=n_samples,\n",
    "    final_test_frac=CFG[\"final_test_frac\"],\n",
    ")\n",
    "\n",
    "print(\"Holdout split:\")\n",
    "print(\"  n_samples total:\", n_samples)\n",
    "print(\"  n_samples CV   :\", n_samples_cv, f\"({100*(n_samples_cv/n_samples):.1f}%)\")\n",
    "print(\"  n_samples FINAL:\", n_samples_final, f\"({100*(n_samples_final/n_samples):.1f}%)\")\n",
    "print(\"  CV range   :\", idx_cv_all[0], idx_cv_all[-1])\n",
    "print(\"  FINAL range:\", idx_final_test[0], idx_final_test[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 6017 | val 1203 | test 1203\n",
      " fold 2: train 7220 | val 1203 | test 1203\n",
      " fold 3: train 8423 | val 1203 | test 1203\n",
      " fold 4: train 9626 | val 1203 | test 1203\n",
      "\n",
      "FINAL HOLDOUT:\n",
      " final_test size: 1337\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test) on CV-part only\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "\n",
    "        idx_train = np.arange(0, tr_end, dtype=np.int64)\n",
    "        idx_val   = np.arange(tr_end, va_end, dtype=np.int64)\n",
    "        idx_test  = np.arange(va_end, te_end, dtype=np.int64)\n",
    "\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "\n",
    "    return splits\n",
    "\n",
    "# IMPORTANT: строим сплиты только на 90% (CV-part)\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples_cv,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "for i, (a, b, c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT:\")\n",
    "print(\" final_test size:\", len(idx_final_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready. logits: torch.Size([4, 2]) finite: True\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: SGA-TCN model (drop-in replacement for GNN_LSTM_Classifier)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "\n",
    "\n",
    "# ЛОГИЧЕСКИЙ БЛОК: SpatialGraphAttention with self-loop edge_attr padding\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class SpatialGraphAttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention with edge_attr in attention scorer:\n",
    "      score_e = a^T [h_src || h_dst || edge_emb]\n",
    "      attn normalized per-dst over incoming edges\n",
    "      msg = W_msg(h_src)\n",
    "      agg_dst = sum(attn * msg)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, out_dim: int, edge_dim: int, heads: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.heads = max(1, int(heads))\n",
    "        self.dropout = float(dropout)\n",
    "\n",
    "        self.head_dim = max(1, int(math.ceil(out_dim / self.heads)))\n",
    "        self.inner_dim = self.heads * self.head_dim\n",
    "\n",
    "        self.lin_node = nn.Linear(in_dim, self.inner_dim, bias=False)\n",
    "        self.lin_edge = nn.Linear(edge_dim, self.inner_dim, bias=False)\n",
    "        self.lin_msg  = nn.Linear(self.inner_dim, self.inner_dim, bias=False)\n",
    "\n",
    "        self.attn_vec = nn.Parameter(torch.empty(self.heads, 3 * self.head_dim))\n",
    "\n",
    "        self.out_proj = nn.Linear(self.inner_dim, out_dim, bias=False)\n",
    "        self.res_proj = nn.Identity() if in_dim == out_dim else nn.Linear(in_dim, out_dim, bias=False)\n",
    "\n",
    "        self.ln = nn.LayerNorm(out_dim)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.out_drop = nn.Dropout(dropout)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in [self.lin_node, self.lin_edge, self.lin_msg, self.out_proj]:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if isinstance(self.res_proj, nn.Linear):\n",
    "            nn.init.xavier_uniform_(self.res_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_vec)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_attr: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x:         (B,N,Fin)\n",
    "        edge_attr: (B,E_attr,W)  (может быть меньше чем E_index из-за self-loops)\n",
    "        edge_index:(E_index,2)   includes self-loops\n",
    "        returns:   (B,N,out_dim)\n",
    "        \"\"\"\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        edge_attr = torch.nan_to_num(edge_attr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        B, N, _ = x.shape\n",
    "        E_index = edge_index.shape[0]\n",
    "        E_attr = edge_attr.shape[1]\n",
    "        W = edge_attr.shape[2]\n",
    "\n",
    "        # --- pad edge_attr with zeros for self-loops if needed\n",
    "        if E_attr < E_index:\n",
    "            pad = torch.zeros((B, E_index - E_attr, W), device=edge_attr.device, dtype=edge_attr.dtype)\n",
    "            edge_attr = torch.cat([edge_attr, pad], dim=1)\n",
    "        elif E_attr > E_index:\n",
    "            edge_attr = edge_attr[:, :E_index, :]\n",
    "\n",
    "        src_idx = edge_index[:, 0]\n",
    "        dst_idx = edge_index[:, 1]\n",
    "\n",
    "        h = self.lin_node(x)  # (B,N,inner)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        h = h.view(B, N, self.heads, self.head_dim)\n",
    "\n",
    "        eemb = self.lin_edge(edge_attr)  # (B,E,inner)\n",
    "        eemb = torch.nan_to_num(eemb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        eemb = eemb.view(B, E_index, self.heads, self.head_dim)\n",
    "\n",
    "        h_src = h[:, src_idx, :, :]  # (B,E,heads,dh)\n",
    "        h_dst = h[:, dst_idx, :, :]  # (B,E,heads,dh)\n",
    "\n",
    "        cat = torch.cat([h_src, h_dst, eemb], dim=-1)  # (B,E,heads,3*dh)\n",
    "        scores = (cat * self.attn_vec[None, None, :, :]).sum(dim=-1)  # (B,E,heads)\n",
    "        scores = self.act(scores)\n",
    "\n",
    "        alphas = torch.zeros_like(scores)  # (B,E,heads)\n",
    "        for n in range(N):\n",
    "            mask = (dst_idx == n)\n",
    "            if int(mask.sum()) == 0:\n",
    "                continue\n",
    "            s = scores[:, mask, :]\n",
    "            a = torch.softmax(s, dim=1)\n",
    "            a = self.attn_drop(a)\n",
    "            alphas[:, mask, :] = a\n",
    "\n",
    "        msg = self.lin_msg(h_src.reshape(B, E_index, self.inner_dim)).view(B, E_index, self.heads, self.head_dim)\n",
    "\n",
    "        agg = torch.zeros((B, N, self.heads, self.head_dim), device=x.device, dtype=x.dtype)\n",
    "        for e_i in range(E_index):\n",
    "            dst = int(dst_idx[e_i].item())\n",
    "            agg[:, dst, :, :] += alphas[:, e_i, :].unsqueeze(-1) * msg[:, e_i, :, :]\n",
    "\n",
    "        out = agg.reshape(B, N, self.inner_dim)\n",
    "        out = self.out_proj(out)\n",
    "        out = self.out_drop(out)\n",
    "\n",
    "        res = self.res_proj(x)\n",
    "        y = self.ln(res + out)\n",
    "        return torch.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "class SpatialGraphAttentionMP(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies SpatialGraphAttentionLayer independently at each timestep t:\n",
    "      x_seq: (B,L,N,F) -> h_seq: (B,L,N,H)\n",
    "\n",
    "    Handles edge_attr padding if EDGE_INDEX includes self-loops but e_seq doesn't.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, hidden: int, edge_dim: int, heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.gat = SpatialGraphAttentionLayer(in_dim=in_dim, out_dim=hidden, edge_dim=edge_dim, heads=heads, dropout=dropout)\n",
    "\n",
    "    def forward_once(self, x_t: torch.Tensor, edge_attr_t: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        return self.gat(x_t, edge_attr_t, edge_index)\n",
    "\n",
    "    def forward(self, x_seq: torch.Tensor, e_seq: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        B, L, N, F = x_seq.shape\n",
    "        x_flat = x_seq.reshape(B*L, N, F)        # (B*L,N,F)\n",
    "        e_flat = e_seq.reshape(B*L, e_seq.size(2), e_seq.size(3))  # (B*L,E,W)\n",
    "\n",
    "        h_flat = self.gat(x_flat, e_flat, edge_index)  # (B*L,N,H)\n",
    "        h_seq  = h_flat.reshape(B, L, N, -1)\n",
    "        return h_seq\n",
    "\n",
    "\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"Causal Conv1d: pads only on the left => no future leakage.\"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, dilation: int = 1):\n",
    "        super().__init__()\n",
    "        self.kernel_size = int(kernel_size)\n",
    "        self.dilation = int(dilation)\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=self.kernel_size, dilation=self.dilation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,C,L)\n",
    "        pad_left = (self.kernel_size - 1) * self.dilation\n",
    "        x = F.pad(x, (pad_left, 0))\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, dilation: int, dropout: float, causal: bool = True):\n",
    "        super().__init__()\n",
    "        self.causal = bool(causal)\n",
    "\n",
    "        if self.causal:\n",
    "            conv1 = CausalConv1d(in_ch, out_ch, kernel_size, dilation=dilation)\n",
    "            conv2 = CausalConv1d(out_ch, out_ch, kernel_size, dilation=dilation)\n",
    "        else:\n",
    "            # non-causal WITHOUT future leakage is tricky; safest is causal=True.\n",
    "            # If you set causal=False, consider it \"experimental\".\n",
    "            pad = ((kernel_size - 1) * dilation) // 2\n",
    "            conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, dilation=dilation, padding=pad)\n",
    "            conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, dilation=dilation, padding=pad)\n",
    "\n",
    "        self.conv1 = conv1\n",
    "        self.conv2 = conv2\n",
    "\n",
    "        self.act = nn.GELU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Identity() if in_ch == out_ch else nn.Conv1d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv1d,)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,C,L)\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        y = self.conv1(x)\n",
    "        y = self.act(y)\n",
    "        y = self.drop(y)\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        y = self.act(y)\n",
    "        y = self.drop(y)\n",
    "\n",
    "        res = self.downsample(x)\n",
    "        out = self.act(y + res)\n",
    "        return torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, in_ch: int, channels: list[int], kernel_size: int, dropout: float, causal: bool = True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i, out_ch in enumerate(channels):\n",
    "            dilation = 2 ** i\n",
    "            layers.append(\n",
    "                TemporalBlock(\n",
    "                    in_ch=in_ch,\n",
    "                    out_ch=out_ch,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=dilation,\n",
    "                    dropout=dropout,\n",
    "                    causal=causal,\n",
    "                )\n",
    "            )\n",
    "            in_ch = out_ch\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    DROP-IN replacement:\n",
    "      input:  x_seq (B,L,N,F), e_seq (B,L,E,W), edge_index (E,2)\n",
    "      output: logits (B,2)\n",
    "\n",
    "    Internally это SGA-TCN:\n",
    "      - Spatial: Graph Attention per timestep (edge_attr in scorer)\n",
    "      - Temporal: TCN on target_node sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = int(target_node)\n",
    "\n",
    "        # --- read new params from global CFG (fallback to reasonable defaults)\n",
    "        _cfg = globals().get(\"CFG\", {})\n",
    "        gat_heads = int(_cfg.get(\"gat_heads\", 1))\n",
    "\n",
    "        tcn_channels = int(_cfg.get(\"tcn_channels\", hidden))\n",
    "        tcn_layers_n = int(_cfg.get(\"tcn_layers\", 4))\n",
    "        tcn_kernel = int(_cfg.get(\"tcn_kernel\", 3))\n",
    "        tcn_dropout = float(_cfg.get(\"tcn_dropout\", dropout))\n",
    "        tcn_causal = bool(_cfg.get(\"tcn_causal\", True))\n",
    "        tcn_pool = str(_cfg.get(\"tcn_pool\", \"last\"))\n",
    "\n",
    "        self.tcn_pool = tcn_pool\n",
    "\n",
    "        # --- spatial stack\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(int(gnn_layers)):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(\n",
    "                SpatialGraphAttentionMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, heads=gat_heads, dropout=dropout)\n",
    "            )\n",
    "\n",
    "        # --- temporal TCN\n",
    "        self.tcn_in = nn.Linear(hidden, tcn_channels)\n",
    "        self.tcn = TemporalConvNet(\n",
    "            in_ch=tcn_channels,\n",
    "            channels=[tcn_channels] * tcn_layers_n,\n",
    "            kernel_size=tcn_kernel,\n",
    "            dropout=tcn_dropout,\n",
    "            causal=tcn_causal,\n",
    "        )\n",
    "\n",
    "        # --- head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(tcn_channels),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(tcn_channels, tcn_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(tcn_channels, n_classes),\n",
    "        )\n",
    "\n",
    "        # init linears\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        e = torch.nan_to_num(e, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        h_tgt = torch.nan_to_num(h_tgt, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        z = self.tcn_in(h_tgt)          # (B,L,C)\n",
    "        z = torch.nan_to_num(z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        z = z.transpose(1, 2)           # (B,C,L)\n",
    "\n",
    "        y = self.tcn(z)                 # (B,C,L)\n",
    "\n",
    "        if self.tcn_pool == \"mean\":\n",
    "            emb = y.mean(dim=-1)        # (B,C)\n",
    "        else:\n",
    "            emb = y[:, :, -1]           # (B,C) safe for causal\n",
    "\n",
    "        logits = self.head(emb)         # (B,2)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "# ---- quick sanity check (shape + no NaNs)\n",
    "B, L, N, Fdim = 4, CFG[\"lookback\"], 3, X_node_raw.shape[-1]\n",
    "E = EDGE_INDEX.shape[0]\n",
    "W = edge_feat.shape[-1]\n",
    "\n",
    "x_dummy = torch.randn(B, L, N, Fdim)\n",
    "e_dummy = torch.randn(B, L, E, W)\n",
    "\n",
    "m = GNN_LSTM_Classifier(\n",
    "    node_in=Fdim,\n",
    "    edge_dim=W,\n",
    "    hidden=CFG[\"hidden\"],\n",
    "    gnn_layers=CFG[\"gnn_layers\"],\n",
    "    lstm_hidden=CFG[\"lstm_hidden\"],   # ignored (compat)\n",
    "    lstm_layers=CFG[\"lstm_layers\"],   # ignored (compat)\n",
    "    dropout=CFG[\"dropout\"],\n",
    "    target_node=TARGET_NODE,\n",
    "    n_classes=2\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = m(x_dummy, e_dummy, EDGE_INDEX)\n",
    "print(\"Model ready. logits:\", out.shape, \"finite:\", torch.isfinite(out).all().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn, y_key: str = \"trade\"):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        y = (y_trade_b if y_key == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "\n",
    "    ys = np.concatenate(ys) if len(ys) else np.array([], dtype=np.int64)\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, None, ys, probs, ers\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:, 1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss / max(n, 1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_only(model, loader):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "    return probs, ers\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps, min_trades: int = 0):\n",
    "    \"\"\"\n",
    "    Возвращает лучший pnl_mean по grid (per-bar), плюс пороги и статистику.\n",
    "    min_trades используется как фильтр: комбинации, где сделок меньше, пропускаются.\n",
    "    Если ни одна комбинация не прошла min_trades — вернём best без фильтра (но это будет fallback-сценарий).\n",
    "    \"\"\"\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    sign = np.where(p_up >= 0.5, 1.0, -1.0).astype(np.float32)\n",
    "    cost = float(cost_bps) * 1e-4\n",
    "    N = len(exit_ret)\n",
    "\n",
    "    best = {\n",
    "        \"pnl_mean\": -1e18,\n",
    "        \"pnl_sum\": -1e18,\n",
    "        \"thr_trade\": None,\n",
    "        \"thr_dir\": None,\n",
    "        \"n_trades\": 0,\n",
    "        \"trade_rate\": 0.0,\n",
    "        \"min_trades_used\": int(min_trades),\n",
    "        \"passed_min_trades\": False,\n",
    "    }\n",
    "\n",
    "    # 1) строгий проход (>=min_trades)\n",
    "    for thr_t in thr_trade_grid:\n",
    "        mt = (p_trade >= thr_t)\n",
    "        for thr_d in thr_dir_grid:\n",
    "            mask = mt & (conf_dir >= thr_d)\n",
    "            n_tr = int(mask.sum())\n",
    "            if n_tr < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "            pnl_sum = float(pnl.sum())\n",
    "            pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "            if pnl_mean > best[\"pnl_mean\"]:\n",
    "                best.update({\n",
    "                    \"pnl_mean\": pnl_mean,\n",
    "                    \"pnl_sum\": pnl_sum,\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": n_tr,\n",
    "                    \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                    \"passed_min_trades\": True,\n",
    "                })\n",
    "\n",
    "    # 2) если ничего не прошло min_trades — найдём best без фильтра (для fallback-логов)\n",
    "    if best[\"thr_trade\"] is None:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            mt = (p_trade >= thr_t)\n",
    "            for thr_d in thr_dir_grid:\n",
    "                mask = mt & (conf_dir >= thr_d)\n",
    "                n_tr = int(mask.sum())\n",
    "                pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "                pnl_sum = float(pnl.sum())\n",
    "                pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "                if pnl_mean > best[\"pnl_mean\"]:\n",
    "                    best.update({\n",
    "                        \"pnl_mean\": pnl_mean,\n",
    "                        \"pnl_sum\": pnl_sum,\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": n_tr,\n",
    "                        \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def _make_ce_weights_binary(y_np: np.ndarray) -> torch.Tensor:\n",
    "    y_np = np.asarray(y_np, dtype=np.int64)\n",
    "    counts = np.bincount(y_np, minlength=2).astype(np.float64)\n",
    "    counts = np.maximum(counts, 1.0)\n",
    "    w = counts.sum() / (2.0 * counts)  # inverse freq\n",
    "    return torch.tensor(w, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "    select_metric: str | None = None,        # \"va_auc\" | \"va_f1m\" | \"va_pnl_max\"\n",
    "    trade_model_for_pnl=None,\n",
    "    idx_val_pnl=None,\n",
    "):\n",
    "    if select_metric is None:\n",
    "        select_metric = \"va_auc\"\n",
    "    if select_metric not in (\"va_auc\", \"va_f1m\", \"va_pnl_max\"):\n",
    "        raise ValueError(\"select_metric must be one of: 'va_auc', 'va_f1m', 'va_pnl_max'\")\n",
    "\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if stage_name != \"dir\":\n",
    "            raise ValueError(\"select_metric='va_pnl_max' supported only for stage_name='dir'\")\n",
    "        if trade_model_for_pnl is None or idx_val_pnl is None:\n",
    "            raise ValueError(\"For va_pnl_max you must pass trade_model_for_pnl and idx_val_pnl.\")\n",
    "\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val,   L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test,  L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True,  drop_last=False, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    va_pnl_loader = None\n",
    "    if stage_name == \"dir\" and (idx_val_pnl is not None):\n",
    "        va_pnl_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val_pnl, L)\n",
    "        va_pnl_loader = DataLoader(va_pnl_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # --- class weights (делает обучение стабильнее на фолдах)\n",
    "    t_train = sample_t[idx_train]\n",
    "    y_train_np = (y_trade_arr[t_train] if stage_name == \"trade\" else y_dir_arr[t_train]).astype(np.int64)\n",
    "    ce_w = _make_ce_weights_binary(y_train_np)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=ce_w)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\"))\n",
    "\n",
    "    # --- trade probs на полном val для PnL proxy (считаем 1 раз)\n",
    "    prob_trade_val_pnl = None\n",
    "    if stage_name == \"dir\" and (trade_model_for_pnl is not None) and (va_pnl_loader is not None):\n",
    "        prob_trade_val_pnl, _ = predict_probs_only(trade_model_for_pnl, va_pnl_loader)\n",
    "        debug_trade_prob_stats(prob_trade_val_pnl, title=\"val_pnl (for dir selector)\")\n",
    "\n",
    "    # --- proxy grids (ВАЖНО: делаем thr_trade_grid динамической!)\n",
    "    proxy_min_trades = int(cfg.get(\"proxy_min_trades\", 0))\n",
    "    objective = str(cfg.get(\"pnl_objective\", \"pnl_sum\"))\n",
    "    thr_dir_grid_proxy = cfg.get(\"thr_dir_grid\", [0.5])\n",
    "\n",
    "    if (stage_name == \"dir\") and (prob_trade_val_pnl is not None):\n",
    "        thr_trade_grid_proxy = build_trade_threshold_grid(\n",
    "            p_trade=prob_trade_val_pnl[:, 1],\n",
    "            base_grid=cfg.get(\"thr_trade_grid\", [0.5]),\n",
    "            target_trades_list=cfg.get(\"proxy_target_trades\", [proxy_min_trades]),\n",
    "            min_thr=0.01, max_thr=0.99\n",
    "        )\n",
    "    else:\n",
    "        thr_trade_grid_proxy = cfg.get(\"thr_trade_grid\", [0.5])\n",
    "\n",
    "    best_score = -1e18\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "    best_used = select_metric\n",
    "\n",
    "    best_score_auc = -1e18\n",
    "    best_state_auc = None\n",
    "    best_epoch_auc = -1\n",
    "\n",
    "    best_score_pnl = -1e18\n",
    "    best_state_pnl = None\n",
    "    best_epoch_pnl = -1\n",
    "    seen_pnl_ok = False\n",
    "\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\"tr_loss\": [], \"va_loss\": [], \"va_f1m\": [], \"va_auc\": [],\n",
    "            \"va_pnl_obj\": [], \"va_pnl_n_trades\": [], \"va_sel\": [], \"va_sel_mode\": []}\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"] + 1):\n",
    "        # ---- TRAIN\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for x, e, y_trade_b, y_dir_b, er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            y = (y_trade_b if stage_name == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot / max(n, 1)\n",
    "\n",
    "        # ---- VAL metrics\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, va_loader, loss_fn, y_key=stage_name\n",
    "        )\n",
    "\n",
    "        # ---- VAL PnL proxy (dir only)\n",
    "        va_pnl_best = {\"thr_trade\": np.nan, \"thr_dir\": np.nan, \"n_trades\": 0, \"trade_rate\": np.nan,\n",
    "                       \"pnl_sum\": np.nan, \"pnl_mean\": np.nan, \"pnl_per_trade\": np.nan,\n",
    "                       \"passed_min_trades\": False, \"min_trades_used\": proxy_min_trades}\n",
    "\n",
    "        if stage_name == \"dir\" and (prob_trade_val_pnl is not None) and (va_pnl_loader is not None):\n",
    "            prob_dir_val_pnl, er_dir_val_pnl = predict_probs_only(model, va_pnl_loader)\n",
    "\n",
    "            va_pnl_best = pnl_proxy_grid_max(\n",
    "                prob_trade=prob_trade_val_pnl,\n",
    "                prob_dir=prob_dir_val_pnl,\n",
    "                exit_ret=er_dir_val_pnl,\n",
    "                thr_trade_grid=thr_trade_grid_proxy,\n",
    "                thr_dir_grid=thr_dir_grid_proxy,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "                min_trades=proxy_min_trades,\n",
    "                objective=objective,\n",
    "            )\n",
    "\n",
    "        # ---- selection\n",
    "        sel_val = np.nan\n",
    "        sel_mode = select_metric\n",
    "\n",
    "        if select_metric in (\"va_auc\", \"va_f1m\"):\n",
    "            sel_val = (va_auc if select_metric == \"va_auc\" else va_f1m)\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "\n",
    "            if sel_val > best_score:\n",
    "                best_score = float(sel_val)\n",
    "                best_epoch = ep\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "        else:\n",
    "            # va_pnl_max with fallback\n",
    "            pnl_obj = float(va_pnl_best.get(objective, np.nan))\n",
    "            n_tr = int(va_pnl_best.get(\"n_trades\", 0))\n",
    "            pnl_ok = (np.isfinite(pnl_obj) and (n_tr >= proxy_min_trades))\n",
    "\n",
    "            # обновим best_auc\n",
    "            if np.isfinite(va_auc) and (float(va_auc) > best_score_auc):\n",
    "                best_score_auc = float(va_auc)\n",
    "                best_epoch_auc = ep\n",
    "                best_state_auc = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            # обновим best_pnl только если pnl_ok\n",
    "            if pnl_ok and (pnl_obj > best_score_pnl):\n",
    "                best_score_pnl = pnl_obj\n",
    "                best_epoch_pnl = ep\n",
    "                best_state_pnl = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            if pnl_ok:\n",
    "                seen_pnl_ok = True\n",
    "                sel_val = pnl_obj\n",
    "                sel_mode = f\"va_pnl_max({objective})\"\n",
    "            else:\n",
    "                sel_val = float(va_auc) if np.isfinite(va_auc) else -1e18\n",
    "                sel_mode = f\"va_auc_fallback({n_tr}/{proxy_min_trades})\"\n",
    "\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "            improved = False\n",
    "            if not seen_pnl_ok:\n",
    "                improved = (np.isfinite(va_auc) and (float(va_auc) >= best_score_auc))\n",
    "            else:\n",
    "                improved = pnl_ok and (pnl_obj >= best_score_pnl)\n",
    "\n",
    "            bad = 0 if improved else (bad + 1)\n",
    "\n",
    "        # ---- logs\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "        hist[\"va_pnl_obj\"].append(float(va_pnl_best.get(objective, np.nan)))\n",
    "        hist[\"va_pnl_n_trades\"].append(int(va_pnl_best.get(\"n_trades\", 0)))\n",
    "        hist[\"va_sel\"].append(float(sel_val) if np.isfinite(sel_val) else np.nan)\n",
    "        hist[\"va_sel_mode\"].append(sel_mode)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "\n",
    "        if stage_name == \"dir\":\n",
    "            best_str = (f\"pnl={best_score_pnl:.6f}@ep{best_epoch_pnl:02d}\" if best_state_pnl is not None\n",
    "                        else f\"auc={best_score_auc:.6f}@ep{best_epoch_auc:02d}\")\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"{objective}={va_pnl_best.get(objective, np.nan):.6f} \"\n",
    "                f\"thr=({va_pnl_best.get('thr_trade', np.nan):.2f},{va_pnl_best.get('thr_dir', np.nan):.2f}) \"\n",
    "                f\"trades={va_pnl_best.get('n_trades', 0)} \"\n",
    "                f\"sel({sel_mode})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "        else:\n",
    "            best_str = f\"{best_score:.6f}@ep{best_epoch:02d}\" if best_epoch > 0 else \"none\"\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"sel({select_metric})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "\n",
    "        if bad >= patience:\n",
    "            break\n",
    "\n",
    "    # ---- choose final best state\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if best_state_pnl is not None:\n",
    "            model.load_state_dict(best_state_pnl)\n",
    "            best_score = best_score_pnl\n",
    "            best_epoch = best_epoch_pnl\n",
    "            best_used = f\"va_pnl_max({objective})\"\n",
    "        else:\n",
    "            model.load_state_dict(best_state_auc)\n",
    "            best_score = best_score_auc\n",
    "            best_epoch = best_epoch_auc\n",
    "            best_used = \"va_auc_fallback_only\"\n",
    "    else:\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "            best_used = select_metric\n",
    "\n",
    "    # финальные VAL/TEST\n",
    "    va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(model, va_loader, loss_fn, y_key=stage_name)\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(model, te_loader, loss_fn, y_key=stage_name)\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": float(best_score),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"select_metric\": select_metric,\n",
    "        \"best_used\": best_used,\n",
    "\n",
    "        \"val_loss\": va_loss, \"val_acc\": va_acc, \"val_f1m\": va_f1m, \"val_auc\": va_auc, \"val_cm\": va_cm,\n",
    "        \"val_y\": va_y, \"val_prob\": va_prob, \"val_er\": va_er,\n",
    "\n",
    "        \"test_loss\": te_loss, \"test_acc\": te_acc, \"test_f1m\": te_f1m, \"test_auc\": te_auc, \"test_cm\": te_cm,\n",
    "        \"test_y\": te_y, \"test_prob\": te_prob, \"test_er\": te_er,\n",
    "\n",
    "        \"hist\": hist,\n",
    "    }\n",
    "    return model, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Better threshold sweep (dynamic thr_trade + min_trades constraint)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "def build_trade_threshold_grid(\n",
    "    p_trade: np.ndarray,\n",
    "    base_grid: list[float] | None = None,\n",
    "    target_trades_list: list[int] | None = None,\n",
    "    min_thr: float = 0.01,\n",
    "    max_thr: float = 0.99,\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Делает пороги thr_trade не только фиксированные, но и \"по квантилям\",\n",
    "    чтобы можно было получать заданное число сделок даже при некалиброванных вероятностях.\n",
    "\n",
    "    target_trades_list: список желаемых n_trades (например [20,40,80])\n",
    "    Возвращает список порогов.\n",
    "    \"\"\"\n",
    "    p_trade = np.asarray(p_trade, dtype=np.float64)\n",
    "    p_trade = p_trade[np.isfinite(p_trade)]\n",
    "    if p_trade.size == 0:\n",
    "        return base_grid or [0.5]\n",
    "\n",
    "    thrs = set()\n",
    "    if base_grid:\n",
    "        for t in base_grid:\n",
    "            thrs.add(float(t))\n",
    "\n",
    "    if target_trades_list:\n",
    "        N = p_trade.size\n",
    "        # порог = значение, которое оставляет примерно k наблюдений сверху\n",
    "        for k in target_trades_list:\n",
    "            k = int(k)\n",
    "            if k <= 0:\n",
    "                continue\n",
    "            if k >= N:\n",
    "                thr = float(np.min(p_trade))  # чтобы взять всё\n",
    "            else:\n",
    "                # k сверху => квантиль 1 - k/N\n",
    "                q = 1.0 - (k / N)\n",
    "                thr = float(np.quantile(p_trade, q))\n",
    "            thr = float(np.clip(thr, min_thr, max_thr))\n",
    "            thrs.add(thr)\n",
    "\n",
    "    thrs = sorted(thrs)\n",
    "    # небольшая чистка дублей/почти-дублей\n",
    "    out = []\n",
    "    for t in thrs:\n",
    "        if not out or abs(t - out[-1]) > 1e-6:\n",
    "            out.append(float(t))\n",
    "    return out\n",
    "\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade, prob_dir, exit_ret,\n",
    "    thr_trade: float, thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    conf_dir = np.maximum(p_up, 1.0 - p_up)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (float(cost_bps) * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    n_tr = int(trade_mask.sum())\n",
    "    out = {\n",
    "        \"n\": int(len(exit_ret)),\n",
    "        \"n_trades\": n_tr,\n",
    "        \"trade_rate\": float(n_tr / max(1, len(exit_ret))),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()) if len(exit_ret) else np.nan,\n",
    "        \"pnl_per_trade\": float(pnl.sum() / max(1, n_tr)),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)) if len(exit_ret) else np.nan,\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg, min_trades: int = 0, objective: str = \"pnl_sum\"):\n",
    "    \"\"\"\n",
    "    Ищет лучшие (thr_trade, thr_dir) на сетке.\n",
    "    ВАЖНО: добавили min_trades (иначе часто \"лучше всего\" 0 сделок => pnl=0).\n",
    "    \"\"\"\n",
    "    if objective not in (\"pnl_sum\", \"pnl_mean\", \"pnl_per_trade\"):\n",
    "        raise ValueError(\"objective must be one of: pnl_sum, pnl_mean, pnl_per_trade\")\n",
    "\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    thr_trade_grid = build_trade_threshold_grid(\n",
    "        p_trade=p_trade,\n",
    "        base_grid=cfg.get(\"thr_trade_grid\", [0.5]),\n",
    "        target_trades_list=cfg.get(\"proxy_target_trades\", None),\n",
    "        min_thr=0.01,\n",
    "        max_thr=0.99,\n",
    "    )\n",
    "    thr_dir_grid = cfg.get(\"thr_dir_grid\", [0.5])\n",
    "\n",
    "    rows = []\n",
    "    for thr_t in thr_trade_grid:\n",
    "        for thr_d in thr_dir_grid:\n",
    "            m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cfg[\"cost_bps\"])\n",
    "            if int(m[\"n_trades\"]) < int(min_trades):\n",
    "                continue\n",
    "            rows.append({\"thr_trade\": float(thr_t), \"thr_dir\": float(thr_d), **m})\n",
    "\n",
    "    # fallback: если min_trades слишком строгий, ослабим до \"хотя бы 1 сделка\"\n",
    "    if not rows and min_trades > 0:\n",
    "        return sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg, min_trades=1, objective=objective)\n",
    "\n",
    "    # последний fallback: разрешим 0 сделок (на случай реально мёртвого сигнала)\n",
    "    if not rows:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            for thr_d in thr_dir_grid:\n",
    "                m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cfg[\"cost_bps\"])\n",
    "                rows.append({\"thr_trade\": float(thr_t), \"thr_dir\": float(thr_d), **m})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values([objective, \"pnl_sum\"], ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps,\n",
    "                       min_trades: int = 0, objective: str = \"pnl_sum\"):\n",
    "    \"\"\"\n",
    "    Упрощённая версия для train_binary_classifier (быстрое max по сетке).\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for thr_t in thr_trade_grid:\n",
    "        for thr_d in thr_dir_grid:\n",
    "            m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cost_bps)\n",
    "            if int(m[\"n_trades\"]) < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            score = float(m[objective])\n",
    "            if (best is None) or (score > best[\"_score\"]):\n",
    "                best = {\n",
    "                    \"_score\": score,\n",
    "                    \"pnl_sum\": m[\"pnl_sum\"],\n",
    "                    \"pnl_mean\": m[\"pnl_mean\"],\n",
    "                    \"pnl_per_trade\": m[\"pnl_per_trade\"],\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": int(m[\"n_trades\"]),\n",
    "                    \"trade_rate\": float(m[\"trade_rate\"]),\n",
    "                    \"passed_min_trades\": True,\n",
    "                    \"min_trades_used\": int(min_trades),\n",
    "                }\n",
    "\n",
    "    # fallback: если ничего не прошло min_trades — попробуем хотя бы 1 сделку\n",
    "    if best is None and min_trades > 0:\n",
    "        return pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps,\n",
    "                                  min_trades=1, objective=objective)\n",
    "\n",
    "    # последний fallback: разрешим 0 сделок\n",
    "    if best is None:\n",
    "        best = {\n",
    "            \"_score\": -1e18,\n",
    "            \"pnl_sum\": -1e18,\n",
    "            \"pnl_mean\": -1e18,\n",
    "            \"pnl_per_trade\": -1e18,\n",
    "            \"thr_trade\": float(thr_trade_grid[0]) if len(thr_trade_grid) else 0.5,\n",
    "            \"thr_dir\": float(thr_dir_grid[0]) if len(thr_dir_grid) else 0.5,\n",
    "            \"n_trades\": 0,\n",
    "            \"trade_rate\": 0.0,\n",
    "            \"passed_min_trades\": False,\n",
    "            \"min_trades_used\": int(min_trades),\n",
    "        }\n",
    "        # найдём реальный best без ограничений (даже 0 сделок)\n",
    "        for thr_t in thr_trade_grid:\n",
    "            for thr_d in thr_dir_grid:\n",
    "                m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cost_bps)\n",
    "                score = float(m[objective])\n",
    "                if score > best[\"_score\"]:\n",
    "                    best.update({\n",
    "                        \"_score\": score,\n",
    "                        \"pnl_sum\": m[\"pnl_sum\"],\n",
    "                        \"pnl_mean\": m[\"pnl_mean\"],\n",
    "                        \"pnl_per_trade\": m[\"pnl_per_trade\"],\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": int(m[\"n_trades\"]),\n",
    "                        \"trade_rate\": float(m[\"trade_rate\"]),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "    best.pop(\"_score\", None)\n",
    "    return best\n",
    "\n",
    "\n",
    "def debug_trade_prob_stats(prob_trade: np.ndarray, title: str = \"\"):\n",
    "    p = prob_trade[:, 1]\n",
    "    qs = [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]\n",
    "    vals = np.quantile(p, qs)\n",
    "    msg = \" | \".join([f\"q{int(q*100):02d}={v:.3f}\" for q, v in zip(qs, vals)])\n",
    "    print(f\"[trade prob stats]{(' ' + title) if title else ''}: {msg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5c430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: shared helper for probs on arbitrary indices\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_on_indices(model, X_scaled, edge_feat, indices, cfg):\n",
    "    ds = LobGraphSequenceDataset2Stage(\n",
    "        X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, cfg[\"lookback\"]\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, yt, yd, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(probs), np.concatenate(ers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 6017 1203 1203\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7915 va_loss=0.6967 f1m=0.496 auc=0.524 sel(va_auc)=0.524477 best=0.524477@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7188 va_loss=0.7002 f1m=0.390 auc=0.556 sel(va_auc)=0.555751 best=0.555751@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7028 va_loss=0.6892 f1m=0.496 auc=0.555 sel(va_auc)=0.554920 best=0.555751@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6988 va_loss=0.6935 f1m=0.516 auc=0.568 sel(va_auc)=0.567940 best=0.567940@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6935 va_loss=0.7039 f1m=0.428 auc=0.568 sel(va_auc)=0.568096 best=0.568096@ep05\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6909 va_loss=0.6844 f1m=0.496 auc=0.570 sel(va_auc)=0.569848 best=0.569848@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6857 va_loss=0.7062 f1m=0.452 auc=0.575 sel(va_auc)=0.574668 best=0.574668@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6879 va_loss=0.7005 f1m=0.496 auc=0.560 sel(va_auc)=0.559599 best=0.574668@ep07\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6843 va_loss=0.7018 f1m=0.517 auc=0.571 sel(va_auc)=0.571081 best=0.574668@ep07\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6791 va_loss=0.6919 f1m=0.568 auc=0.574 sel(va_auc)=0.573804 best=0.574668@ep07\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.6773 va_loss=0.6946 f1m=0.546 auc=0.573 sel(va_auc)=0.573138 best=0.574668@ep07\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.6738 va_loss=0.7072 f1m=0.532 auc=0.582 sel(va_auc)=0.581929 best=0.581929@ep12\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.6788 va_loss=0.6817 f1m=0.522 auc=0.578 sel(va_auc)=0.577805 best=0.581929@ep12\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.6709 va_loss=0.6848 f1m=0.527 auc=0.568 sel(va_auc)=0.567934 best=0.581929@ep12\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.6669 va_loss=0.6938 f1m=0.498 auc=0.565 sel(va_auc)=0.565337 best=0.581929@ep12\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.6717 va_loss=0.6967 f1m=0.497 auc=0.561 sel(va_auc)=0.560985 best=0.581929@ep12\n",
      "[trade] ep 17 lr=1.00e-04 tr_loss=0.6698 va_loss=0.7171 f1m=0.549 auc=0.566 sel(va_auc)=0.565952 best=0.581929@ep12\n",
      "[trade] ep 18 lr=1.00e-04 tr_loss=0.6627 va_loss=0.6984 f1m=0.558 auc=0.569 sel(va_auc)=0.568990 best=0.581929@ep12\n",
      "[trade] ep 19 lr=1.00e-04 tr_loss=0.6623 va_loss=0.7010 f1m=0.551 auc=0.568 sel(va_auc)=0.567826 best=0.581929@ep12\n",
      "[trade] ep 20 lr=1.00e-04 tr_loss=0.6598 va_loss=0.7392 f1m=0.530 auc=0.572 sel(va_auc)=0.572127 best=0.581929@ep12\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.218 | q05=0.263 | q10=0.298 | q25=0.339 | q50=0.434 | q75=0.508 | q90=0.532 | q95=0.539 | q99=0.553\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7640 va_loss=0.7055 f1m=0.302 auc=0.516 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7333 va_loss=0.7128 f1m=0.302 auc=0.366 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7139 va_loss=0.7011 f1m=0.399 auc=0.306 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7020 va_loss=0.7038 f1m=0.389 auc=0.298 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7119 va_loss=0.7120 f1m=0.346 auc=0.301 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6994 va_loss=0.7097 f1m=0.382 auc=0.330 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.7014 va_loss=0.7126 f1m=0.384 auc=0.357 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.7018 va_loss=0.7088 f1m=0.386 auc=0.410 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.6913 va_loss=0.7099 f1m=0.377 auc=0.410 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.6923 va_loss=0.7286 f1m=0.371 auc=0.339 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 11 lr=2.00e-04 tr_loss=0.6921 va_loss=0.7255 f1m=0.447 auc=0.337 pnl_sum=-0.010911 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.010911 best=pnl=-0.001377@ep01\n",
      "[dir] ep 12 lr=2.00e-04 tr_loss=0.6825 va_loss=0.7392 f1m=0.447 auc=0.333 pnl_sum=-0.001377 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.001377 best=pnl=-0.001377@ep01\n",
      "[dir] ep 13 lr=2.00e-04 tr_loss=0.6669 va_loss=0.7560 f1m=0.439 auc=0.357 pnl_sum=-0.006933 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.006933 best=pnl=-0.001377@ep01\n",
      "[dir] ep 14 lr=2.00e-04 tr_loss=0.6665 va_loss=0.7813 f1m=0.430 auc=0.359 pnl_sum=-0.006933 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.006933 best=pnl=-0.001377@ep01\n",
      "[dir] ep 15 lr=2.00e-04 tr_loss=0.6661 va_loss=0.7923 f1m=0.401 auc=0.342 pnl_sum=-0.032502 thr=(0.50,0.60) trades=120 sel(va_pnl_max(pnl_sum))=-0.032502 best=pnl=-0.001377@ep01\n",
      "[dir] ep 16 lr=2.00e-04 tr_loss=0.6568 va_loss=0.7915 f1m=0.447 auc=0.422 pnl_sum=-0.036718 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.036718 best=pnl=-0.001377@ep01\n",
      "[dir] ep 17 lr=1.00e-04 tr_loss=0.6528 va_loss=0.8137 f1m=0.412 auc=0.450 pnl_sum=-0.036718 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.036718 best=pnl=-0.001377@ep01\n",
      "[dir] ep 18 lr=1.00e-04 tr_loss=0.6297 va_loss=0.8613 f1m=0.409 auc=0.386 pnl_sum=-0.036718 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.036718 best=pnl=-0.001377@ep01\n",
      "[dir] ep 19 lr=1.00e-04 tr_loss=0.6417 va_loss=0.9041 f1m=0.429 auc=0.396 pnl_sum=-0.006933 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.006933 best=pnl=-0.001377@ep01\n",
      "[dir] ep 20 lr=1.00e-04 tr_loss=0.6304 va_loss=0.9120 f1m=0.425 auc=0.428 pnl_sum=-0.006933 thr=(0.53,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.006933 best=pnl=-0.001377@ep01\n",
      "PnL on fold-test: | thr_trade= 0.45 | thr_dir= 0.5 | pnl_sum= 0.06527522951364517 | pnl_mean= 5.426037387223914e-05 | trades= 98.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 7220 1203 1203\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7515 va_loss=0.6693 f1m=0.420 auc=0.712 sel(va_auc)=0.712351 best=0.712351@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7165 va_loss=0.7198 f1m=0.216 auc=0.734 sel(va_auc)=0.733908 best=0.733908@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7040 va_loss=0.7041 f1m=0.216 auc=0.740 sel(va_auc)=0.739958 best=0.739958@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7021 va_loss=0.6897 f1m=0.406 auc=0.691 sel(va_auc)=0.691028 best=0.739958@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6953 va_loss=0.6767 f1m=0.543 auc=0.698 sel(va_auc)=0.697709 best=0.739958@ep03\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6915 va_loss=0.6731 f1m=0.593 auc=0.667 sel(va_auc)=0.666641 best=0.739958@ep03\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6867 va_loss=0.6705 f1m=0.560 auc=0.650 sel(va_auc)=0.650149 best=0.739958@ep03\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6877 va_loss=0.6622 f1m=0.613 auc=0.636 sel(va_auc)=0.635767 best=0.739958@ep03\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6873 va_loss=0.6866 f1m=0.445 auc=0.647 sel(va_auc)=0.647013 best=0.739958@ep03\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.6806 va_loss=0.6809 f1m=0.486 auc=0.631 sel(va_auc)=0.630746 best=0.739958@ep03\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.6824 va_loss=0.6700 f1m=0.518 auc=0.639 sel(va_auc)=0.639308 best=0.739958@ep03\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.509 | q05=0.513 | q10=0.531 | q25=0.541 | q50=0.565 | q75=0.580 | q90=0.598 | q95=0.602 | q99=0.607\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8332 va_loss=0.6944 f1m=0.482 auc=0.449 pnl_sum=0.164628 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.164628 best=pnl=0.164628@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7387 va_loss=0.6867 f1m=0.377 auc=0.385 pnl_sum=0.293439 thr=(0.55,0.50) trades=694 sel(va_pnl_max(pnl_sum))=0.293439 best=pnl=0.293439@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7308 va_loss=0.7990 f1m=0.291 auc=0.369 pnl_sum=0.040167 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.040167 best=pnl=0.293439@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7156 va_loss=0.8080 f1m=0.291 auc=0.387 pnl_sum=0.040167 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.040167 best=pnl=0.293439@ep02\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7100 va_loss=0.7375 f1m=0.291 auc=0.376 pnl_sum=0.040167 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.040167 best=pnl=0.293439@ep02\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7138 va_loss=0.7793 f1m=0.291 auc=0.404 pnl_sum=0.040167 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.040167 best=pnl=0.293439@ep02\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.7099 va_loss=0.7282 f1m=0.291 auc=0.410 pnl_sum=0.040167 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.040167 best=pnl=0.293439@ep02\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7003 va_loss=0.7598 f1m=0.291 auc=0.396 pnl_sum=0.040167 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.040167 best=pnl=0.293439@ep02\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7007 va_loss=0.7549 f1m=0.291 auc=0.456 pnl_sum=0.040167 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.040167 best=pnl=0.293439@ep02\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.7007 va_loss=0.7215 f1m=0.291 auc=0.441 pnl_sum=0.040167 thr=(0.60,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.040167 best=pnl=0.293439@ep02\n",
      "PnL on fold-test: | thr_trade= 0.45 | thr_dir= 0.5 | pnl_sum= 0.2960372269153595 | pnl_mean= 0.0002460824907757342 | trades= 1203.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 8423 1203 1203\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7576 va_loss=0.7431 f1m=0.373 auc=0.564 sel(va_auc)=0.564461 best=0.564461@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7060 va_loss=0.8110 f1m=0.373 auc=0.502 sel(va_auc)=0.501543 best=0.564461@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7028 va_loss=0.7682 f1m=0.373 auc=0.502 sel(va_auc)=0.502343 best=0.564461@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6917 va_loss=0.8479 f1m=0.373 auc=0.489 sel(va_auc)=0.489332 best=0.564461@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6910 va_loss=0.7528 f1m=0.373 auc=0.474 sel(va_auc)=0.473940 best=0.564461@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.6911 va_loss=0.7669 f1m=0.373 auc=0.476 sel(va_auc)=0.475850 best=0.564461@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6846 va_loss=0.8139 f1m=0.373 auc=0.480 sel(va_auc)=0.480349 best=0.564461@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6792 va_loss=0.8127 f1m=0.373 auc=0.484 sel(va_auc)=0.483690 best=0.564461@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6807 va_loss=0.7965 f1m=0.382 auc=0.481 sel(va_auc)=0.480662 best=0.564461@ep01\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.372 | q05=0.375 | q10=0.378 | q25=0.382 | q50=0.391 | q75=0.408 | q90=0.418 | q95=0.422 | q99=0.429\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8347 va_loss=0.7476 f1m=0.313 auc=0.513 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=-0.089291@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7499 va_loss=0.7208 f1m=0.313 auc=0.492 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=-0.089291@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7269 va_loss=0.6894 f1m=0.469 auc=0.582 pnl_sum=0.069291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=0.069291 best=pnl=0.069291@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7190 va_loss=0.7038 f1m=0.313 auc=0.513 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=0.069291@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7186 va_loss=0.7030 f1m=0.313 auc=0.534 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=0.069291@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7120 va_loss=0.6907 f1m=0.529 auc=0.588 pnl_sum=-0.095091 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.095091 best=pnl=0.069291@ep03\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.7091 va_loss=0.6940 f1m=0.529 auc=0.624 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=0.069291@ep03\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7093 va_loss=0.7146 f1m=0.313 auc=0.588 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=0.069291@ep03\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7016 va_loss=0.6939 f1m=0.470 auc=0.632 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=0.069291@ep03\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.7029 va_loss=0.6945 f1m=0.459 auc=0.611 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=0.069291@ep03\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.7040 va_loss=0.6985 f1m=0.424 auc=0.561 pnl_sum=-0.089291 thr=(0.42,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.089291 best=pnl=0.069291@ep03\n",
      "PnL on fold-test: | thr_trade= 0.416044066176252 | thr_dir= 0.5 | pnl_sum= 0.14916718006134033 | pnl_mean= 0.00012399599654600024 | trades= 50.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 9626 1203 1203\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7510 va_loss=0.6759 f1m=0.296 auc=0.499 sel(va_auc)=0.498947 best=0.498947@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7069 va_loss=0.6845 f1m=0.441 auc=0.500 sel(va_auc)=0.499821 best=0.499821@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7042 va_loss=0.6848 f1m=0.509 auc=0.529 sel(va_auc)=0.529326 best=0.529326@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6957 va_loss=0.6879 f1m=0.532 auc=0.545 sel(va_auc)=0.545312 best=0.545312@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6922 va_loss=0.6853 f1m=0.512 auc=0.529 sel(va_auc)=0.529260 best=0.545312@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6879 va_loss=0.6861 f1m=0.528 auc=0.554 sel(va_auc)=0.553956 best=0.553956@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6849 va_loss=0.6838 f1m=0.572 auc=0.562 sel(va_auc)=0.561840 best=0.561840@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6818 va_loss=0.6823 f1m=0.407 auc=0.562 sel(va_auc)=0.561979 best=0.561979@ep08\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6861 va_loss=0.6743 f1m=0.497 auc=0.568 sel(va_auc)=0.568447 best=0.568447@ep09\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6793 va_loss=0.7025 f1m=0.567 auc=0.570 sel(va_auc)=0.570130 best=0.570130@ep10\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.6787 va_loss=0.6746 f1m=0.479 auc=0.579 sel(va_auc)=0.579121 best=0.579121@ep11\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.6735 va_loss=0.6879 f1m=0.560 auc=0.582 sel(va_auc)=0.581954 best=0.581954@ep12\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.6771 va_loss=0.6921 f1m=0.512 auc=0.590 sel(va_auc)=0.590349 best=0.590349@ep13\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.6671 va_loss=0.6934 f1m=0.531 auc=0.589 sel(va_auc)=0.589083 best=0.590349@ep13\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.6675 va_loss=0.6889 f1m=0.535 auc=0.602 sel(va_auc)=0.602175 best=0.602175@ep15\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.6663 va_loss=0.6798 f1m=0.537 auc=0.596 sel(va_auc)=0.595526 best=0.602175@ep15\n",
      "[trade] ep 17 lr=2.00e-04 tr_loss=0.6640 va_loss=0.7380 f1m=0.539 auc=0.586 sel(va_auc)=0.585594 best=0.602175@ep15\n",
      "[trade] ep 18 lr=2.00e-04 tr_loss=0.6533 va_loss=0.7537 f1m=0.503 auc=0.582 sel(va_auc)=0.582419 best=0.602175@ep15\n",
      "[trade] ep 19 lr=2.00e-04 tr_loss=0.6650 va_loss=0.8274 f1m=0.507 auc=0.569 sel(va_auc)=0.569057 best=0.602175@ep15\n",
      "[trade] ep 20 lr=1.00e-04 tr_loss=0.6550 va_loss=0.6846 f1m=0.457 auc=0.587 sel(va_auc)=0.586520 best=0.602175@ep15\n",
      "[trade] ep 21 lr=1.00e-04 tr_loss=0.6485 va_loss=0.7344 f1m=0.514 auc=0.575 sel(va_auc)=0.575236 best=0.602175@ep15\n",
      "[trade] ep 22 lr=1.00e-04 tr_loss=0.6473 va_loss=0.6897 f1m=0.532 auc=0.581 sel(va_auc)=0.580791 best=0.602175@ep15\n",
      "[trade] ep 23 lr=1.00e-04 tr_loss=0.6436 va_loss=0.7649 f1m=0.517 auc=0.573 sel(va_auc)=0.572833 best=0.602175@ep15\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.273 | q05=0.327 | q10=0.379 | q25=0.484 | q50=0.626 | q75=0.817 | q90=0.853 | q95=0.859 | q99=0.865\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7724 va_loss=0.6906 f1m=0.503 auc=0.586 pnl_sum=0.533918 thr=(0.60,0.50) trades=648 sel(va_pnl_max(pnl_sum))=0.533918 best=pnl=0.533918@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7176 va_loss=0.6929 f1m=0.407 auc=0.506 pnl_sum=0.458380 thr=(0.60,0.50) trades=648 sel(va_pnl_max(pnl_sum))=0.458380 best=pnl=0.533918@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7105 va_loss=0.6950 f1m=0.331 auc=0.466 pnl_sum=0.291063 thr=(0.60,0.50) trades=648 sel(va_pnl_max(pnl_sum))=0.291063 best=pnl=0.533918@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7099 va_loss=0.7061 f1m=0.336 auc=0.452 pnl_sum=-0.100285 thr=(0.85,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.100285 best=pnl=0.533918@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7050 va_loss=0.6982 f1m=0.336 auc=0.426 pnl_sum=-0.100285 thr=(0.85,0.50) trades=100 sel(va_pnl_max(pnl_sum))=-0.100285 best=pnl=0.533918@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr_loss=0.7032 va_loss=0.6949 f1m=0.330 auc=0.376 pnl_sum=0.365729 thr=(0.60,0.50) trades=648 sel(va_pnl_max(pnl_sum))=0.365729 best=pnl=0.533918@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.7038 va_loss=0.6948 f1m=0.330 auc=0.396 pnl_sum=0.365729 thr=(0.60,0.50) trades=648 sel(va_pnl_max(pnl_sum))=0.365729 best=pnl=0.533918@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7073 va_loss=0.6955 f1m=0.330 auc=0.372 pnl_sum=0.365729 thr=(0.60,0.50) trades=648 sel(va_pnl_max(pnl_sum))=0.365729 best=pnl=0.533918@ep01\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7054 va_loss=0.6949 f1m=0.330 auc=0.373 pnl_sum=0.365729 thr=(0.60,0.50) trades=648 sel(va_pnl_max(pnl_sum))=0.365729 best=pnl=0.533918@ep01\n",
      "PnL on fold-test: | thr_trade= 0.7 | thr_dir= 0.5 | pnl_sum= 0.2421400249004364 | pnl_mean= 0.00020128015603404492 | trades= 509.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.427992</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.081463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.505331</td>\n",
       "      <td>0.352394</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.367175</td>\n",
       "      <td>0.359742</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.416044</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.041563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.533150</td>\n",
       "      <td>0.309798</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0.423109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.427992      0.371212       0.000054        0.450000   \n",
       "1     2        0.505331      0.352394       0.000246        0.450000   \n",
       "2     3        0.367175      0.359742       0.000124        0.416044   \n",
       "3     4        0.533150      0.309798       0.000201        0.700000   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0           0.5           98.0         0.081463  \n",
       "1           0.5         1203.0         1.000000  \n",
       "2           0.5           50.0         0.041563  \n",
       "3           0.5          509.0         0.423109  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN (fold-test внутри CV-part):\n",
      "fold                 2.500000\n",
      "trade_test_f1m       0.458412\n",
      "dir_test_f1m         0.348286\n",
      "best_pnl_mean        0.000156\n",
      "best_thr_trade       0.504011\n",
      "best_thr_dir         0.500000\n",
      "n_trades_best      465.000000\n",
      "trade_rate_best      0.386534\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training (ONLY on CV-part)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold (fit only on train times)\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples (по AUC)\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\",\n",
    "        select_metric=\"va_auc\",\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples (train/val/test индексы фильтруем)\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "            \"trade_rate_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # dir: учим на trade-only, но PnL-proxy считаем на полном idx_va (full val)\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\",\n",
    "        select_metric=\"va_pnl_max\",\n",
    "        trade_model_for_pnl=m_trade,\n",
    "        idx_val_pnl=idx_va,   # <-- полный val для pnl-proxy\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on fold TEST\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te, CFG)\n",
    "    prob_dir_te, _       = predict_probs_on_indices(m_dir,   X_scaled, edge_feat, idx_te, CFG)\n",
    "\n",
    "    \n",
    "    objective = CFG.get(\"pnl_objective\", \"pnl_sum\")\n",
    "    min_tr_eval = int(CFG.get(\"eval_min_trades\", 0))\n",
    "\n",
    "    sweep = sweep_thresholds(\n",
    "        prob_trade_te, prob_dir_te, er_te,\n",
    "        CFG,\n",
    "        min_trades=min_tr_eval,\n",
    "        objective=objective\n",
    "    )\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on fold-test:\",\n",
    "        \"| thr_trade=\", best[\"thr_trade\"],\n",
    "        \"| thr_dir=\", best[\"thr_dir\"],\n",
    "        f\"| {objective}=\", best[objective],\n",
    "        \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "        \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN (fold-test внутри CV-part):\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": [
    "## 11. Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50d16463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL TRAIN/TEST (CV=90% | FINAL=10%)\n",
      "Final split sizes:\n",
      "  train_final: 10832\n",
      "  val_final  : 1203\n",
      "  FINAL test : 1337\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : -0.00019602017709985375\n",
      "  pnl_sum  : -0.2620789706707001\n",
      "  n_trades : 563\n",
      "  trade_rate: 0.42109199700822736\n",
      "  sharpe (per-bar proxy): -1.0795120777971074\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.8948021193627733 thr_dir: 0.5\n",
      "  pnl_mean : 3.1657204090151936e-05 trades: 50.0\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Final train on CV(90%) and evaluate once on FINAL(10%)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAIN/TEST (CV=90% | FINAL=10%)\")\n",
    "\n",
    "# 1) final train/val split внутри CV-part (по времени)\n",
    "val_w_final = max(1, int(CFG[\"val_window_frac\"] * n_samples_cv))\n",
    "train_end = n_samples_cv - val_w_final\n",
    "\n",
    "idx_train_final = np.arange(0, train_end, dtype=np.int64)\n",
    "idx_val_final   = np.arange(train_end, n_samples_cv, dtype=np.int64)\n",
    "idx_test_final  = idx_final_test.astype(np.int64)  # финальный holdout\n",
    "\n",
    "print(\"Final split sizes:\")\n",
    "print(\"  train_final:\", len(idx_train_final))\n",
    "print(\"  val_final  :\", len(idx_val_final))\n",
    "print(\"  FINAL test :\", len(idx_test_final))\n",
    "\n",
    "# 2) scaling (fit only on train_final)\n",
    "X_scaled_final, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train_final, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=summary['best_thr_trade'][3],\n",
    "    thr_dir=summary['best_thr_dir'][3],\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c4946a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7473 va_loss=0.6860 f1m=0.470 auc=0.510 sel(va_auc)=0.509737 best=0.509737@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7035 va_loss=0.6906 f1m=0.512 auc=0.521 sel(va_auc)=0.520860 best=0.520860@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6982 va_loss=0.6972 f1m=0.516 auc=0.519 sel(va_auc)=0.518662 best=0.520860@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6894 va_loss=0.7261 f1m=0.377 auc=0.486 sel(va_auc)=0.486332 best=0.520860@ep02\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6914 va_loss=0.7077 f1m=0.513 auc=0.555 sel(va_auc)=0.555171 best=0.555171@ep05\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6884 va_loss=0.6975 f1m=0.510 auc=0.561 sel(va_auc)=0.561320 best=0.561320@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6846 va_loss=0.7602 f1m=0.377 auc=0.561 sel(va_auc)=0.560950 best=0.561320@ep06\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6858 va_loss=0.6929 f1m=0.510 auc=0.557 sel(va_auc)=0.557127 best=0.561320@ep06\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6842 va_loss=0.7015 f1m=0.510 auc=0.555 sel(va_auc)=0.554668 best=0.561320@ep06\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6790 va_loss=0.6939 f1m=0.516 auc=0.555 sel(va_auc)=0.554749 best=0.561320@ep06\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.6786 va_loss=0.7141 f1m=0.540 auc=0.558 sel(va_auc)=0.558459 best=0.561320@ep06\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.6731 va_loss=0.7304 f1m=0.502 auc=0.557 sel(va_auc)=0.556899 best=0.561320@ep06\n",
      "[trade] ep 13 lr=1.00e-04 tr_loss=0.6674 va_loss=0.7354 f1m=0.504 auc=0.555 sel(va_auc)=0.554787 best=0.561320@ep06\n",
      "[trade] ep 14 lr=1.00e-04 tr_loss=0.6697 va_loss=0.7775 f1m=0.524 auc=0.557 sel(va_auc)=0.557243 best=0.561320@ep06\n",
      "Trade-only sizes for DIR:\n",
      "  train_final_T: 3639\n",
      "  val_final_T  : 476\n",
      "  test_final_T : 495\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.389 | q05=0.397 | q10=0.400 | q25=0.421 | q50=0.457 | q75=0.529 | q90=0.560 | q95=0.569 | q99=0.581\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7635 va_loss=0.7183 f1m=0.308 auc=0.631 pnl_sum=0.300211 thr=(0.50,0.60) trades=489 sel(va_pnl_max(pnl_sum))=0.300211 best=pnl=0.300211@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7338 va_loss=0.7044 f1m=0.308 auc=0.626 pnl_sum=0.356466 thr=(0.45,0.60) trades=409 sel(va_pnl_max(pnl_sum))=0.356466 best=pnl=0.356466@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7179 va_loss=0.6912 f1m=0.359 auc=0.597 pnl_sum=0.188380 thr=(0.50,0.50) trades=525 sel(va_pnl_max(pnl_sum))=0.188380 best=pnl=0.356466@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7033 va_loss=0.6894 f1m=0.535 auc=0.619 pnl_sum=0.188380 thr=(0.50,0.50) trades=525 sel(va_pnl_max(pnl_sum))=0.188380 best=pnl=0.356466@ep02\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7009 va_loss=0.6875 f1m=0.506 auc=0.612 pnl_sum=0.188380 thr=(0.50,0.50) trades=525 sel(va_pnl_max(pnl_sum))=0.188380 best=pnl=0.356466@ep02\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7022 va_loss=0.6900 f1m=0.523 auc=0.595 pnl_sum=0.188380 thr=(0.50,0.50) trades=525 sel(va_pnl_max(pnl_sum))=0.188380 best=pnl=0.356466@ep02\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.7058 va_loss=0.6995 f1m=0.308 auc=0.600 pnl_sum=0.188380 thr=(0.50,0.50) trades=525 sel(va_pnl_max(pnl_sum))=0.188380 best=pnl=0.356466@ep02\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7006 va_loss=0.6908 f1m=0.514 auc=0.592 pnl_sum=0.258579 thr=(0.45,0.55) trades=223 sel(va_pnl_max(pnl_sum))=0.258579 best=pnl=0.356466@ep02\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7000 va_loss=0.6893 f1m=0.516 auc=0.586 pnl_sum=0.240522 thr=(0.45,0.55) trades=211 sel(va_pnl_max(pnl_sum))=0.240522 best=pnl=0.356466@ep02\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.6957 va_loss=0.6896 f1m=0.516 auc=0.588 pnl_sum=0.188380 thr=(0.50,0.50) trades=525 sel(va_pnl_max(pnl_sum))=0.188380 best=pnl=0.356466@ep02\n",
      "\n",
      "Chosen thresholds on val_final:\n",
      "  thr_trade*: 0.45\n",
      "  thr_dir*  : 0.6\n",
      "  val pnl_mean: 0.0002963143342640251 | val trades: 409\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : -0.00021051963267382234\n",
      "  pnl_sum  : -0.28146475553512573\n",
      "  n_trades : 633\n",
      "  trade_rate: 0.47344801795063574\n",
      "  sharpe (per-bar proxy): -1.0874242213743606\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.55 thr_dir: 0.5\n",
      "  pnl_mean : 5.24287715961691e-05 trades: 430.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3) train TRADE on train_final, select by AUC on val_final\n",
    "m_trade_final, r_trade_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final, idx_val_final, idx_test_final,\n",
    "    CFG,\n",
    "    stage_name=\"trade\",\n",
    "    select_metric=\"va_auc\",\n",
    ")\n",
    "\n",
    "# 4) train DIR on trade-only samples (train/val/test filtered),\n",
    "#    but pnl-proxy computed on full val_final; selector hard-fallback already inside\n",
    "idx_train_final_T = subset_trade_indices(idx_train_final, sample_t, y_trade)\n",
    "idx_val_final_T   = subset_trade_indices(idx_val_final,   sample_t, y_trade)\n",
    "idx_test_final_T  = subset_trade_indices(idx_test_final,  sample_t, y_trade)\n",
    "\n",
    "print(\"Trade-only sizes for DIR:\")\n",
    "print(\"  train_final_T:\", len(idx_train_final_T))\n",
    "print(\"  val_final_T  :\", len(idx_val_final_T))\n",
    "print(\"  test_final_T :\", len(idx_test_final_T))\n",
    "\n",
    "m_dir_final, r_dir_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final_T, idx_val_final_T, idx_test_final_T,\n",
    "    CFG,\n",
    "    stage_name=\"dir\",\n",
    "    select_metric=\"va_pnl_max\",\n",
    "    trade_model_for_pnl=m_trade_final,\n",
    "    idx_val_pnl=idx_val_final,   # pnl-proxy на полном val_final\n",
    ")\n",
    "\n",
    "# 5) выбрать пороги по val_final (grid sweep)\n",
    "prob_trade_val, er_val = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "prob_dir_val, _        = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "\n",
    "sweep_val = sweep_thresholds(prob_trade_val, prob_dir_val, er_val, CFG)\n",
    "best_val = sweep_val.iloc[0].to_dict()\n",
    "thr_trade_star = float(best_val[\"thr_trade\"])\n",
    "thr_dir_star   = float(best_val[\"thr_dir\"])\n",
    "\n",
    "print(\"\\nChosen thresholds on val_final:\")\n",
    "print(\"  thr_trade*:\", thr_trade_star)\n",
    "print(\"  thr_dir*  :\", thr_dir_star)\n",
    "print(\"  val pnl_mean:\", float(best_val[\"pnl_mean\"]), \"| val trades:\", int(best_val[\"n_trades\"]))\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=thr_trade_star,\n",
    "    thr_dir=thr_dir_star,\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
