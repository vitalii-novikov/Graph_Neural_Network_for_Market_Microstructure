{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),  \n",
    "\n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 84],  # 30m,1h,2h,4h,7h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 1*12,       # 1h     # нужен для sample_t (чтобы TB-exit не вылезал за конец)\n",
    "    \"lookback\": 7*12,   \n",
    "    \"tb_pt_mult\": 1.1,\n",
    "    \"tb_sl_mult\": 1.2,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "    # training (общие)\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.2,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "\n",
    "    # ---- PnL proxy during DIR training (grid selector)\n",
    "    # можно сделать уже/шире, но по умолчанию переиспользуем thr_*_grid\n",
    "    \"proxy_thr_trade_grid\": None,  # None -> использовать thr_trade_grid\n",
    "    \"proxy_thr_dir_grid\":   None,  # None -> использовать thr_dir_grid\n",
    "    \"proxy_min_trades\": 50,        # защита от \"лучший pnl = 0 потому что 0 трейдов\"\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "print(\"EDGE_INDEX:\", EDGE_INDEX.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (3367, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (3367, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [ 854 1474 1039]\n",
      "Trade ratio: 0.5622215622215623\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=1*12, \n",
    "    vol_window=7*12,\n",
    "    pt_mult=1.1,\n",
    "    sl_mult=1.2,\n",
    "    min_barrier=0.001,\n",
    "    max_barrier=0.006,\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (3367, 3, 15) edge_feat: (3367, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 3271 t range: 83 3353\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1635 | val 327 | test 327\n",
      " fold 2: train 1962 | val 327 | test 327\n",
      " fold 3: train 2289 | val 327 | test 327\n",
      " fold 4: train 2616 | val 327 | test 327\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "        idx_train = np.arange(0, tr_end)\n",
    "        idx_val   = np.arange(tr_end, va_end)\n",
    "        idx_test  = np.arange(va_end, te_end)\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "    return splits\n",
    "\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "\n",
    "for i, (a,b,c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: GNN + LSTM classifier (универсальный под 2 класса)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class EdgeGatedMP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_proj = nn.Linear(in_dim, hidden)\n",
    "        self.ln0 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden + edge_dim, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden + 1)  # msg(hidden) + gate(1)\n",
    "        )\n",
    "\n",
    "        self.upd = nn.Sequential(\n",
    "            nn.Linear(2*hidden, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward_once(self, x_t, edge_attr_t, edge_index):\n",
    "        B, N, _ = x_t.shape\n",
    "        E = edge_index.shape[0]\n",
    "\n",
    "        h = self.ln0(self.node_proj(x_t))  # (B,N,H)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        agg = torch.zeros((B, N, h.shape[-1]), device=h.device, dtype=h.dtype)\n",
    "\n",
    "        for e in range(E):\n",
    "            src = edge_index[e, 0].item()\n",
    "            dst = edge_index[e, 1].item()\n",
    "            h_src = h[:, src, :]\n",
    "            h_dst = h[:, dst, :]\n",
    "            ea = edge_attr_t[:, e, :]\n",
    "\n",
    "            z = torch.cat([h_src, h_dst, ea], dim=-1)\n",
    "            out = self.edge_mlp(z)\n",
    "            msg = out[:, :-1]\n",
    "            gate = torch.sigmoid(out[:, -1:])\n",
    "\n",
    "            agg[:, dst, :] += msg * gate\n",
    "\n",
    "        h2 = self.upd(torch.cat([h, agg], dim=-1))\n",
    "        h2 = self.ln1(h + self.dropout(h2))\n",
    "        h2 = torch.nan_to_num(h2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return h2\n",
    "\n",
    "    def forward(self, x_seq, e_seq, edge_index):\n",
    "        B, L, N, Fin = x_seq.shape\n",
    "        h_out = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            h_out.append(ht)\n",
    "        return torch.stack(h_out, dim=1)  # (B,L,N,H)\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = target_node\n",
    "\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(gnn_layers):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(EdgeGatedMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, dropout=dropout))\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(lstm_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, lstm_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, n_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        out, _ = self.lstm(h_tgt)\n",
    "        last = out[:, -1, :]\n",
    "        logits = self.head(last)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"Model ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn, y_key: str = \"trade\"):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        y = (y_trade_b if y_key == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "\n",
    "    ys = np.concatenate(ys) if len(ys) else np.array([], dtype=np.int64)\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, None, ys, probs, ers\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:, 1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss / max(n, 1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_only(model, loader):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "    return probs, ers\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps, min_trades: int = 0):\n",
    "    \"\"\"\n",
    "    Возвращает лучший pnl_mean по grid (пер-бар), плюс пороги и статистику.\n",
    "    Защита от вырожденного решения \"0 трейдов => pnl_mean=0\": через min_trades.\n",
    "    \"\"\"\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    # знак позиции зависит только от p_up>=0.5\n",
    "    sign = np.where(p_up >= 0.5, 1.0, -1.0).astype(np.float32)\n",
    "\n",
    "    cost = float(cost_bps) * 1e-4\n",
    "    N = len(exit_ret)\n",
    "\n",
    "    best = {\n",
    "        \"pnl_mean\": -1e18,\n",
    "        \"pnl_sum\": -1e18,\n",
    "        \"thr_trade\": None,\n",
    "        \"thr_dir\": None,\n",
    "        \"n_trades\": 0,\n",
    "        \"trade_rate\": 0.0,\n",
    "    }\n",
    "\n",
    "    for thr_t in thr_trade_grid:\n",
    "        mt = (p_trade >= thr_t)\n",
    "        for thr_d in thr_dir_grid:\n",
    "            mask = mt & (conf_dir >= thr_d)\n",
    "            n_tr = int(mask.sum())\n",
    "            if n_tr < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "            pnl_sum = float(pnl.sum())\n",
    "            pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "            if pnl_mean > best[\"pnl_mean\"]:\n",
    "                best.update({\n",
    "                    \"pnl_mean\": pnl_mean,\n",
    "                    \"pnl_sum\": pnl_sum,\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": n_tr,\n",
    "                    \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                })\n",
    "\n",
    "    # если ничего не прошло min_trades — разрешим любой порог (чтобы не падало)\n",
    "    if best[\"thr_trade\"] is None:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            mt = (p_trade >= thr_t)\n",
    "            for thr_d in thr_dir_grid:\n",
    "                mask = mt & (conf_dir >= thr_d)\n",
    "                n_tr = int(mask.sum())\n",
    "                pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "                pnl_sum = float(pnl.sum())\n",
    "                pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "                if pnl_mean > best[\"pnl_mean\"]:\n",
    "                    best.update({\n",
    "                        \"pnl_mean\": pnl_mean,\n",
    "                        \"pnl_sum\": pnl_sum,\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": n_tr,\n",
    "                        \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                    })\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "    select_metric: str | None = None,        # \"va_auc\" | \"va_f1m\" | \"va_pnl_max\"\n",
    "    trade_model_for_pnl=None,                # для stage=\"dir\": фиксированная trade-модель\n",
    "    idx_val_pnl=None,                        # индексы (sample-space) для pnl-proxy, обычно полный idx_val\n",
    "):\n",
    "    \"\"\"\n",
    "    Что оптимизируем градиентами: CrossEntropyLoss.\n",
    "    Что используем для best checkpoint / lr scheduler / early stop: select_metric.\n",
    "\n",
    "    select_metric:\n",
    "      - \"va_auc\", \"va_f1m\"\n",
    "      - \"va_pnl_max\" (только для stage=\"dir\", нужен trade_model_for_pnl + idx_val_pnl)\n",
    "    \"\"\"\n",
    "    if select_metric is None:\n",
    "        select_metric = \"va_auc\"\n",
    "    if select_metric not in (\"va_auc\", \"va_f1m\", \"va_pnl_max\"):\n",
    "        raise ValueError(\"select_metric must be one of: 'va_auc', 'va_f1m', 'va_pnl_max'\")\n",
    "\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if stage_name != \"dir\":\n",
    "            raise ValueError(\"select_metric='va_pnl_max' supported only for stage_name='dir'\")\n",
    "        if trade_model_for_pnl is None or idx_val_pnl is None:\n",
    "            raise ValueError(\"For va_pnl_max you must pass trade_model_for_pnl and idx_val_pnl (full val indices).\")\n",
    "\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val, L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test, L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True, drop_last=True, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    # loader для PnL proxy (полный val)\n",
    "    va_pnl_loader = None\n",
    "    if stage_name == \"dir\" and (idx_val_pnl is not None):\n",
    "        va_pnl_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val_pnl, L)\n",
    "        va_pnl_loader = DataLoader(va_pnl_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # оптимизация (градиенты) — только CE\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\"))\n",
    "\n",
    "    # --- подготовка trade-prob на полном val для PnL proxy (считаем 1 раз)\n",
    "    prob_trade_val_pnl = None\n",
    "    if stage_name == \"dir\" and (trade_model_for_pnl is not None) and (va_pnl_loader is not None):\n",
    "        prob_trade_val_pnl, _ = predict_probs_only(trade_model_for_pnl, va_pnl_loader)\n",
    "\n",
    "    thr_trade_grid_proxy = cfg.get(\"proxy_thr_trade_grid\") or cfg.get(\"thr_trade_grid\", [0.5])\n",
    "    thr_dir_grid_proxy = cfg.get(\"proxy_thr_dir_grid\") or cfg.get(\"thr_dir_grid\", [0.5])\n",
    "    proxy_min_trades = int(cfg.get(\"proxy_min_trades\", 0))\n",
    "\n",
    "    best_score = -1e18\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\n",
    "        \"tr_loss\": [], \"va_loss\": [],\n",
    "        \"va_f1m\": [], \"va_auc\": [],\n",
    "        \"va_pnl_max\": [],\n",
    "        \"va_pnl_thr_trade\": [],\n",
    "        \"va_pnl_thr_dir\": [],\n",
    "        \"va_pnl_n_trades\": [],\n",
    "        \"va_sel\": []\n",
    "    }\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"] + 1):\n",
    "        # ---- TRAIN\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for x, e, y_trade_b, y_dir_b, er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            y = (y_trade_b if stage_name == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot / max(n, 1)\n",
    "\n",
    "        # ---- VAL classification metrics\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, va_loader, loss_fn, y_key=stage_name\n",
    "        )\n",
    "\n",
    "        # ---- VAL PnL proxy grid max (dir only, full val)\n",
    "        va_pnl_best = {\"pnl_mean\": np.nan, \"thr_trade\": np.nan, \"thr_dir\": np.nan, \"n_trades\": 0, \"trade_rate\": np.nan}\n",
    "        if stage_name == \"dir\" and (prob_trade_val_pnl is not None) and (va_pnl_loader is not None):\n",
    "            prob_dir_val_pnl, er_dir_val_pnl = predict_probs_only(model, va_pnl_loader)\n",
    "\n",
    "            va_pnl_best = pnl_proxy_grid_max(\n",
    "                prob_trade=prob_trade_val_pnl,\n",
    "                prob_dir=prob_dir_val_pnl,\n",
    "                exit_ret=er_dir_val_pnl,\n",
    "                thr_trade_grid=thr_trade_grid_proxy,\n",
    "                thr_dir_grid=thr_dir_grid_proxy,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "                min_trades=proxy_min_trades,\n",
    "            )\n",
    "\n",
    "        # --- selection metric\n",
    "        if select_metric == \"va_auc\":\n",
    "            sel_val = va_auc\n",
    "        elif select_metric == \"va_f1m\":\n",
    "            sel_val = va_f1m\n",
    "        else:\n",
    "            sel_val = va_pnl_best[\"pnl_mean\"]\n",
    "\n",
    "        if not np.isfinite(sel_val):\n",
    "            sel_val = -1e18\n",
    "\n",
    "        sch.step(float(sel_val))\n",
    "\n",
    "        # ---- logging + hist\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "\n",
    "        hist[\"va_pnl_max\"].append(float(va_pnl_best[\"pnl_mean\"]) if np.isfinite(va_pnl_best[\"pnl_mean\"]) else np.nan)\n",
    "        hist[\"va_pnl_thr_trade\"].append(float(va_pnl_best[\"thr_trade\"]) if va_pnl_best[\"thr_trade\"] is not None else np.nan)\n",
    "        hist[\"va_pnl_thr_dir\"].append(float(va_pnl_best[\"thr_dir\"]) if va_pnl_best[\"thr_dir\"] is not None else np.nan)\n",
    "        hist[\"va_pnl_n_trades\"].append(int(va_pnl_best[\"n_trades\"]))\n",
    "        hist[\"va_sel\"].append(sel_val)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "        best_str = f\"{best_score:.6f}@ep{best_epoch:02d}\" if best_epoch > 0 else \"none\"\n",
    "\n",
    "        if stage_name == \"dir\":\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"pnl_max={va_pnl_best['pnl_mean']:.6f} \"\n",
    "                f\"thr=({va_pnl_best['thr_trade']:.2f},{va_pnl_best['thr_dir']:.2f}) \"\n",
    "                f\"trades={va_pnl_best['n_trades']} \"\n",
    "                f\"sel({select_metric})={sel_val:.6f} best={best_str}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"sel({select_metric})={sel_val:.6f} best={best_str}\"\n",
    "            )\n",
    "\n",
    "        # ---- best checkpoint / early stop\n",
    "        if sel_val > best_score:\n",
    "            best_score = sel_val\n",
    "            best_epoch = ep\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # финальные VAL/TEST по best_state\n",
    "    va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "        model, va_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(\n",
    "        model, te_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": float(best_score),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"select_metric\": select_metric,\n",
    "\n",
    "        \"val_loss\": va_loss,\n",
    "        \"val_acc\": va_acc,\n",
    "        \"val_f1m\": va_f1m,\n",
    "        \"val_auc\": va_auc,\n",
    "        \"val_cm\": va_cm,\n",
    "        \"val_y\": va_y,\n",
    "        \"val_prob\": va_prob,\n",
    "        \"val_er\": va_er,\n",
    "\n",
    "        \"test_loss\": te_loss,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_f1m\": te_f1m,\n",
    "        \"test_auc\": te_auc,\n",
    "        \"test_cm\": te_cm,\n",
    "        \"test_y\": te_y,\n",
    "        \"test_prob\": te_prob,\n",
    "        \"test_er\": te_er,\n",
    "\n",
    "        \"hist\": hist,\n",
    "    }\n",
    "    return model, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: PnL по порогам уверенности (two-stage)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade,          # (N,2) softmax: [:,1]=p_trade\n",
    "    prob_dir,            # (N,2) softmax: [:,1]=p_up\n",
    "    exit_ret,            # (N,) realized log-ret to TB exit\n",
    "    thr_trade: float,\n",
    "    thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:,1]\n",
    "    p_up = prob_dir[:,1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (cost_bps * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(exit_ret),\n",
    "        \"n_trades\": int(trade_mask.sum()),\n",
    "        \"trade_rate\": float(trade_mask.mean()),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg):\n",
    "    rows = []\n",
    "    for thr_t in cfg[\"thr_trade_grid\"]:\n",
    "        for thr_d in cfg[\"thr_dir_grid\"]:\n",
    "            m = two_stage_pnl_by_threshold(\n",
    "                prob_trade=prob_trade,\n",
    "                prob_dir=prob_dir,\n",
    "                exit_ret=exit_ret,\n",
    "                thr_trade=thr_t,\n",
    "                thr_dir=thr_d,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "            )\n",
    "            rows.append({\"thr_trade\":thr_t, \"thr_dir\":thr_d, **m})\n",
    "    return pd.DataFrame(rows).sort_values([\"pnl_mean\",\"pnl_sum\"], ascending=False)\n",
    "\n",
    "print(\"Two-stage PnL threshold utils ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1635 327 327\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8151 va_loss=0.7821 f1m=0.433 auc=0.463 sel(va_auc)=0.463342 best=none\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7224 va_loss=0.9245 f1m=0.266 auc=0.502 sel(va_auc)=0.501997 best=0.463342@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6897 va_loss=0.7942 f1m=0.378 auc=0.516 sel(va_auc)=0.516023 best=0.501997@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6555 va_loss=0.8018 f1m=0.385 auc=0.547 sel(va_auc)=0.546833 best=0.516023@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6537 va_loss=0.7847 f1m=0.422 auc=0.545 sel(va_auc)=0.545407 best=0.546833@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6531 va_loss=0.7272 f1m=0.502 auc=0.590 sel(va_auc)=0.590386 best=0.546833@ep04\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6399 va_loss=0.8101 f1m=0.449 auc=0.589 sel(va_auc)=0.588769 best=0.590386@ep06\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6299 va_loss=0.7732 f1m=0.476 auc=0.607 sel(va_auc)=0.607027 best=0.590386@ep06\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.5966 va_loss=0.6686 f1m=0.584 auc=0.656 sel(va_auc)=0.656143 best=0.607027@ep08\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.5927 va_loss=0.6569 f1m=0.576 auc=0.657 sel(va_auc)=0.657141 best=0.656143@ep09\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.5785 va_loss=0.7127 f1m=0.589 auc=0.659 sel(va_auc)=0.658901 best=0.657141@ep10\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.5801 va_loss=0.7348 f1m=0.576 auc=0.657 sel(va_auc)=0.657046 best=0.658901@ep11\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.5650 va_loss=0.7073 f1m=0.581 auc=0.666 sel(va_auc)=0.666128 best=0.658901@ep11\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.5367 va_loss=0.6376 f1m=0.600 auc=0.681 sel(va_auc)=0.680867 best=0.666128@ep13\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.5259 va_loss=0.7264 f1m=0.585 auc=0.664 sel(va_auc)=0.663703 best=0.680867@ep14\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.5127 va_loss=0.6890 f1m=0.583 auc=0.668 sel(va_auc)=0.668267 best=0.680867@ep14\n",
      "[trade] ep 17 lr=2.00e-04 tr_loss=0.4780 va_loss=0.7745 f1m=0.560 auc=0.672 sel(va_auc)=0.671596 best=0.680867@ep14\n",
      "[trade] ep 18 lr=2.00e-04 tr_loss=0.4733 va_loss=0.7447 f1m=0.586 auc=0.663 sel(va_auc)=0.663085 best=0.680867@ep14\n",
      "[trade] ep 19 lr=1.00e-04 tr_loss=0.4696 va_loss=0.8005 f1m=0.562 auc=0.660 sel(va_auc)=0.659661 best=0.680867@ep14\n",
      "[trade] ep 20 lr=1.00e-04 tr_loss=0.4521 va_loss=0.7949 f1m=0.562 auc=0.674 sel(va_auc)=0.674116 best=0.680867@ep14\n",
      "[trade] ep 21 lr=1.00e-04 tr_loss=0.4381 va_loss=0.7856 f1m=0.565 auc=0.663 sel(va_auc)=0.663465 best=0.680867@ep14\n",
      "[trade] ep 22 lr=1.00e-04 tr_loss=0.4390 va_loss=0.8210 f1m=0.566 auc=0.661 sel(va_auc)=0.660612 best=0.680867@ep14\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8329 va_loss=0.6757 f1m=0.494 auc=0.567 pnl_max=0.000702 thr=(0.70,0.60) trades=93 sel(va_pnl_max)=0.000702 best=none\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7796 va_loss=0.6646 f1m=0.502 auc=0.580 pnl_max=0.000740 thr=(0.70,0.55) trades=115 sel(va_pnl_max)=0.000740 best=0.000702@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7268 va_loss=0.6645 f1m=0.538 auc=0.575 pnl_max=0.000754 thr=(0.70,0.50) trades=139 sel(va_pnl_max)=0.000754 best=0.000740@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6626 va_loss=0.6782 f1m=0.563 auc=0.569 pnl_max=0.000512 thr=(0.70,0.50) trades=139 sel(va_pnl_max)=0.000512 best=0.000754@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6494 va_loss=0.6983 f1m=0.532 auc=0.547 pnl_max=0.000321 thr=(0.70,0.55) trades=104 sel(va_pnl_max)=0.000321 best=0.000754@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6260 va_loss=0.6932 f1m=0.556 auc=0.533 pnl_max=0.000812 thr=(0.70,0.50) trades=139 sel(va_pnl_max)=0.000812 best=0.000754@ep03\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6371 va_loss=0.7002 f1m=0.503 auc=0.532 pnl_max=0.000692 thr=(0.70,0.55) trades=112 sel(va_pnl_max)=0.000692 best=0.000812@ep06\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.5930 va_loss=0.7163 f1m=0.549 auc=0.538 pnl_max=0.000482 thr=(0.70,0.60) trades=80 sel(va_pnl_max)=0.000482 best=0.000812@ep06\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.5924 va_loss=0.7189 f1m=0.511 auc=0.524 pnl_max=0.000564 thr=(0.70,0.50) trades=139 sel(va_pnl_max)=0.000564 best=0.000812@ep06\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.5488 va_loss=0.7290 f1m=0.518 auc=0.525 pnl_max=0.000530 thr=(0.70,0.50) trades=139 sel(va_pnl_max)=0.000530 best=0.000812@ep06\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.5571 va_loss=0.7414 f1m=0.524 auc=0.522 pnl_max=0.000703 thr=(0.70,0.50) trades=139 sel(va_pnl_max)=0.000703 best=0.000812@ep06\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.5425 va_loss=0.7435 f1m=0.518 auc=0.523 pnl_max=0.000502 thr=(0.70,0.55) trades=118 sel(va_pnl_max)=0.000502 best=0.000812@ep06\n",
      "[dir] ep 13 lr=1.00e-04 tr_loss=0.5456 va_loss=0.7494 f1m=0.517 auc=0.523 pnl_max=0.000605 thr=(0.70,0.50) trades=139 sel(va_pnl_max)=0.000605 best=0.000812@ep06\n",
      "[dir] ep 14 lr=1.00e-04 tr_loss=0.5037 va_loss=0.7563 f1m=0.518 auc=0.521 pnl_max=0.000541 thr=(0.70,0.50) trades=139 sel(va_pnl_max)=0.000541 best=0.000812@ep06\n",
      "PnL on test: | thr_trade= 0.7 | thr_dir= 0.6 | pnl_mean= 0.0002869701129384339 | trades= 73.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1962 327 327\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7657 va_loss=0.6646 f1m=0.567 auc=0.586 sel(va_auc)=0.586104 best=none\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.6807 va_loss=0.6626 f1m=0.593 auc=0.594 sel(va_auc)=0.593974 best=0.586104@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6777 va_loss=0.6559 f1m=0.581 auc=0.589 sel(va_auc)=0.589386 best=0.593974@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6555 va_loss=0.6646 f1m=0.551 auc=0.577 sel(va_auc)=0.576887 best=0.593974@ep02\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6253 va_loss=0.6891 f1m=0.557 auc=0.566 sel(va_auc)=0.566156 best=0.593974@ep02\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6236 va_loss=0.7123 f1m=0.533 auc=0.559 sel(va_auc)=0.559338 best=0.593974@ep02\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6245 va_loss=0.7007 f1m=0.554 auc=0.570 sel(va_auc)=0.569859 best=0.593974@ep02\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6072 va_loss=0.7001 f1m=0.551 auc=0.573 sel(va_auc)=0.572889 best=0.593974@ep02\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.5900 va_loss=0.7121 f1m=0.558 auc=0.577 sel(va_auc)=0.577350 best=0.593974@ep02\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.5900 va_loss=0.7299 f1m=0.577 auc=0.578 sel(va_auc)=0.577897 best=0.593974@ep02\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8468 va_loss=0.7280 f1m=0.470 auc=0.467 pnl_max=0.000109 thr=(0.50,0.60) trades=93 sel(va_pnl_max)=0.000109 best=none\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7480 va_loss=0.7058 f1m=0.508 auc=0.480 pnl_max=0.000328 thr=(0.50,0.50) trades=199 sel(va_pnl_max)=0.000328 best=0.000109@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.6945 va_loss=0.6834 f1m=0.509 auc=0.491 pnl_max=0.000471 thr=(0.50,0.50) trades=199 sel(va_pnl_max)=0.000471 best=0.000328@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6898 va_loss=0.6925 f1m=0.529 auc=0.508 pnl_max=0.000584 thr=(0.50,0.50) trades=199 sel(va_pnl_max)=0.000584 best=0.000471@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6814 va_loss=0.6922 f1m=0.518 auc=0.516 pnl_max=0.000359 thr=(0.50,0.50) trades=199 sel(va_pnl_max)=0.000359 best=0.000584@ep04\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6658 va_loss=0.6975 f1m=0.489 auc=0.522 pnl_max=0.000197 thr=(0.55,0.60) trades=67 sel(va_pnl_max)=0.000197 best=0.000584@ep04\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6308 va_loss=0.6986 f1m=0.493 auc=0.523 pnl_max=0.000201 thr=(0.50,0.55) trades=140 sel(va_pnl_max)=0.000201 best=0.000584@ep04\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.6199 va_loss=0.6970 f1m=0.484 auc=0.521 pnl_max=0.000220 thr=(0.55,0.65) trades=52 sel(va_pnl_max)=0.000220 best=0.000584@ep04\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.5928 va_loss=0.7127 f1m=0.476 auc=0.518 pnl_max=0.000159 thr=(0.50,0.65) trades=66 sel(va_pnl_max)=0.000159 best=0.000584@ep04\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.6007 va_loss=0.7054 f1m=0.486 auc=0.520 pnl_max=0.000261 thr=(0.50,0.65) trades=74 sel(va_pnl_max)=0.000261 best=0.000584@ep04\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.5968 va_loss=0.7212 f1m=0.478 auc=0.514 pnl_max=0.000303 thr=(0.50,0.65) trades=79 sel(va_pnl_max)=0.000303 best=0.000584@ep04\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.5910 va_loss=0.7321 f1m=0.464 auc=0.518 pnl_max=0.000177 thr=(0.50,0.65) trades=75 sel(va_pnl_max)=0.000177 best=0.000584@ep04\n",
      "PnL on test: | thr_trade= 0.65 | thr_dir= 0.6 | pnl_mean= 0.0006744243437424302 | trades= 72.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 2289 327 327\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8054 va_loss=0.6683 f1m=0.508 auc=0.473 sel(va_auc)=0.472635 best=none\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7150 va_loss=0.5901 f1m=0.491 auc=0.451 sel(va_auc)=0.450758 best=0.472635@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6764 va_loss=0.5768 f1m=0.472 auc=0.454 sel(va_auc)=0.453935 best=0.472635@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6607 va_loss=0.6084 f1m=0.499 auc=0.457 sel(va_auc)=0.456606 best=0.472635@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6443 va_loss=0.5691 f1m=0.476 auc=0.468 sel(va_auc)=0.468159 best=0.472635@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.6397 va_loss=0.5738 f1m=0.503 auc=0.471 sel(va_auc)=0.470686 best=0.472635@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6235 va_loss=0.5991 f1m=0.484 auc=0.465 sel(va_auc)=0.465271 best=0.472635@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6151 va_loss=0.6131 f1m=0.482 auc=0.460 sel(va_auc)=0.460000 best=0.472635@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6042 va_loss=0.5796 f1m=0.490 auc=0.463 sel(va_auc)=0.462888 best=0.472635@ep01\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8034 va_loss=0.7418 f1m=0.439 auc=0.514 pnl_max=0.000220 thr=(0.60,0.65) trades=53 sel(va_pnl_max)=0.000220 best=none\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7192 va_loss=0.7019 f1m=0.510 auc=0.552 pnl_max=0.000269 thr=(0.60,0.55) trades=97 sel(va_pnl_max)=0.000269 best=0.000220@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.6770 va_loss=0.6955 f1m=0.463 auc=0.583 pnl_max=0.000574 thr=(0.65,0.60) trades=53 sel(va_pnl_max)=0.000574 best=0.000269@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6746 va_loss=0.7125 f1m=0.433 auc=0.587 pnl_max=0.000542 thr=(0.60,0.65) trades=66 sel(va_pnl_max)=0.000542 best=0.000574@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6294 va_loss=0.6866 f1m=0.543 auc=0.596 pnl_max=0.000604 thr=(0.60,0.60) trades=72 sel(va_pnl_max)=0.000604 best=0.000574@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6234 va_loss=0.6997 f1m=0.506 auc=0.596 pnl_max=0.000586 thr=(0.60,0.65) trades=64 sel(va_pnl_max)=0.000586 best=0.000604@ep05\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6361 va_loss=0.6977 f1m=0.507 auc=0.595 pnl_max=0.000694 thr=(0.60,0.60) trades=78 sel(va_pnl_max)=0.000694 best=0.000604@ep05\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.6267 va_loss=0.6943 f1m=0.551 auc=0.613 pnl_max=0.000770 thr=(0.60,0.65) trades=70 sel(va_pnl_max)=0.000770 best=0.000694@ep07\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.5984 va_loss=0.7044 f1m=0.549 auc=0.604 pnl_max=0.000678 thr=(0.60,0.65) trades=72 sel(va_pnl_max)=0.000678 best=0.000770@ep08\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.5833 va_loss=0.6996 f1m=0.578 auc=0.614 pnl_max=0.000741 thr=(0.50,0.55) trades=178 sel(va_pnl_max)=0.000741 best=0.000770@ep08\n",
      "[dir] ep 11 lr=2.00e-04 tr_loss=0.5818 va_loss=0.7163 f1m=0.555 auc=0.614 pnl_max=0.000605 thr=(0.50,0.65) trades=128 sel(va_pnl_max)=0.000605 best=0.000770@ep08\n",
      "[dir] ep 12 lr=2.00e-04 tr_loss=0.5540 va_loss=0.7041 f1m=0.600 auc=0.617 pnl_max=0.000902 thr=(0.50,0.50) trades=215 sel(va_pnl_max)=0.000902 best=0.000770@ep08\n",
      "[dir] ep 13 lr=2.00e-04 tr_loss=0.5280 va_loss=0.7084 f1m=0.591 auc=0.621 pnl_max=0.000781 thr=(0.50,0.50) trades=215 sel(va_pnl_max)=0.000781 best=0.000902@ep12\n",
      "[dir] ep 14 lr=2.00e-04 tr_loss=0.5090 va_loss=0.7556 f1m=0.554 auc=0.620 pnl_max=0.000794 thr=(0.50,0.55) trades=197 sel(va_pnl_max)=0.000794 best=0.000902@ep12\n",
      "[dir] ep 15 lr=2.00e-04 tr_loss=0.5229 va_loss=0.7240 f1m=0.609 auc=0.626 pnl_max=0.000990 thr=(0.50,0.55) trades=194 sel(va_pnl_max)=0.000990 best=0.000902@ep12\n",
      "[dir] ep 16 lr=2.00e-04 tr_loss=0.4626 va_loss=0.7274 f1m=0.630 auc=0.636 pnl_max=0.000995 thr=(0.50,0.50) trades=215 sel(va_pnl_max)=0.000995 best=0.000990@ep15\n",
      "[dir] ep 17 lr=2.00e-04 tr_loss=0.4416 va_loss=0.8121 f1m=0.574 auc=0.635 pnl_max=0.000906 thr=(0.50,0.50) trades=215 sel(va_pnl_max)=0.000906 best=0.000995@ep16\n",
      "[dir] ep 18 lr=2.00e-04 tr_loss=0.4366 va_loss=0.7581 f1m=0.626 auc=0.647 pnl_max=0.001098 thr=(0.50,0.60) trades=173 sel(va_pnl_max)=0.001098 best=0.000995@ep16\n",
      "[dir] ep 19 lr=2.00e-04 tr_loss=0.4176 va_loss=0.7766 f1m=0.641 auc=0.636 pnl_max=0.001069 thr=(0.50,0.50) trades=215 sel(va_pnl_max)=0.001069 best=0.001098@ep18\n",
      "[dir] ep 20 lr=2.00e-04 tr_loss=0.3717 va_loss=0.7950 f1m=0.624 auc=0.647 pnl_max=0.001124 thr=(0.50,0.55) trades=205 sel(va_pnl_max)=0.001124 best=0.001098@ep18\n",
      "[dir] ep 21 lr=2.00e-04 tr_loss=0.3639 va_loss=0.8310 f1m=0.616 auc=0.643 pnl_max=0.001043 thr=(0.50,0.70) trades=162 sel(va_pnl_max)=0.001043 best=0.001124@ep20\n",
      "[dir] ep 22 lr=2.00e-04 tr_loss=0.3474 va_loss=0.8832 f1m=0.619 auc=0.641 pnl_max=0.000991 thr=(0.50,0.70) trades=166 sel(va_pnl_max)=0.000991 best=0.001124@ep20\n",
      "[dir] ep 23 lr=2.00e-04 tr_loss=0.2958 va_loss=0.9050 f1m=0.637 auc=0.648 pnl_max=0.001258 thr=(0.50,0.60) trades=193 sel(va_pnl_max)=0.001258 best=0.001124@ep20\n",
      "[dir] ep 24 lr=2.00e-04 tr_loss=0.3219 va_loss=0.9660 f1m=0.635 auc=0.637 pnl_max=0.001199 thr=(0.50,0.60) trades=195 sel(va_pnl_max)=0.001199 best=0.001258@ep23\n",
      "[dir] ep 25 lr=2.00e-04 tr_loss=0.3035 va_loss=0.9128 f1m=0.614 auc=0.650 pnl_max=0.001300 thr=(0.50,0.55) trades=207 sel(va_pnl_max)=0.001300 best=0.001258@ep23\n",
      "[dir] ep 26 lr=2.00e-04 tr_loss=0.2716 va_loss=0.9611 f1m=0.620 auc=0.643 pnl_max=0.001280 thr=(0.50,0.70) trades=172 sel(va_pnl_max)=0.001280 best=0.001300@ep25\n",
      "[dir] ep 27 lr=2.00e-04 tr_loss=0.2450 va_loss=1.0338 f1m=0.628 auc=0.630 pnl_max=0.001092 thr=(0.50,0.55) trades=207 sel(va_pnl_max)=0.001092 best=0.001300@ep25\n",
      "[dir] ep 28 lr=2.00e-04 tr_loss=0.2401 va_loss=1.0956 f1m=0.647 auc=0.629 pnl_max=0.001360 thr=(0.50,0.50) trades=215 sel(va_pnl_max)=0.001360 best=0.001300@ep25\n",
      "[dir] ep 29 lr=2.00e-04 tr_loss=0.2518 va_loss=1.1166 f1m=0.623 auc=0.617 pnl_max=0.001119 thr=(0.50,0.60) trades=200 sel(va_pnl_max)=0.001119 best=0.001360@ep28\n",
      "[dir] ep 30 lr=2.00e-04 tr_loss=0.1976 va_loss=1.2867 f1m=0.587 auc=0.599 pnl_max=0.000722 thr=(0.50,0.60) trades=196 sel(va_pnl_max)=0.000722 best=0.001360@ep28\n",
      "PnL on test: | thr_trade= 0.7 | thr_dir= 0.5 | pnl_mean= -0.00030635003349743783 | trades= 34.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 2616 327 327\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7754 va_loss=0.6463 f1m=0.557 auc=0.655 sel(va_auc)=0.655247 best=none\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.6762 va_loss=0.6181 f1m=0.609 auc=0.673 sel(va_auc)=0.673264 best=0.655247@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6655 va_loss=0.5996 f1m=0.629 auc=0.697 sel(va_auc)=0.697222 best=0.673264@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6459 va_loss=0.5985 f1m=0.644 auc=0.704 sel(va_auc)=0.704398 best=0.697222@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6371 va_loss=0.5958 f1m=0.630 auc=0.705 sel(va_auc)=0.704514 best=0.704398@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6288 va_loss=0.5994 f1m=0.632 auc=0.723 sel(va_auc)=0.722762 best=0.704514@ep05\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6048 va_loss=0.6117 f1m=0.594 auc=0.716 sel(va_auc)=0.716358 best=0.722762@ep06\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.5869 va_loss=0.5979 f1m=0.632 auc=0.720 sel(va_auc)=0.719715 best=0.722762@ep06\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.5803 va_loss=0.6380 f1m=0.577 auc=0.712 sel(va_auc)=0.712269 best=0.722762@ep06\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.5718 va_loss=0.6764 f1m=0.565 auc=0.707 sel(va_auc)=0.706944 best=0.722762@ep06\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.5622 va_loss=0.6310 f1m=0.596 auc=0.706 sel(va_auc)=0.706019 best=0.722762@ep06\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.5473 va_loss=0.6332 f1m=0.595 auc=0.702 sel(va_auc)=0.701659 best=0.722762@ep06\n",
      "[trade] ep 13 lr=1.00e-04 tr_loss=0.5348 va_loss=0.6748 f1m=0.570 auc=0.697 sel(va_auc)=0.697377 best=0.722762@ep06\n",
      "[trade] ep 14 lr=1.00e-04 tr_loss=0.5273 va_loss=0.6800 f1m=0.570 auc=0.691 sel(va_auc)=0.690625 best=0.722762@ep06\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7612 va_loss=0.8904 f1m=0.309 auc=0.610 pnl_max=-0.000253 thr=(0.60,0.70) trades=59 sel(va_pnl_max)=-0.000253 best=none\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.6928 va_loss=0.8901 f1m=0.308 auc=0.579 pnl_max=-0.000159 thr=(0.55,0.70) trades=50 sel(va_pnl_max)=-0.000159 best=-0.000253@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.6802 va_loss=0.8507 f1m=0.327 auc=0.579 pnl_max=-0.000314 thr=(0.65,0.65) trades=52 sel(va_pnl_max)=-0.000314 best=-0.000159@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6589 va_loss=0.8318 f1m=0.379 auc=0.582 pnl_max=-0.000326 thr=(0.70,0.65) trades=50 sel(va_pnl_max)=-0.000326 best=-0.000159@ep02\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6480 va_loss=0.8172 f1m=0.432 auc=0.570 pnl_max=-0.000307 thr=(0.70,0.50) trades=127 sel(va_pnl_max)=-0.000307 best=-0.000159@ep02\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6381 va_loss=0.8755 f1m=0.357 auc=0.571 pnl_max=-0.000303 thr=(0.70,0.65) trades=61 sel(va_pnl_max)=-0.000303 best=-0.000159@ep02\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.6203 va_loss=0.8552 f1m=0.396 auc=0.580 pnl_max=-0.000222 thr=(0.60,0.70) trades=58 sel(va_pnl_max)=-0.000222 best=-0.000159@ep02\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6100 va_loss=0.8331 f1m=0.427 auc=0.568 pnl_max=-0.000151 thr=(0.70,0.65) trades=61 sel(va_pnl_max)=-0.000151 best=-0.000159@ep02\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6009 va_loss=0.8565 f1m=0.417 auc=0.566 pnl_max=-0.000275 thr=(0.60,0.70) trades=58 sel(va_pnl_max)=-0.000275 best=-0.000151@ep08\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.5943 va_loss=0.8544 f1m=0.416 auc=0.586 pnl_max=-0.000344 thr=(0.60,0.70) trades=61 sel(va_pnl_max)=-0.000344 best=-0.000151@ep08\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.5784 va_loss=0.9101 f1m=0.422 auc=0.580 pnl_max=-0.000456 thr=(0.70,0.70) trades=59 sel(va_pnl_max)=-0.000456 best=-0.000151@ep08\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.5712 va_loss=0.8971 f1m=0.414 auc=0.564 pnl_max=-0.000302 thr=(0.70,0.70) trades=54 sel(va_pnl_max)=-0.000302 best=-0.000151@ep08\n",
      "[dir] ep 13 lr=5.00e-05 tr_loss=0.5508 va_loss=0.9307 f1m=0.423 auc=0.549 pnl_max=-0.000336 thr=(0.70,0.65) trades=76 sel(va_pnl_max)=-0.000336 best=-0.000151@ep08\n",
      "[dir] ep 14 lr=5.00e-05 tr_loss=0.5553 va_loss=0.9386 f1m=0.411 auc=0.547 pnl_max=-0.000325 thr=(0.70,0.65) trades=77 sel(va_pnl_max)=-0.000325 best=-0.000151@ep08\n",
      "[dir] ep 15 lr=5.00e-05 tr_loss=0.5558 va_loss=0.9501 f1m=0.406 auc=0.547 pnl_max=-0.000286 thr=(0.70,0.65) trades=79 sel(va_pnl_max)=-0.000286 best=-0.000151@ep08\n",
      "[dir] ep 16 lr=5.00e-05 tr_loss=0.5461 va_loss=0.9593 f1m=0.404 auc=0.541 pnl_max=-0.000268 thr=(0.70,0.65) trades=79 sel(va_pnl_max)=-0.000268 best=-0.000151@ep08\n",
      "PnL on test: | thr_trade= 0.7 | thr_dir= 0.55 | pnl_mean= 0.00036208672099746764 | trades= 157.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.510597</td>\n",
       "      <td>0.527814</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.223242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.448320</td>\n",
       "      <td>0.525247</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.220183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.608266</td>\n",
       "      <td>0.408748</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.103976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.570344</td>\n",
       "      <td>0.466175</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.55</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.480122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.510597      0.527814       0.000287            0.70   \n",
       "1     2        0.448320      0.525247       0.000674            0.65   \n",
       "2     3        0.608266      0.408748      -0.000306            0.70   \n",
       "3     4        0.570344      0.466175       0.000362            0.70   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0          0.60           73.0         0.223242  \n",
       "1          0.60           72.0         0.220183  \n",
       "2          0.50           34.0         0.103976  \n",
       "3          0.55          157.0         0.480122  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "fold                2.500000\n",
      "trade_test_f1m      0.534382\n",
      "dir_test_f1m        0.481996\n",
      "best_pnl_mean       0.000254\n",
      "best_thr_trade      0.687500\n",
      "best_thr_dir        0.562500\n",
      "n_trades_best      84.000000\n",
      "trade_rate_best     0.256881\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples (по AUC)\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\",\n",
    "        select_metric=\"va_auc\",\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples (train/val/test индексы фильтруем)\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # dir: учим на trade-only, но PnL-proxy считаем на полном idx_va (full val)\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\",\n",
    "        select_metric=\"va_pnl_max\",\n",
    "        trade_model_for_pnl=m_trade,\n",
    "        idx_val_pnl=idx_va,   # <-- полный val для pnl-proxy\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on TEST (как раньше)\n",
    "    @torch.no_grad()\n",
    "    def predict_probs_on_indices(model, X_scaled, edge_feat, indices):\n",
    "        ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, CFG[\"lookback\"])\n",
    "        loader = DataLoader(ds, batch_size=CFG[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "        model.eval()\n",
    "        probs = []\n",
    "        ers = []\n",
    "        for x, e, yt, yd, er in loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "            p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            probs.append(p)\n",
    "            ers.append(er.cpu().numpy())\n",
    "        return np.concatenate(probs), np.concatenate(ers)\n",
    "\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te)\n",
    "    prob_dir_te, _ = predict_probs_on_indices(m_dir, X_scaled, edge_feat, idx_te)\n",
    "\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN:\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
