{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),\n",
    "\n",
    "    \"lookback\": 96,\n",
    "    \"tb_horizon\": 24,          \n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 96],  # 30m,1h,2h,4h,8h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 1*12,       # 1h     # нужен для sample_t (чтобы TB-exit не вылезал за конец)\n",
    "    \"tb_vol_window\": 8*12,    # 8h\n",
    "    \"tb_pt_mult\": 2,\n",
    "    \"tb_sl_mult\": 1.5,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "    # training (общие)\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.15,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "print(\"EDGE_INDEX:\", EDGE_INDEX.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (3367, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (3367, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [ 669 2275  423]\n",
      "Trade ratio: 0.32432432432432434\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=1*12, \n",
    "    vol_window=8*12,\n",
    "    pt_mult=2,\n",
    "    sl_mult=1.5,\n",
    "    min_barrier=0.001,\n",
    "    max_barrier=0.006,\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (3367, 3, 15) edge_feat: (3367, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 3259 t range: 95 3353\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1629 | val 325 | test 325\n",
      " fold 2: train 1954 | val 325 | test 325\n",
      " fold 3: train 2279 | val 325 | test 325\n",
      " fold 4: train 2604 | val 325 | test 325\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "        idx_train = np.arange(0, tr_end)\n",
    "        idx_val   = np.arange(tr_end, va_end)\n",
    "        idx_test  = np.arange(va_end, te_end)\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "    return splits\n",
    "\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "\n",
    "for i, (a,b,c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: GNN + LSTM classifier (универсальный под 2 класса)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class EdgeGatedMP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_proj = nn.Linear(in_dim, hidden)\n",
    "        self.ln0 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden + edge_dim, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden + 1)  # msg(hidden) + gate(1)\n",
    "        )\n",
    "\n",
    "        self.upd = nn.Sequential(\n",
    "            nn.Linear(2*hidden, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward_once(self, x_t, edge_attr_t, edge_index):\n",
    "        B, N, _ = x_t.shape\n",
    "        E = edge_index.shape[0]\n",
    "\n",
    "        h = self.ln0(self.node_proj(x_t))  # (B,N,H)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        agg = torch.zeros((B, N, h.shape[-1]), device=h.device, dtype=h.dtype)\n",
    "\n",
    "        for e in range(E):\n",
    "            src = edge_index[e, 0].item()\n",
    "            dst = edge_index[e, 1].item()\n",
    "            h_src = h[:, src, :]\n",
    "            h_dst = h[:, dst, :]\n",
    "            ea = edge_attr_t[:, e, :]\n",
    "\n",
    "            z = torch.cat([h_src, h_dst, ea], dim=-1)\n",
    "            out = self.edge_mlp(z)\n",
    "            msg = out[:, :-1]\n",
    "            gate = torch.sigmoid(out[:, -1:])\n",
    "\n",
    "            agg[:, dst, :] += msg * gate\n",
    "\n",
    "        h2 = self.upd(torch.cat([h, agg], dim=-1))\n",
    "        h2 = self.ln1(h + self.dropout(h2))\n",
    "        h2 = torch.nan_to_num(h2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return h2\n",
    "\n",
    "    def forward(self, x_seq, e_seq, edge_index):\n",
    "        B, L, N, Fin = x_seq.shape\n",
    "        h_out = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            h_out.append(ht)\n",
    "        return torch.stack(h_out, dim=1)  # (B,L,N,H)\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = target_node\n",
    "\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(gnn_layers):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(EdgeGatedMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, dropout=dropout))\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(lstm_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, lstm_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, n_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        out, _ = self.lstm(h_tgt)\n",
    "        last = out[:, -1, :]\n",
    "        logits = self.head(last)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"Model ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn, y_key: str = \"trade\"):\n",
    "    \"\"\"\n",
    "    y_key:\n",
    "      - \"trade\": использовать y_trade_b\n",
    "      - \"dir\":   использовать y_dir_b\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "\n",
    "        y = (y_trade_b if y_key == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))  # (B,2)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()  # (B,2)\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "\n",
    "    ys = np.concatenate(ys) if len(ys) else np.array([], dtype=np.int64)\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, None, ys, probs, ers\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:, 1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss / max(n, 1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "\n",
    "def make_pos_weight(y01: np.ndarray):\n",
    "    pos = max(1, int((y01 == 1).sum()))\n",
    "    neg = max(1, int((y01 == 0).sum()))\n",
    "    return float(neg / pos)\n",
    "\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "    select_metric: str | None = None,   # \"va_auc\" | \"va_f1m\"\n",
    "):\n",
    "    \"\"\"\n",
    "    stage_name:\n",
    "      - \"trade\": обучаем y_trade на всех samples\n",
    "      - \"dir\":   обучаем y_dir только на trade samples (idx_* уже должны быть отфильтрованы)\n",
    "\n",
    "    select_metric:\n",
    "      - None: по умолчанию trade->va_auc, dir->va_auc\n",
    "      - \"va_auc\" или \"va_f1m\"\n",
    "    \"\"\"\n",
    "    if select_metric is None:\n",
    "        select_metric = \"va_auc\"  # дефолт для обоих; вызовы ниже зададут явно как нужно\n",
    "\n",
    "    if select_metric not in (\"va_auc\", \"va_f1m\"):\n",
    "        raise ValueError(\"select_metric must be one of: 'va_auc', 'va_f1m'\")\n",
    "\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val, L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test, L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True, drop_last=True, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # label extraction (на всякий)\n",
    "    if stage_name == \"trade\":\n",
    "        ytr = y_trade_arr[sample_t[idx_train]]\n",
    "    elif stage_name == \"dir\":\n",
    "        ytr = y_dir_arr[sample_t[idx_train]]\n",
    "    else:\n",
    "        raise ValueError(\"stage_name must be 'trade' or 'dir'\")\n",
    "\n",
    "    _ = make_pos_weight(ytr)  # сейчас не используем, но оставлено как хук\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\"))\n",
    "\n",
    "    best_score = -1e18\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\"tr_loss\": [], \"va_loss\": [], \"va_f1m\": [], \"va_auc\": [], \"va_sel\": []}\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"] + 1):\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for x, e, y_trade_b, y_dir_b, er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            y = (y_trade_b if stage_name == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot / max(n, 1)\n",
    "\n",
    "        # ---- VAL (быстрый прогон: получаем probs + метрики после каждой эпохи)\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, va_loader, loss_fn, y_key=stage_name\n",
    "        )\n",
    "\n",
    "        # metric selection\n",
    "        sel_val = va_auc if select_metric == \"va_auc\" else va_f1m\n",
    "        if not np.isfinite(sel_val):\n",
    "            sel_val = -1e18\n",
    "\n",
    "        sch.step(float(sel_val))\n",
    "\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "        hist[\"va_sel\"].append(sel_val)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "        best_str = f\"{best_score:.4f}@ep{best_epoch:02d}\" if best_epoch > 0 else \"none\"\n",
    "        print(\n",
    "            f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "            f\"tr={tr_loss:.4f} va={va_loss:.4f} \"\n",
    "            f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "            f\"sel({select_metric})={sel_val:.4f} best={best_str}\"\n",
    "        )\n",
    "\n",
    "        if sel_val > best_score:\n",
    "            best_score = sel_val\n",
    "            best_epoch = ep\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # финальные VAL/TEST уже по best_state (чтобы дальше удобно выбирать пороги по VAL PnL)\n",
    "    va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "        model, va_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(\n",
    "        model, te_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": float(best_score),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"select_metric\": select_metric,\n",
    "\n",
    "        \"val_loss\": va_loss,\n",
    "        \"val_acc\": va_acc,\n",
    "        \"val_f1m\": va_f1m,\n",
    "        \"val_auc\": va_auc,\n",
    "        \"val_cm\": va_cm,\n",
    "        \"val_y\": va_y,\n",
    "        \"val_prob\": va_prob,\n",
    "        \"val_er\": va_er,\n",
    "\n",
    "        \"test_loss\": te_loss,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_f1m\": te_f1m,\n",
    "        \"test_auc\": te_auc,\n",
    "        \"test_cm\": te_cm,\n",
    "        \"test_y\": te_y,\n",
    "        \"test_prob\": te_prob,\n",
    "        \"test_er\": te_er,\n",
    "\n",
    "        \"hist\": hist,\n",
    "    }\n",
    "    return model, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: PnL по порогам уверенности (two-stage)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade,          # (N,2) softmax: [:,1]=p_trade\n",
    "    prob_dir,            # (N,2) softmax: [:,1]=p_up\n",
    "    exit_ret,            # (N,) realized log-ret to TB exit\n",
    "    thr_trade: float,\n",
    "    thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:,1]\n",
    "    p_up = prob_dir[:,1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (cost_bps * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(exit_ret),\n",
    "        \"n_trades\": int(trade_mask.sum()),\n",
    "        \"trade_rate\": float(trade_mask.mean()),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg):\n",
    "    rows = []\n",
    "    for thr_t in cfg[\"thr_trade_grid\"]:\n",
    "        for thr_d in cfg[\"thr_dir_grid\"]:\n",
    "            m = two_stage_pnl_by_threshold(\n",
    "                prob_trade=prob_trade,\n",
    "                prob_dir=prob_dir,\n",
    "                exit_ret=exit_ret,\n",
    "                thr_trade=thr_t,\n",
    "                thr_dir=thr_d,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "            )\n",
    "            rows.append({\"thr_trade\":thr_t, \"thr_dir\":thr_d, **m})\n",
    "    return pd.DataFrame(rows).sort_values([\"pnl_mean\",\"pnl_sum\"], ascending=False)\n",
    "\n",
    "print(\"Two-stage PnL threshold utils ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1629 325 325\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.8078 va=0.9646 f1m=0.376 auc=0.515 sel(va_auc)=0.5149 best=none\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.5065 va=1.2164 f1m=0.358 auc=0.498 sel(va_auc)=0.4975 best=0.5149@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.4702 va=1.1207 f1m=0.358 auc=0.473 sel(va_auc)=0.4727 best=0.5149@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.4596 va=1.0036 f1m=0.358 auc=0.464 sel(va_auc)=0.4635 best=0.5149@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.4426 va=0.9679 f1m=0.358 auc=0.477 sel(va_auc)=0.4772 best=0.5149@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr=0.4558 va=0.9840 f1m=0.358 auc=0.506 sel(va_auc)=0.5059 best=0.5149@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.4425 va=0.9770 f1m=0.358 auc=0.518 sel(va_auc)=0.5183 best=0.5149@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.4377 va=0.9556 f1m=0.358 auc=0.523 sel(va_auc)=0.5228 best=0.5183@ep07\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.4300 va=0.9405 f1m=0.358 auc=0.529 sel(va_auc)=0.5289 best=0.5228@ep08\n",
      "[trade] ep 10 lr=1.00e-04 tr=0.4208 va=0.9392 f1m=0.358 auc=0.533 sel(va_auc)=0.5326 best=0.5289@ep09\n",
      "[trade] ep 11 lr=1.00e-04 tr=0.4263 va=0.9423 f1m=0.358 auc=0.536 sel(va_auc)=0.5359 best=0.5326@ep10\n",
      "[trade] ep 12 lr=1.00e-04 tr=0.4112 va=0.9531 f1m=0.358 auc=0.537 sel(va_auc)=0.5372 best=0.5359@ep11\n",
      "[trade] ep 13 lr=1.00e-04 tr=0.4161 va=0.9594 f1m=0.358 auc=0.536 sel(va_auc)=0.5359 best=0.5372@ep12\n",
      "[trade] ep 14 lr=1.00e-04 tr=0.4154 va=0.9510 f1m=0.358 auc=0.538 sel(va_auc)=0.5384 best=0.5372@ep12\n",
      "[trade] ep 15 lr=1.00e-04 tr=0.4151 va=0.9409 f1m=0.358 auc=0.542 sel(va_auc)=0.5417 best=0.5384@ep14\n",
      "[trade] ep 16 lr=1.00e-04 tr=0.4169 va=0.9371 f1m=0.358 auc=0.543 sel(va_auc)=0.5433 best=0.5417@ep15\n",
      "[trade] ep 17 lr=1.00e-04 tr=0.4100 va=0.9513 f1m=0.358 auc=0.545 sel(va_auc)=0.5445 best=0.5433@ep16\n",
      "[trade] ep 18 lr=1.00e-04 tr=0.4133 va=0.9522 f1m=0.358 auc=0.544 sel(va_auc)=0.5440 best=0.5445@ep17\n",
      "[trade] ep 19 lr=1.00e-04 tr=0.4060 va=0.9315 f1m=0.356 auc=0.543 sel(va_auc)=0.5431 best=0.5445@ep17\n",
      "[trade] ep 20 lr=1.00e-04 tr=0.4045 va=0.9345 f1m=0.355 auc=0.545 sel(va_auc)=0.5449 best=0.5445@ep17\n",
      "[trade] ep 21 lr=1.00e-04 tr=0.3947 va=0.9557 f1m=0.355 auc=0.546 sel(va_auc)=0.5464 best=0.5449@ep20\n",
      "[trade] ep 22 lr=1.00e-04 tr=0.3946 va=0.9483 f1m=0.354 auc=0.552 sel(va_auc)=0.5522 best=0.5464@ep21\n",
      "[trade] ep 23 lr=1.00e-04 tr=0.3853 va=0.9416 f1m=0.353 auc=0.554 sel(va_auc)=0.5543 best=0.5522@ep22\n",
      "[trade] ep 24 lr=1.00e-04 tr=0.3909 va=0.9442 f1m=0.353 auc=0.555 sel(va_auc)=0.5551 best=0.5543@ep23\n",
      "[trade] ep 25 lr=1.00e-04 tr=0.3838 va=0.9488 f1m=0.360 auc=0.558 sel(va_auc)=0.5575 best=0.5551@ep24\n",
      "[trade] ep 26 lr=1.00e-04 tr=0.3756 va=0.9469 f1m=0.360 auc=0.558 sel(va_auc)=0.5581 best=0.5575@ep25\n",
      "[trade] ep 27 lr=1.00e-04 tr=0.3886 va=0.9392 f1m=0.382 auc=0.553 sel(va_auc)=0.5532 best=0.5581@ep26\n",
      "[trade] ep 28 lr=1.00e-04 tr=0.3812 va=0.9326 f1m=0.389 auc=0.553 sel(va_auc)=0.5526 best=0.5581@ep26\n",
      "[trade] ep 29 lr=1.00e-04 tr=0.3700 va=0.9552 f1m=0.396 auc=0.551 sel(va_auc)=0.5506 best=0.5581@ep26\n",
      "[trade] ep 30 lr=1.00e-04 tr=0.3554 va=0.9947 f1m=0.382 auc=0.550 sel(va_auc)=0.5498 best=0.5581@ep26\n",
      "[dir] skip: not enough trade samples in this fold.\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1954 325 325\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.5861 va=0.8311 f1m=0.384 auc=0.430 sel(va_auc)=0.4300 best=none\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.5294 va=0.7473 f1m=0.451 auc=0.464 sel(va_auc)=0.4642 best=0.4300@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.5181 va=0.7441 f1m=0.454 auc=0.457 sel(va_auc)=0.4570 best=0.4642@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.4791 va=0.7577 f1m=0.447 auc=0.455 sel(va_auc)=0.4554 best=0.4642@ep02\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.4805 va=0.7601 f1m=0.459 auc=0.457 sel(va_auc)=0.4570 best=0.4642@ep02\n",
      "[trade] ep 06 lr=2.00e-04 tr=0.4675 va=0.7567 f1m=0.463 auc=0.457 sel(va_auc)=0.4573 best=0.4642@ep02\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.4566 va=0.7599 f1m=0.476 auc=0.456 sel(va_auc)=0.4559 best=0.4642@ep02\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.4578 va=0.7701 f1m=0.476 auc=0.456 sel(va_auc)=0.4562 best=0.4642@ep02\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.4509 va=0.7788 f1m=0.482 auc=0.458 sel(va_auc)=0.4581 best=0.4642@ep02\n",
      "[trade] ep 10 lr=1.00e-04 tr=0.4599 va=0.7762 f1m=0.470 auc=0.461 sel(va_auc)=0.4612 best=0.4642@ep02\n",
      "[dir] skip: not enough trade samples in this fold.\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 2279 325 325\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.7630 va=1.0355 f1m=0.315 auc=0.422 sel(va_auc)=0.4217 best=none\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.5817 va=0.9124 f1m=0.315 auc=0.410 sel(va_auc)=0.4098 best=0.4217@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.5340 va=0.8587 f1m=0.336 auc=0.411 sel(va_auc)=0.4115 best=0.4217@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.5315 va=0.8988 f1m=0.313 auc=0.418 sel(va_auc)=0.4184 best=0.4217@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5210 va=0.8676 f1m=0.348 auc=0.413 sel(va_auc)=0.4128 best=0.4217@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr=0.5038 va=0.8482 f1m=0.356 auc=0.409 sel(va_auc)=0.4089 best=0.4217@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.5072 va=0.8654 f1m=0.362 auc=0.404 sel(va_auc)=0.4042 best=0.4217@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.5145 va=0.8716 f1m=0.360 auc=0.401 sel(va_auc)=0.4005 best=0.4217@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.4949 va=0.8734 f1m=0.379 auc=0.396 sel(va_auc)=0.3964 best=0.4217@ep01\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.9876 va=0.7683 f1m=0.547 auc=0.599 sel(va_auc)=0.5989 best=none\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.8601 va=0.6866 f1m=0.585 auc=0.573 sel(va_auc)=0.5731 best=0.5989@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.8037 va=0.6737 f1m=0.524 auc=0.553 sel(va_auc)=0.5535 best=0.5989@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.7655 va=0.6702 f1m=0.483 auc=0.547 sel(va_auc)=0.5469 best=0.5989@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.7273 va=0.6684 f1m=0.476 auc=0.548 sel(va_auc)=0.5483 best=0.5989@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr=0.7146 va=0.6698 f1m=0.477 auc=0.551 sel(va_auc)=0.5510 best=0.5989@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr=0.7015 va=0.6730 f1m=0.484 auc=0.556 sel(va_auc)=0.5564 best=0.5989@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6950 va=0.6767 f1m=0.512 auc=0.559 sel(va_auc)=0.5590 best=0.5989@ep01\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.7012 va=0.6787 f1m=0.522 auc=0.563 sel(va_auc)=0.5630 best=0.5989@ep01\n",
      "PnL on test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 4.261923459125683e-05 | trades= 2.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 2604 325 325\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.7376 va=0.7131 f1m=0.514 auc=0.604 sel(va_auc)=0.6036 best=none\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.6060 va=0.6912 f1m=0.569 auc=0.638 sel(va_auc)=0.6380 best=0.6036@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.5871 va=0.6876 f1m=0.539 auc=0.654 sel(va_auc)=0.6541 best=0.6380@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.5689 va=0.6813 f1m=0.555 auc=0.659 sel(va_auc)=0.6588 best=0.6541@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5584 va=0.6677 f1m=0.576 auc=0.668 sel(va_auc)=0.6678 best=0.6588@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr=0.5372 va=0.6650 f1m=0.609 auc=0.664 sel(va_auc)=0.6637 best=0.6678@ep05\n",
      "[trade] ep 07 lr=2.00e-04 tr=0.5445 va=0.6849 f1m=0.569 auc=0.656 sel(va_auc)=0.6560 best=0.6678@ep05\n",
      "[trade] ep 08 lr=2.00e-04 tr=0.5308 va=0.6695 f1m=0.598 auc=0.662 sel(va_auc)=0.6621 best=0.6678@ep05\n",
      "[trade] ep 09 lr=2.00e-04 tr=0.5212 va=0.6770 f1m=0.574 auc=0.662 sel(va_auc)=0.6622 best=0.6678@ep05\n",
      "[trade] ep 10 lr=1.00e-04 tr=0.5267 va=0.6666 f1m=0.595 auc=0.667 sel(va_auc)=0.6671 best=0.6678@ep05\n",
      "[trade] ep 11 lr=1.00e-04 tr=0.5075 va=0.6690 f1m=0.597 auc=0.665 sel(va_auc)=0.6649 best=0.6678@ep05\n",
      "[trade] ep 12 lr=1.00e-04 tr=0.5113 va=0.6795 f1m=0.595 auc=0.656 sel(va_auc)=0.6559 best=0.6678@ep05\n",
      "[trade] ep 13 lr=1.00e-04 tr=0.4976 va=0.6784 f1m=0.612 auc=0.652 sel(va_auc)=0.6520 best=0.6678@ep05\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.7882 va=0.5540 f1m=0.497 auc=0.537 sel(va_auc)=0.5369 best=none\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7653 va=0.6521 f1m=0.546 auc=0.563 sel(va_auc)=0.5633 best=0.5369@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7408 va=0.7365 f1m=0.435 auc=0.596 sel(va_auc)=0.5962 best=0.5633@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.7595 va=0.7564 f1m=0.418 auc=0.614 sel(va_auc)=0.6141 best=0.5962@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.7358 va=0.7413 f1m=0.434 auc=0.664 sel(va_auc)=0.6635 best=0.6141@ep04\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.7068 va=0.6925 f1m=0.500 auc=0.678 sel(va_auc)=0.6776 best=0.6635@ep05\n",
      "[dir] ep 07 lr=2.00e-04 tr=0.6975 va=0.6473 f1m=0.502 auc=0.669 sel(va_auc)=0.6687 best=0.6776@ep06\n",
      "[dir] ep 08 lr=2.00e-04 tr=0.6860 va=0.6024 f1m=0.572 auc=0.661 sel(va_auc)=0.6607 best=0.6776@ep06\n",
      "[dir] ep 09 lr=2.00e-04 tr=0.6796 va=0.5733 f1m=0.533 auc=0.656 sel(va_auc)=0.6560 best=0.6776@ep06\n",
      "[dir] ep 10 lr=2.00e-04 tr=0.6687 va=0.5557 f1m=0.543 auc=0.642 sel(va_auc)=0.6419 best=0.6776@ep06\n",
      "[dir] ep 11 lr=1.00e-04 tr=0.6622 va=0.5442 f1m=0.539 auc=0.614 sel(va_auc)=0.6141 best=0.6776@ep06\n",
      "[dir] ep 12 lr=1.00e-04 tr=0.6822 va=0.5466 f1m=0.539 auc=0.615 sel(va_auc)=0.6151 best=0.6776@ep06\n",
      "[dir] ep 13 lr=1.00e-04 tr=0.6576 va=0.5525 f1m=0.534 auc=0.616 sel(va_auc)=0.6160 best=0.6776@ep06\n",
      "[dir] ep 14 lr=1.00e-04 tr=0.6535 va=0.5649 f1m=0.548 auc=0.620 sel(va_auc)=0.6198 best=0.6776@ep06\n",
      "PnL on test: | thr_trade= 0.5 | thr_dir= 0.6 | pnl_mean= 0.0005287145613692701 | trades= 29.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.381990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.366628</td>\n",
       "      <td>0.362333</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.501635</td>\n",
       "      <td>0.529387</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.089231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.386792           NaN            NaN             NaN   \n",
       "1     2        0.381990           NaN            NaN             NaN   \n",
       "2     3        0.366628      0.362333       0.000043             0.5   \n",
       "3     4        0.501635      0.529387       0.000529             0.5   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0           NaN            NaN              NaN  \n",
       "1           NaN            NaN              NaN  \n",
       "2           0.5            2.0         0.006154  \n",
       "3           0.6           29.0         0.089231  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "fold                2.500000\n",
      "trade_test_f1m      0.409261\n",
      "dir_test_f1m        0.445860\n",
      "best_pnl_mean       0.000286\n",
      "best_thr_trade      0.500000\n",
      "best_thr_dir        0.550000\n",
      "n_trades_best      15.500000\n",
      "trade_rate_best     0.047692\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\",\n",
    "        select_metric=CFG.get(\"select_metric_trade\", \"va_auc\"),   # <-- Stage A: va_auc\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    # если в какой-то части trade почти нет — пропускаем fold direction\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\",\n",
    "        select_metric=CFG.get(\"select_metric_dir\", \"va_auc\"),     # <-- Stage B: va_auc или va_f1m\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on TEST (в sample-space idx_te)\n",
    "    # helper: get probs on arbitrary indices\n",
    "    @torch.no_grad()\n",
    "    def predict_probs_on_indices(model, X_scaled, edge_feat, indices):\n",
    "        ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, CFG[\"lookback\"])\n",
    "        loader = DataLoader(ds, batch_size=CFG[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "        model.eval()\n",
    "        probs = []\n",
    "        ers = []\n",
    "        for x, e, yt, yd, er in loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "            p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            probs.append(p)\n",
    "            ers.append(er.cpu().numpy())\n",
    "        return np.concatenate(probs), np.concatenate(ers)\n",
    "\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te)\n",
    "    prob_dir_te, _ = predict_probs_on_indices(m_dir, X_scaled, edge_feat, idx_te)\n",
    "\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN:\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
