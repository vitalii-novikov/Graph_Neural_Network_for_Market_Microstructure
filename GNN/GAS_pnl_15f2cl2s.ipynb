{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX (with self-loops): [[0, 1], [0, 2], [2, 1], [0, 0], [1, 1], [2, 2]]\n",
      "CFG thresholds updated.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),  \n",
    "    # NEW: holdout final test split (по времени, на sample-space)\n",
    "    \"final_test_frac\": 0.10, \n",
    "\n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 84],  # 30m,1h,2h,4h,7h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 1*12,       # 1h     # нужен для sample_t (чтобы TB-exit не вылезал за конец)\n",
    "    \"lookback\": 7*12,   \n",
    "    \"tb_pt_mult\": 1.2,\n",
    "    \"tb_sl_mult\": 1.1,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "    # training (общие)\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.2,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "\n",
    "    \"proxy_min_trades\": 20,        # защита от \"лучший pnl = 0 потому что 0 трейдов\"\n",
    "\n",
    "        # --- GAT (spatial)\n",
    "    \"gat_heads\": 2,          # попробуй 1/2/4 (hidden не обязан делиться идеально)\n",
    "\n",
    "    # --- TCN (temporal)\n",
    "    \"tcn_channels\": 64,      # ширина temporal-канала\n",
    "    \"tcn_layers\": 3,         # число residual TCN блоков\n",
    "    \"tcn_kernel\": 2,         # kernel size\n",
    "    \"tcn_dropout\": 0.2,      # обычно = CFG[\"dropout\"]\n",
    "    \"tcn_causal\": True,      # True = no leakage (рекомендуется)\n",
    "    \"tcn_pool\": \"mean\",      # \"last\" или \"mean\"\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "\n",
    "def add_self_loops_edge_index(edge_index: torch.Tensor, num_nodes: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    edge_index: (E,2) [src,dst]\n",
    "    returns: (E+N,2) with added (i,i)\n",
    "    \"\"\"\n",
    "    loops = torch.arange(num_nodes, dtype=edge_index.dtype).view(-1, 1)\n",
    "    loops = torch.cat([loops, loops], dim=1)  # (N,2) i->i\n",
    "    return torch.cat([edge_index, loops], dim=0)\n",
    "\n",
    "EDGE_INDEX = add_self_loops_edge_index(EDGE_INDEX, num_nodes=len(ASSETS))\n",
    "print(\"EDGE_INDEX (with self-loops):\", EDGE_INDEX.tolist())\n",
    "\n",
    "CFG[\"thr_trade_grid\"] = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "CFG[\"thr_dir_grid\"]   = [0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "\n",
    "# 2) минимальное число сделок, которое мы хотим ВЫНУЖДАТЬ при выборе порогов\n",
    "CFG[\"eval_min_trades\"] = 20           # применяется в sweep на test/val/holdout\n",
    "CFG[\"proxy_min_trades\"] = 40          # оставляем как было, но теперь реально достижимо\n",
    "\n",
    "# 3) динамические целевые уровни сделок (чтобы пороги подстраивались под распределение p_trade)\n",
    "CFG[\"proxy_target_trades\"] = [20, 40, 60, 80, 120]  # будет превращено в пороги по квантилям\n",
    "\n",
    "# 4) что оптимизируем на сетке: pnl_sum обычно стабильнее чем pnl_mean\n",
    "CFG[\"pnl_objective\"] = \"pnl_sum\"      # \"pnl_mean\" тоже можно\n",
    "print(\"CFG thresholds updated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (2693, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int, part = [0,100]) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.iloc[int(len(df)*part[0]/100) : int(len(df)*part[1]/100)]\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels, part = [0, 80]), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels, part = [0, 80]), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels, part = [0, 80]), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (2693, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [ 655 1311  727]\n",
      "Trade ratio: 0.5131823245451169\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=1*12, \n",
    "    vol_window=7*12,\n",
    "    pt_mult=1.2,\n",
    "    sl_mult=1.1,\n",
    "    min_barrier=0.001,\n",
    "    max_barrier=0.006,\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (2693, 3, 15) edge_feat: (2693, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 2597 t range: 83 2679\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb5de4",
   "metadata": {},
   "source": [
    "## Train (folds) - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9bad799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout split:\n",
      "  n_samples total: 2597\n",
      "  n_samples CV   : 2337 (90.0%)\n",
      "  n_samples FINAL: 260 (10.0%)\n",
      "  CV range   : 0 2336\n",
      "  FINAL range: 2337 2596\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: final holdout split (90% CV + 10% final test), time-ordered\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_final_holdout_split(n_samples: int, final_test_frac: float):\n",
    "    if not (0.0 < final_test_frac < 0.5):\n",
    "        raise ValueError(\"final_test_frac should be in (0, 0.5)\")\n",
    "\n",
    "    n_final = max(1, int(round(final_test_frac * n_samples)))\n",
    "    n_cv = n_samples - n_final\n",
    "    if n_cv <= 10:\n",
    "        raise ValueError(\"Too few samples left for CV after holdout split.\")\n",
    "\n",
    "    idx_cv = np.arange(0, n_cv, dtype=np.int64)\n",
    "    idx_final = np.arange(n_cv, n_samples, dtype=np.int64)\n",
    "    return idx_cv, idx_final, n_cv, n_final\n",
    "\n",
    "idx_cv_all, idx_final_test, n_samples_cv, n_samples_final = make_final_holdout_split(\n",
    "    n_samples=n_samples,\n",
    "    final_test_frac=CFG[\"final_test_frac\"],\n",
    ")\n",
    "\n",
    "print(\"Holdout split:\")\n",
    "print(\"  n_samples total:\", n_samples)\n",
    "print(\"  n_samples CV   :\", n_samples_cv, f\"({100*(n_samples_cv/n_samples):.1f}%)\")\n",
    "print(\"  n_samples FINAL:\", n_samples_final, f\"({100*(n_samples_final/n_samples):.1f}%)\")\n",
    "print(\"  CV range   :\", idx_cv_all[0], idx_cv_all[-1])\n",
    "print(\"  FINAL range:\", idx_final_test[0], idx_final_test[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1168 | val 233 | test 233\n",
      " fold 2: train 1401 | val 233 | test 233\n",
      " fold 3: train 1634 | val 233 | test 233\n",
      " fold 4: train 1867 | val 233 | test 233\n",
      "\n",
      "FINAL HOLDOUT:\n",
      " final_test size: 260\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test) on CV-part only\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "\n",
    "        idx_train = np.arange(0, tr_end, dtype=np.int64)\n",
    "        idx_val   = np.arange(tr_end, va_end, dtype=np.int64)\n",
    "        idx_test  = np.arange(va_end, te_end, dtype=np.int64)\n",
    "\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "\n",
    "    return splits\n",
    "\n",
    "# IMPORTANT: строим сплиты только на 90% (CV-part)\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples_cv,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "for i, (a, b, c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT:\")\n",
    "print(\" final_test size:\", len(idx_final_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready. logits: torch.Size([4, 2]) finite: True\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: SGA-TCN model (drop-in replacement for GNN_LSTM_Classifier)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "\n",
    "\n",
    "# ЛОГИЧЕСКИЙ БЛОК: SpatialGraphAttention with self-loop edge_attr padding\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class SpatialGraphAttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention with edge_attr in attention scorer:\n",
    "      score_e = a^T [h_src || h_dst || edge_emb]\n",
    "      attn normalized per-dst over incoming edges\n",
    "      msg = W_msg(h_src)\n",
    "      agg_dst = sum(attn * msg)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, out_dim: int, edge_dim: int, heads: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.heads = max(1, int(heads))\n",
    "        self.dropout = float(dropout)\n",
    "\n",
    "        self.head_dim = max(1, int(math.ceil(out_dim / self.heads)))\n",
    "        self.inner_dim = self.heads * self.head_dim\n",
    "\n",
    "        self.lin_node = nn.Linear(in_dim, self.inner_dim, bias=False)\n",
    "        self.lin_edge = nn.Linear(edge_dim, self.inner_dim, bias=False)\n",
    "        self.lin_msg  = nn.Linear(self.inner_dim, self.inner_dim, bias=False)\n",
    "\n",
    "        self.attn_vec = nn.Parameter(torch.empty(self.heads, 3 * self.head_dim))\n",
    "\n",
    "        self.out_proj = nn.Linear(self.inner_dim, out_dim, bias=False)\n",
    "        self.res_proj = nn.Identity() if in_dim == out_dim else nn.Linear(in_dim, out_dim, bias=False)\n",
    "\n",
    "        self.ln = nn.LayerNorm(out_dim)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.out_drop = nn.Dropout(dropout)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in [self.lin_node, self.lin_edge, self.lin_msg, self.out_proj]:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if isinstance(self.res_proj, nn.Linear):\n",
    "            nn.init.xavier_uniform_(self.res_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_vec)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_attr: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x:         (B,N,Fin)\n",
    "        edge_attr: (B,E_attr,W)  (может быть меньше чем E_index из-за self-loops)\n",
    "        edge_index:(E_index,2)   includes self-loops\n",
    "        returns:   (B,N,out_dim)\n",
    "        \"\"\"\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        edge_attr = torch.nan_to_num(edge_attr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        B, N, _ = x.shape\n",
    "        E_index = edge_index.shape[0]\n",
    "        E_attr = edge_attr.shape[1]\n",
    "        W = edge_attr.shape[2]\n",
    "\n",
    "        # --- pad edge_attr with zeros for self-loops if needed\n",
    "        if E_attr < E_index:\n",
    "            pad = torch.zeros((B, E_index - E_attr, W), device=edge_attr.device, dtype=edge_attr.dtype)\n",
    "            edge_attr = torch.cat([edge_attr, pad], dim=1)\n",
    "        elif E_attr > E_index:\n",
    "            edge_attr = edge_attr[:, :E_index, :]\n",
    "\n",
    "        src_idx = edge_index[:, 0]\n",
    "        dst_idx = edge_index[:, 1]\n",
    "\n",
    "        h = self.lin_node(x)  # (B,N,inner)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        h = h.view(B, N, self.heads, self.head_dim)\n",
    "\n",
    "        eemb = self.lin_edge(edge_attr)  # (B,E,inner)\n",
    "        eemb = torch.nan_to_num(eemb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        eemb = eemb.view(B, E_index, self.heads, self.head_dim)\n",
    "\n",
    "        h_src = h[:, src_idx, :, :]  # (B,E,heads,dh)\n",
    "        h_dst = h[:, dst_idx, :, :]  # (B,E,heads,dh)\n",
    "\n",
    "        cat = torch.cat([h_src, h_dst, eemb], dim=-1)  # (B,E,heads,3*dh)\n",
    "        scores = (cat * self.attn_vec[None, None, :, :]).sum(dim=-1)  # (B,E,heads)\n",
    "        scores = self.act(scores)\n",
    "\n",
    "        alphas = torch.zeros_like(scores)  # (B,E,heads)\n",
    "        for n in range(N):\n",
    "            mask = (dst_idx == n)\n",
    "            if int(mask.sum()) == 0:\n",
    "                continue\n",
    "            s = scores[:, mask, :]\n",
    "            a = torch.softmax(s, dim=1)\n",
    "            a = self.attn_drop(a)\n",
    "            alphas[:, mask, :] = a\n",
    "\n",
    "        msg = self.lin_msg(h_src.reshape(B, E_index, self.inner_dim)).view(B, E_index, self.heads, self.head_dim)\n",
    "\n",
    "        agg = torch.zeros((B, N, self.heads, self.head_dim), device=x.device, dtype=x.dtype)\n",
    "        for e_i in range(E_index):\n",
    "            dst = int(dst_idx[e_i].item())\n",
    "            agg[:, dst, :, :] += alphas[:, e_i, :].unsqueeze(-1) * msg[:, e_i, :, :]\n",
    "\n",
    "        out = agg.reshape(B, N, self.inner_dim)\n",
    "        out = self.out_proj(out)\n",
    "        out = self.out_drop(out)\n",
    "\n",
    "        res = self.res_proj(x)\n",
    "        y = self.ln(res + out)\n",
    "        return torch.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "class SpatialGraphAttentionMP(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies SpatialGraphAttentionLayer independently at each timestep t:\n",
    "      x_seq: (B,L,N,F) -> h_seq: (B,L,N,H)\n",
    "\n",
    "    Handles edge_attr padding if EDGE_INDEX includes self-loops but e_seq doesn't.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, hidden: int, edge_dim: int, heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.gat = SpatialGraphAttentionLayer(in_dim=in_dim, out_dim=hidden, edge_dim=edge_dim, heads=heads, dropout=dropout)\n",
    "\n",
    "    def forward_once(self, x_t: torch.Tensor, edge_attr_t: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        return self.gat(x_t, edge_attr_t, edge_index)\n",
    "\n",
    "    def forward(self, x_seq: torch.Tensor, e_seq: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        x_seq = torch.nan_to_num(x_seq, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        e_seq = torch.nan_to_num(e_seq, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        B, L, N, _ = x_seq.shape\n",
    "        hs = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            hs.append(ht)\n",
    "        return torch.stack(hs, dim=1)  # (B,L,N,H)\n",
    "\n",
    "\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"Causal Conv1d: pads only on the left => no future leakage.\"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, dilation: int = 1):\n",
    "        super().__init__()\n",
    "        self.kernel_size = int(kernel_size)\n",
    "        self.dilation = int(dilation)\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=self.kernel_size, dilation=self.dilation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,C,L)\n",
    "        pad_left = (self.kernel_size - 1) * self.dilation\n",
    "        x = F.pad(x, (pad_left, 0))\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, dilation: int, dropout: float, causal: bool = True):\n",
    "        super().__init__()\n",
    "        self.causal = bool(causal)\n",
    "\n",
    "        if self.causal:\n",
    "            conv1 = CausalConv1d(in_ch, out_ch, kernel_size, dilation=dilation)\n",
    "            conv2 = CausalConv1d(out_ch, out_ch, kernel_size, dilation=dilation)\n",
    "        else:\n",
    "            # non-causal WITHOUT future leakage is tricky; safest is causal=True.\n",
    "            # If you set causal=False, consider it \"experimental\".\n",
    "            pad = ((kernel_size - 1) * dilation) // 2\n",
    "            conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, dilation=dilation, padding=pad)\n",
    "            conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, dilation=dilation, padding=pad)\n",
    "\n",
    "        self.conv1 = conv1\n",
    "        self.conv2 = conv2\n",
    "\n",
    "        self.act = nn.GELU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Identity() if in_ch == out_ch else nn.Conv1d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv1d,)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,C,L)\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        y = self.conv1(x)\n",
    "        y = self.act(y)\n",
    "        y = self.drop(y)\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        y = self.act(y)\n",
    "        y = self.drop(y)\n",
    "\n",
    "        res = self.downsample(x)\n",
    "        out = self.act(y + res)\n",
    "        return torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, in_ch: int, channels: list[int], kernel_size: int, dropout: float, causal: bool = True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i, out_ch in enumerate(channels):\n",
    "            dilation = 2 ** i\n",
    "            layers.append(\n",
    "                TemporalBlock(\n",
    "                    in_ch=in_ch,\n",
    "                    out_ch=out_ch,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=dilation,\n",
    "                    dropout=dropout,\n",
    "                    causal=causal,\n",
    "                )\n",
    "            )\n",
    "            in_ch = out_ch\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    DROP-IN replacement:\n",
    "      input:  x_seq (B,L,N,F), e_seq (B,L,E,W), edge_index (E,2)\n",
    "      output: logits (B,2)\n",
    "\n",
    "    Internally это SGA-TCN:\n",
    "      - Spatial: Graph Attention per timestep (edge_attr in scorer)\n",
    "      - Temporal: TCN on target_node sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = int(target_node)\n",
    "\n",
    "        # --- read new params from global CFG (fallback to reasonable defaults)\n",
    "        _cfg = globals().get(\"CFG\", {})\n",
    "        gat_heads = int(_cfg.get(\"gat_heads\", 1))\n",
    "\n",
    "        tcn_channels = int(_cfg.get(\"tcn_channels\", hidden))\n",
    "        tcn_layers_n = int(_cfg.get(\"tcn_layers\", 4))\n",
    "        tcn_kernel = int(_cfg.get(\"tcn_kernel\", 3))\n",
    "        tcn_dropout = float(_cfg.get(\"tcn_dropout\", dropout))\n",
    "        tcn_causal = bool(_cfg.get(\"tcn_causal\", True))\n",
    "        tcn_pool = str(_cfg.get(\"tcn_pool\", \"last\"))\n",
    "\n",
    "        self.tcn_pool = tcn_pool\n",
    "\n",
    "        # --- spatial stack\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(int(gnn_layers)):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(\n",
    "                SpatialGraphAttentionMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, heads=gat_heads, dropout=dropout)\n",
    "            )\n",
    "\n",
    "        # --- temporal TCN\n",
    "        self.tcn_in = nn.Linear(hidden, tcn_channels)\n",
    "        self.tcn = TemporalConvNet(\n",
    "            in_ch=tcn_channels,\n",
    "            channels=[tcn_channels] * tcn_layers_n,\n",
    "            kernel_size=tcn_kernel,\n",
    "            dropout=tcn_dropout,\n",
    "            causal=tcn_causal,\n",
    "        )\n",
    "\n",
    "        # --- head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(tcn_channels),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(tcn_channels, tcn_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(tcn_channels, n_classes),\n",
    "        )\n",
    "\n",
    "        # init linears\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        e = torch.nan_to_num(e, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        h_tgt = torch.nan_to_num(h_tgt, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        z = self.tcn_in(h_tgt)          # (B,L,C)\n",
    "        z = torch.nan_to_num(z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        z = z.transpose(1, 2)           # (B,C,L)\n",
    "\n",
    "        y = self.tcn(z)                 # (B,C,L)\n",
    "\n",
    "        if self.tcn_pool == \"mean\":\n",
    "            emb = y.mean(dim=-1)        # (B,C)\n",
    "        else:\n",
    "            emb = y[:, :, -1]           # (B,C) safe for causal\n",
    "\n",
    "        logits = self.head(emb)         # (B,2)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "# ---- quick sanity check (shape + no NaNs)\n",
    "B, L, N, Fdim = 4, CFG[\"lookback\"], 3, X_node_raw.shape[-1]\n",
    "E = EDGE_INDEX.shape[0]\n",
    "W = edge_feat.shape[-1]\n",
    "\n",
    "x_dummy = torch.randn(B, L, N, Fdim)\n",
    "e_dummy = torch.randn(B, L, E, W)\n",
    "\n",
    "m = GNN_LSTM_Classifier(\n",
    "    node_in=Fdim,\n",
    "    edge_dim=W,\n",
    "    hidden=CFG[\"hidden\"],\n",
    "    gnn_layers=CFG[\"gnn_layers\"],\n",
    "    lstm_hidden=CFG[\"lstm_hidden\"],   # ignored (compat)\n",
    "    lstm_layers=CFG[\"lstm_layers\"],   # ignored (compat)\n",
    "    dropout=CFG[\"dropout\"],\n",
    "    target_node=TARGET_NODE,\n",
    "    n_classes=2\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = m(x_dummy, e_dummy, EDGE_INDEX)\n",
    "print(\"Model ready. logits:\", out.shape, \"finite:\", torch.isfinite(out).all().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn, y_key: str = \"trade\"):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        y = (y_trade_b if y_key == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "\n",
    "    ys = np.concatenate(ys) if len(ys) else np.array([], dtype=np.int64)\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, None, ys, probs, ers\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:, 1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss / max(n, 1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_only(model, loader):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "    return probs, ers\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps, min_trades: int = 0):\n",
    "    \"\"\"\n",
    "    Возвращает лучший pnl_mean по grid (per-bar), плюс пороги и статистику.\n",
    "    min_trades используется как фильтр: комбинации, где сделок меньше, пропускаются.\n",
    "    Если ни одна комбинация не прошла min_trades — вернём best без фильтра (но это будет fallback-сценарий).\n",
    "    \"\"\"\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    sign = np.where(p_up >= 0.5, 1.0, -1.0).astype(np.float32)\n",
    "    cost = float(cost_bps) * 1e-4\n",
    "    N = len(exit_ret)\n",
    "\n",
    "    best = {\n",
    "        \"pnl_mean\": -1e18,\n",
    "        \"pnl_sum\": -1e18,\n",
    "        \"thr_trade\": None,\n",
    "        \"thr_dir\": None,\n",
    "        \"n_trades\": 0,\n",
    "        \"trade_rate\": 0.0,\n",
    "        \"min_trades_used\": int(min_trades),\n",
    "        \"passed_min_trades\": False,\n",
    "    }\n",
    "\n",
    "    # 1) строгий проход (>=min_trades)\n",
    "    for thr_t in thr_trade_grid:\n",
    "        mt = (p_trade >= thr_t)\n",
    "        for thr_d in thr_dir_grid:\n",
    "            mask = mt & (conf_dir >= thr_d)\n",
    "            n_tr = int(mask.sum())\n",
    "            if n_tr < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "            pnl_sum = float(pnl.sum())\n",
    "            pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "            if pnl_mean > best[\"pnl_mean\"]:\n",
    "                best.update({\n",
    "                    \"pnl_mean\": pnl_mean,\n",
    "                    \"pnl_sum\": pnl_sum,\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": n_tr,\n",
    "                    \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                    \"passed_min_trades\": True,\n",
    "                })\n",
    "\n",
    "    # 2) если ничего не прошло min_trades — найдём best без фильтра (для fallback-логов)\n",
    "    if best[\"thr_trade\"] is None:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            mt = (p_trade >= thr_t)\n",
    "            for thr_d in thr_dir_grid:\n",
    "                mask = mt & (conf_dir >= thr_d)\n",
    "                n_tr = int(mask.sum())\n",
    "                pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "                pnl_sum = float(pnl.sum())\n",
    "                pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "                if pnl_mean > best[\"pnl_mean\"]:\n",
    "                    best.update({\n",
    "                        \"pnl_mean\": pnl_mean,\n",
    "                        \"pnl_sum\": pnl_sum,\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": n_tr,\n",
    "                        \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def _make_ce_weights_binary(y_np: np.ndarray) -> torch.Tensor:\n",
    "    y_np = np.asarray(y_np, dtype=np.int64)\n",
    "    counts = np.bincount(y_np, minlength=2).astype(np.float64)\n",
    "    counts = np.maximum(counts, 1.0)\n",
    "    w = counts.sum() / (2.0 * counts)  # inverse freq\n",
    "    return torch.tensor(w, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "    select_metric: str | None = None,        # \"va_auc\" | \"va_f1m\" | \"va_pnl_max\"\n",
    "    trade_model_for_pnl=None,\n",
    "    idx_val_pnl=None,\n",
    "):\n",
    "    if select_metric is None:\n",
    "        select_metric = \"va_auc\"\n",
    "    if select_metric not in (\"va_auc\", \"va_f1m\", \"va_pnl_max\"):\n",
    "        raise ValueError(\"select_metric must be one of: 'va_auc', 'va_f1m', 'va_pnl_max'\")\n",
    "\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if stage_name != \"dir\":\n",
    "            raise ValueError(\"select_metric='va_pnl_max' supported only for stage_name='dir'\")\n",
    "        if trade_model_for_pnl is None or idx_val_pnl is None:\n",
    "            raise ValueError(\"For va_pnl_max you must pass trade_model_for_pnl and idx_val_pnl.\")\n",
    "\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val,   L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test,  L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True,  drop_last=False, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    va_pnl_loader = None\n",
    "    if stage_name == \"dir\" and (idx_val_pnl is not None):\n",
    "        va_pnl_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val_pnl, L)\n",
    "        va_pnl_loader = DataLoader(va_pnl_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # --- class weights (делает обучение стабильнее на фолдах)\n",
    "    t_train = sample_t[idx_train]\n",
    "    y_train_np = (y_trade_arr[t_train] if stage_name == \"trade\" else y_dir_arr[t_train]).astype(np.int64)\n",
    "    ce_w = _make_ce_weights_binary(y_train_np)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=ce_w)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\"))\n",
    "\n",
    "    # --- trade probs на полном val для PnL proxy (считаем 1 раз)\n",
    "    prob_trade_val_pnl = None\n",
    "    if stage_name == \"dir\" and (trade_model_for_pnl is not None) and (va_pnl_loader is not None):\n",
    "        prob_trade_val_pnl, _ = predict_probs_only(trade_model_for_pnl, va_pnl_loader)\n",
    "        debug_trade_prob_stats(prob_trade_val_pnl, title=\"val_pnl (for dir selector)\")\n",
    "\n",
    "    # --- proxy grids (ВАЖНО: делаем thr_trade_grid динамической!)\n",
    "    proxy_min_trades = int(cfg.get(\"proxy_min_trades\", 0))\n",
    "    objective = str(cfg.get(\"pnl_objective\", \"pnl_sum\"))\n",
    "    thr_dir_grid_proxy = cfg.get(\"thr_dir_grid\", [0.5])\n",
    "\n",
    "    if (stage_name == \"dir\") and (prob_trade_val_pnl is not None):\n",
    "        thr_trade_grid_proxy = build_trade_threshold_grid(\n",
    "            p_trade=prob_trade_val_pnl[:, 1],\n",
    "            base_grid=cfg.get(\"thr_trade_grid\", [0.5]),\n",
    "            target_trades_list=cfg.get(\"proxy_target_trades\", [proxy_min_trades]),\n",
    "            min_thr=0.01, max_thr=0.99\n",
    "        )\n",
    "    else:\n",
    "        thr_trade_grid_proxy = cfg.get(\"thr_trade_grid\", [0.5])\n",
    "\n",
    "    best_score = -1e18\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "    best_used = select_metric\n",
    "\n",
    "    best_score_auc = -1e18\n",
    "    best_state_auc = None\n",
    "    best_epoch_auc = -1\n",
    "\n",
    "    best_score_pnl = -1e18\n",
    "    best_state_pnl = None\n",
    "    best_epoch_pnl = -1\n",
    "    seen_pnl_ok = False\n",
    "\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\"tr_loss\": [], \"va_loss\": [], \"va_f1m\": [], \"va_auc\": [],\n",
    "            \"va_pnl_obj\": [], \"va_pnl_n_trades\": [], \"va_sel\": [], \"va_sel_mode\": []}\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"] + 1):\n",
    "        # ---- TRAIN\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for x, e, y_trade_b, y_dir_b, er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            y = (y_trade_b if stage_name == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot / max(n, 1)\n",
    "\n",
    "        # ---- VAL metrics\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, va_loader, loss_fn, y_key=stage_name\n",
    "        )\n",
    "\n",
    "        # ---- VAL PnL proxy (dir only)\n",
    "        va_pnl_best = {\"thr_trade\": np.nan, \"thr_dir\": np.nan, \"n_trades\": 0, \"trade_rate\": np.nan,\n",
    "                       \"pnl_sum\": np.nan, \"pnl_mean\": np.nan, \"pnl_per_trade\": np.nan,\n",
    "                       \"passed_min_trades\": False, \"min_trades_used\": proxy_min_trades}\n",
    "\n",
    "        if stage_name == \"dir\" and (prob_trade_val_pnl is not None) and (va_pnl_loader is not None):\n",
    "            prob_dir_val_pnl, er_dir_val_pnl = predict_probs_only(model, va_pnl_loader)\n",
    "\n",
    "            va_pnl_best = pnl_proxy_grid_max(\n",
    "                prob_trade=prob_trade_val_pnl,\n",
    "                prob_dir=prob_dir_val_pnl,\n",
    "                exit_ret=er_dir_val_pnl,\n",
    "                thr_trade_grid=thr_trade_grid_proxy,\n",
    "                thr_dir_grid=thr_dir_grid_proxy,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "                min_trades=proxy_min_trades,\n",
    "                objective=objective,\n",
    "            )\n",
    "\n",
    "        # ---- selection\n",
    "        sel_val = np.nan\n",
    "        sel_mode = select_metric\n",
    "\n",
    "        if select_metric in (\"va_auc\", \"va_f1m\"):\n",
    "            sel_val = (va_auc if select_metric == \"va_auc\" else va_f1m)\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "\n",
    "            if sel_val > best_score:\n",
    "                best_score = float(sel_val)\n",
    "                best_epoch = ep\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "        else:\n",
    "            # va_pnl_max with fallback\n",
    "            pnl_obj = float(va_pnl_best.get(objective, np.nan))\n",
    "            n_tr = int(va_pnl_best.get(\"n_trades\", 0))\n",
    "            pnl_ok = (np.isfinite(pnl_obj) and (n_tr >= proxy_min_trades))\n",
    "\n",
    "            # обновим best_auc\n",
    "            if np.isfinite(va_auc) and (float(va_auc) > best_score_auc):\n",
    "                best_score_auc = float(va_auc)\n",
    "                best_epoch_auc = ep\n",
    "                best_state_auc = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            # обновим best_pnl только если pnl_ok\n",
    "            if pnl_ok and (pnl_obj > best_score_pnl):\n",
    "                best_score_pnl = pnl_obj\n",
    "                best_epoch_pnl = ep\n",
    "                best_state_pnl = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            if pnl_ok:\n",
    "                seen_pnl_ok = True\n",
    "                sel_val = pnl_obj\n",
    "                sel_mode = f\"va_pnl_max({objective})\"\n",
    "            else:\n",
    "                sel_val = float(va_auc) if np.isfinite(va_auc) else -1e18\n",
    "                sel_mode = f\"va_auc_fallback({n_tr}/{proxy_min_trades})\"\n",
    "\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "            improved = False\n",
    "            if not seen_pnl_ok:\n",
    "                improved = (np.isfinite(va_auc) and (float(va_auc) >= best_score_auc))\n",
    "            else:\n",
    "                improved = pnl_ok and (pnl_obj >= best_score_pnl)\n",
    "\n",
    "            bad = 0 if improved else (bad + 1)\n",
    "\n",
    "        # ---- logs\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "        hist[\"va_pnl_obj\"].append(float(va_pnl_best.get(objective, np.nan)))\n",
    "        hist[\"va_pnl_n_trades\"].append(int(va_pnl_best.get(\"n_trades\", 0)))\n",
    "        hist[\"va_sel\"].append(float(sel_val) if np.isfinite(sel_val) else np.nan)\n",
    "        hist[\"va_sel_mode\"].append(sel_mode)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "\n",
    "        if stage_name == \"dir\":\n",
    "            best_str = (f\"pnl={best_score_pnl:.6f}@ep{best_epoch_pnl:02d}\" if best_state_pnl is not None\n",
    "                        else f\"auc={best_score_auc:.6f}@ep{best_epoch_auc:02d}\")\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"{objective}={va_pnl_best.get(objective, np.nan):.6f} \"\n",
    "                f\"thr=({va_pnl_best.get('thr_trade', np.nan):.2f},{va_pnl_best.get('thr_dir', np.nan):.2f}) \"\n",
    "                f\"trades={va_pnl_best.get('n_trades', 0)} \"\n",
    "                f\"sel({sel_mode})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "        else:\n",
    "            best_str = f\"{best_score:.6f}@ep{best_epoch:02d}\" if best_epoch > 0 else \"none\"\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"sel({select_metric})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "\n",
    "        if bad >= patience:\n",
    "            break\n",
    "\n",
    "    # ---- choose final best state\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if best_state_pnl is not None:\n",
    "            model.load_state_dict(best_state_pnl)\n",
    "            best_score = best_score_pnl\n",
    "            best_epoch = best_epoch_pnl\n",
    "            best_used = f\"va_pnl_max({objective})\"\n",
    "        else:\n",
    "            model.load_state_dict(best_state_auc)\n",
    "            best_score = best_score_auc\n",
    "            best_epoch = best_epoch_auc\n",
    "            best_used = \"va_auc_fallback_only\"\n",
    "    else:\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "            best_used = select_metric\n",
    "\n",
    "    # финальные VAL/TEST\n",
    "    va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(model, va_loader, loss_fn, y_key=stage_name)\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(model, te_loader, loss_fn, y_key=stage_name)\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": float(best_score),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"select_metric\": select_metric,\n",
    "        \"best_used\": best_used,\n",
    "\n",
    "        \"val_loss\": va_loss, \"val_acc\": va_acc, \"val_f1m\": va_f1m, \"val_auc\": va_auc, \"val_cm\": va_cm,\n",
    "        \"val_y\": va_y, \"val_prob\": va_prob, \"val_er\": va_er,\n",
    "\n",
    "        \"test_loss\": te_loss, \"test_acc\": te_acc, \"test_f1m\": te_f1m, \"test_auc\": te_auc, \"test_cm\": te_cm,\n",
    "        \"test_y\": te_y, \"test_prob\": te_prob, \"test_er\": te_er,\n",
    "\n",
    "        \"hist\": hist,\n",
    "    }\n",
    "    return model, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Better threshold sweep (dynamic thr_trade + min_trades constraint)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "def build_trade_threshold_grid(\n",
    "    p_trade: np.ndarray,\n",
    "    base_grid: list[float] | None = None,\n",
    "    target_trades_list: list[int] | None = None,\n",
    "    min_thr: float = 0.01,\n",
    "    max_thr: float = 0.99,\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Делает пороги thr_trade не только фиксированные, но и \"по квантилям\",\n",
    "    чтобы можно было получать заданное число сделок даже при некалиброванных вероятностях.\n",
    "\n",
    "    target_trades_list: список желаемых n_trades (например [20,40,80])\n",
    "    Возвращает список порогов.\n",
    "    \"\"\"\n",
    "    p_trade = np.asarray(p_trade, dtype=np.float64)\n",
    "    p_trade = p_trade[np.isfinite(p_trade)]\n",
    "    if p_trade.size == 0:\n",
    "        return base_grid or [0.5]\n",
    "\n",
    "    thrs = set()\n",
    "    if base_grid:\n",
    "        for t in base_grid:\n",
    "            thrs.add(float(t))\n",
    "\n",
    "    if target_trades_list:\n",
    "        N = p_trade.size\n",
    "        # порог = значение, которое оставляет примерно k наблюдений сверху\n",
    "        for k in target_trades_list:\n",
    "            k = int(k)\n",
    "            if k <= 0:\n",
    "                continue\n",
    "            if k >= N:\n",
    "                thr = float(np.min(p_trade))  # чтобы взять всё\n",
    "            else:\n",
    "                # k сверху => квантиль 1 - k/N\n",
    "                q = 1.0 - (k / N)\n",
    "                thr = float(np.quantile(p_trade, q))\n",
    "            thr = float(np.clip(thr, min_thr, max_thr))\n",
    "            thrs.add(thr)\n",
    "\n",
    "    thrs = sorted(thrs)\n",
    "    # небольшая чистка дублей/почти-дублей\n",
    "    out = []\n",
    "    for t in thrs:\n",
    "        if not out or abs(t - out[-1]) > 1e-6:\n",
    "            out.append(float(t))\n",
    "    return out\n",
    "\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade, prob_dir, exit_ret,\n",
    "    thr_trade: float, thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    conf_dir = np.maximum(p_up, 1.0 - p_up)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (float(cost_bps) * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    n_tr = int(trade_mask.sum())\n",
    "    out = {\n",
    "        \"n\": int(len(exit_ret)),\n",
    "        \"n_trades\": n_tr,\n",
    "        \"trade_rate\": float(n_tr / max(1, len(exit_ret))),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()) if len(exit_ret) else np.nan,\n",
    "        \"pnl_per_trade\": float(pnl.sum() / max(1, n_tr)),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)) if len(exit_ret) else np.nan,\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg, min_trades: int = 0, objective: str = \"pnl_sum\"):\n",
    "    \"\"\"\n",
    "    Ищет лучшие (thr_trade, thr_dir) на сетке.\n",
    "    ВАЖНО: добавили min_trades (иначе часто \"лучше всего\" 0 сделок => pnl=0).\n",
    "    \"\"\"\n",
    "    if objective not in (\"pnl_sum\", \"pnl_mean\", \"pnl_per_trade\"):\n",
    "        raise ValueError(\"objective must be one of: pnl_sum, pnl_mean, pnl_per_trade\")\n",
    "\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    thr_trade_grid = build_trade_threshold_grid(\n",
    "        p_trade=p_trade,\n",
    "        base_grid=cfg.get(\"thr_trade_grid\", [0.5]),\n",
    "        target_trades_list=cfg.get(\"proxy_target_trades\", None),\n",
    "        min_thr=0.01,\n",
    "        max_thr=0.99,\n",
    "    )\n",
    "    thr_dir_grid = cfg.get(\"thr_dir_grid\", [0.5])\n",
    "\n",
    "    rows = []\n",
    "    for thr_t in thr_trade_grid:\n",
    "        for thr_d in thr_dir_grid:\n",
    "            m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cfg[\"cost_bps\"])\n",
    "            if int(m[\"n_trades\"]) < int(min_trades):\n",
    "                continue\n",
    "            rows.append({\"thr_trade\": float(thr_t), \"thr_dir\": float(thr_d), **m})\n",
    "\n",
    "    # fallback: если min_trades слишком строгий, ослабим до \"хотя бы 1 сделка\"\n",
    "    if not rows and min_trades > 0:\n",
    "        return sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg, min_trades=1, objective=objective)\n",
    "\n",
    "    # последний fallback: разрешим 0 сделок (на случай реально мёртвого сигнала)\n",
    "    if not rows:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            for thr_d in thr_dir_grid:\n",
    "                m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cfg[\"cost_bps\"])\n",
    "                rows.append({\"thr_trade\": float(thr_t), \"thr_dir\": float(thr_d), **m})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values([objective, \"pnl_sum\"], ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps,\n",
    "                       min_trades: int = 0, objective: str = \"pnl_sum\"):\n",
    "    \"\"\"\n",
    "    Упрощённая версия для train_binary_classifier (быстрое max по сетке).\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for thr_t in thr_trade_grid:\n",
    "        for thr_d in thr_dir_grid:\n",
    "            m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cost_bps)\n",
    "            if int(m[\"n_trades\"]) < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            score = float(m[objective])\n",
    "            if (best is None) or (score > best[\"_score\"]):\n",
    "                best = {\n",
    "                    \"_score\": score,\n",
    "                    \"pnl_sum\": m[\"pnl_sum\"],\n",
    "                    \"pnl_mean\": m[\"pnl_mean\"],\n",
    "                    \"pnl_per_trade\": m[\"pnl_per_trade\"],\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": int(m[\"n_trades\"]),\n",
    "                    \"trade_rate\": float(m[\"trade_rate\"]),\n",
    "                    \"passed_min_trades\": True,\n",
    "                    \"min_trades_used\": int(min_trades),\n",
    "                }\n",
    "\n",
    "    # fallback: если ничего не прошло min_trades — попробуем хотя бы 1 сделку\n",
    "    if best is None and min_trades > 0:\n",
    "        return pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps,\n",
    "                                  min_trades=1, objective=objective)\n",
    "\n",
    "    # последний fallback: разрешим 0 сделок\n",
    "    if best is None:\n",
    "        best = {\n",
    "            \"_score\": -1e18,\n",
    "            \"pnl_sum\": -1e18,\n",
    "            \"pnl_mean\": -1e18,\n",
    "            \"pnl_per_trade\": -1e18,\n",
    "            \"thr_trade\": float(thr_trade_grid[0]) if len(thr_trade_grid) else 0.5,\n",
    "            \"thr_dir\": float(thr_dir_grid[0]) if len(thr_dir_grid) else 0.5,\n",
    "            \"n_trades\": 0,\n",
    "            \"trade_rate\": 0.0,\n",
    "            \"passed_min_trades\": False,\n",
    "            \"min_trades_used\": int(min_trades),\n",
    "        }\n",
    "        # найдём реальный best без ограничений (даже 0 сделок)\n",
    "        for thr_t in thr_trade_grid:\n",
    "            for thr_d in thr_dir_grid:\n",
    "                m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cost_bps)\n",
    "                score = float(m[objective])\n",
    "                if score > best[\"_score\"]:\n",
    "                    best.update({\n",
    "                        \"_score\": score,\n",
    "                        \"pnl_sum\": m[\"pnl_sum\"],\n",
    "                        \"pnl_mean\": m[\"pnl_mean\"],\n",
    "                        \"pnl_per_trade\": m[\"pnl_per_trade\"],\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": int(m[\"n_trades\"]),\n",
    "                        \"trade_rate\": float(m[\"trade_rate\"]),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "    best.pop(\"_score\", None)\n",
    "    return best\n",
    "\n",
    "\n",
    "def debug_trade_prob_stats(prob_trade: np.ndarray, title: str = \"\"):\n",
    "    p = prob_trade[:, 1]\n",
    "    qs = [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]\n",
    "    vals = np.quantile(p, qs)\n",
    "    msg = \" | \".join([f\"q{int(q*100):02d}={v:.3f}\" for q, v in zip(qs, vals)])\n",
    "    print(f\"[trade prob stats]{(' ' + title) if title else ''}: {msg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f5c430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: shared helper for probs on arbitrary indices\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_on_indices(model, X_scaled, edge_feat, indices, cfg):\n",
    "    ds = LobGraphSequenceDataset2Stage(\n",
    "        X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, cfg[\"lookback\"]\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, yt, yd, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(probs), np.concatenate(ers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1168 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7576 va_loss=0.6910 f1m=0.392 auc=0.570 sel(va_auc)=0.569852 best=0.569852@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7553 va_loss=0.6920 f1m=0.279 auc=0.604 sel(va_auc)=0.604196 best=0.604196@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7115 va_loss=0.6933 f1m=0.279 auc=0.573 sel(va_auc)=0.572650 best=0.604196@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7115 va_loss=0.6856 f1m=0.495 auc=0.577 sel(va_auc)=0.576690 best=0.604196@ep02\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7185 va_loss=0.6893 f1m=0.483 auc=0.576 sel(va_auc)=0.575991 best=0.604196@ep02\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.7017 va_loss=0.6881 f1m=0.455 auc=0.575 sel(va_auc)=0.575291 best=0.604196@ep02\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6940 va_loss=0.6880 f1m=0.488 auc=0.570 sel(va_auc)=0.570085 best=0.604196@ep02\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6956 va_loss=0.6850 f1m=0.545 auc=0.570 sel(va_auc)=0.569697 best=0.604196@ep02\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.7011 va_loss=0.6868 f1m=0.527 auc=0.570 sel(va_auc)=0.570163 best=0.604196@ep02\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.6848 va_loss=0.6902 f1m=0.482 auc=0.565 sel(va_auc)=0.564880 best=0.604196@ep02\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.516 | q05=0.519 | q10=0.522 | q25=0.531 | q50=0.544 | q75=0.557 | q90=0.564 | q95=0.566 | q99=0.572\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7240 va_loss=0.7258 f1m=0.311 auc=0.513 pnl_sum=-0.149597 thr=(0.54,0.55) trades=88 sel(va_pnl_max(pnl_sum))=-0.149597 best=pnl=-0.149597@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7214 va_loss=0.7631 f1m=0.281 auc=0.497 pnl_sum=-0.118780 thr=(0.05,0.60) trades=156 sel(va_pnl_max(pnl_sum))=-0.118780 best=pnl=-0.118780@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7235 va_loss=0.7552 f1m=0.281 auc=0.545 pnl_sum=-0.051470 thr=(0.05,0.60) trades=148 sel(va_pnl_max(pnl_sum))=-0.051470 best=pnl=-0.051470@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6896 va_loss=0.7149 f1m=0.311 auc=0.601 pnl_sum=-0.140528 thr=(0.54,0.55) trades=61 sel(va_pnl_max(pnl_sum))=-0.140528 best=pnl=-0.051470@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7074 va_loss=0.7216 f1m=0.275 auc=0.621 pnl_sum=0.071668 thr=(0.05,0.60) trades=53 sel(va_pnl_max(pnl_sum))=0.071668 best=pnl=0.071668@ep05\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6814 va_loss=0.7332 f1m=0.275 auc=0.613 pnl_sum=0.041275 thr=(0.05,0.60) trades=79 sel(va_pnl_max(pnl_sum))=0.041275 best=pnl=0.071668@ep05\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6612 va_loss=0.7446 f1m=0.311 auc=0.599 pnl_sum=-0.001173 thr=(0.05,0.60) trades=95 sel(va_pnl_max(pnl_sum))=-0.001173 best=pnl=0.071668@ep05\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.6687 va_loss=0.7543 f1m=0.328 auc=0.571 pnl_sum=-0.076493 thr=(0.54,0.60) trades=56 sel(va_pnl_max(pnl_sum))=-0.076493 best=pnl=0.071668@ep05\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.6732 va_loss=0.7900 f1m=0.328 auc=0.542 pnl_sum=0.060219 thr=(0.05,0.65) trades=64 sel(va_pnl_max(pnl_sum))=0.060219 best=pnl=0.071668@ep05\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.6315 va_loss=0.8252 f1m=0.328 auc=0.516 pnl_sum=-0.135181 thr=(0.54,0.65) trades=80 sel(va_pnl_max(pnl_sum))=-0.135181 best=pnl=0.071668@ep05\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.6573 va_loss=0.7719 f1m=0.315 auc=0.506 pnl_sum=-0.026514 thr=(0.05,0.60) trades=108 sel(va_pnl_max(pnl_sum))=-0.026514 best=pnl=0.071668@ep05\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.6086 va_loss=0.7942 f1m=0.299 auc=0.489 pnl_sum=-0.051694 thr=(0.05,0.70) trades=47 sel(va_pnl_max(pnl_sum))=-0.051694 best=pnl=0.071668@ep05\n",
      "[dir] ep 13 lr=1.00e-04 tr_loss=0.6342 va_loss=0.7904 f1m=0.314 auc=0.479 pnl_sum=-0.039378 thr=(0.54,0.60) trades=41 sel(va_pnl_max(pnl_sum))=-0.039378 best=pnl=0.071668@ep05\n",
      "PnL on fold-test: | thr_trade= 0.05 | thr_dir= 0.5 | pnl_sum= 0.2686450481414795 | pnl_mean= 0.001152983051724732 | trades= 233.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1401 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7656 va_loss=0.6589 f1m=0.429 auc=0.671 sel(va_auc)=0.670640 best=0.670640@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7257 va_loss=0.6882 f1m=0.520 auc=0.588 sel(va_auc)=0.587685 best=0.670640@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7129 va_loss=0.6722 f1m=0.460 auc=0.590 sel(va_auc)=0.590443 best=0.670640@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7014 va_loss=0.6699 f1m=0.428 auc=0.534 sel(va_auc)=0.534286 best=0.670640@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7018 va_loss=0.6887 f1m=0.517 auc=0.564 sel(va_auc)=0.563842 best=0.670640@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.7030 va_loss=0.6481 f1m=0.429 auc=0.565 sel(va_auc)=0.565222 best=0.670640@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6955 va_loss=0.6786 f1m=0.580 auc=0.586 sel(va_auc)=0.586305 best=0.670640@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6925 va_loss=0.6750 f1m=0.594 auc=0.585 sel(va_auc)=0.584532 best=0.670640@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6932 va_loss=0.6580 f1m=0.493 auc=0.592 sel(va_auc)=0.591823 best=0.670640@ep01\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.417 | q05=0.430 | q10=0.435 | q25=0.444 | q50=0.459 | q75=0.471 | q90=0.479 | q95=0.487 | q99=0.491\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7733 va_loss=0.7738 f1m=0.134 auc=0.331 pnl_sum=-0.162522 thr=(0.46,0.55) trades=46 sel(va_pnl_max(pnl_sum))=-0.162522 best=pnl=-0.162522@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7472 va_loss=0.8229 f1m=0.134 auc=0.286 pnl_sum=-0.159098 thr=(0.05,0.60) trades=61 sel(va_pnl_max(pnl_sum))=-0.159098 best=pnl=-0.159098@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7093 va_loss=0.8073 f1m=0.134 auc=0.295 pnl_sum=-0.175091 thr=(0.47,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175091 best=pnl=-0.159098@ep02\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7084 va_loss=0.7940 f1m=0.134 auc=0.290 pnl_sum=-0.175091 thr=(0.47,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175091 best=pnl=-0.159098@ep02\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7063 va_loss=0.7974 f1m=0.134 auc=0.197 pnl_sum=-0.175091 thr=(0.47,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175091 best=pnl=-0.159098@ep02\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6902 va_loss=0.8438 f1m=0.134 auc=0.170 pnl_sum=-0.175091 thr=(0.47,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175091 best=pnl=-0.159098@ep02\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6836 va_loss=0.8262 f1m=0.134 auc=0.168 pnl_sum=-0.153029 thr=(0.05,0.60) trades=63 sel(va_pnl_max(pnl_sum))=-0.153029 best=pnl=-0.153029@ep07\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.6964 va_loss=0.8293 f1m=0.134 auc=0.170 pnl_sum=-0.175091 thr=(0.47,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175091 best=pnl=-0.153029@ep07\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.6917 va_loss=0.9254 f1m=0.134 auc=0.195 pnl_sum=-0.175091 thr=(0.47,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175091 best=pnl=-0.153029@ep07\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.6713 va_loss=0.9084 f1m=0.134 auc=0.283 pnl_sum=-0.117408 thr=(0.47,0.60) trades=44 sel(va_pnl_max(pnl_sum))=-0.117408 best=pnl=-0.117408@ep10\n",
      "[dir] ep 11 lr=2.00e-04 tr_loss=0.6571 va_loss=1.0074 f1m=0.134 auc=0.356 pnl_sum=-0.133382 thr=(0.46,0.65) trades=61 sel(va_pnl_max(pnl_sum))=-0.133382 best=pnl=-0.117408@ep10\n",
      "[dir] ep 12 lr=2.00e-04 tr_loss=0.6533 va_loss=1.0773 f1m=0.134 auc=0.385 pnl_sum=-0.071343 thr=(0.47,0.65) trades=40 sel(va_pnl_max(pnl_sum))=-0.071343 best=pnl=-0.071343@ep12\n",
      "[dir] ep 13 lr=2.00e-04 tr_loss=0.6365 va_loss=1.2667 f1m=0.134 auc=0.417 pnl_sum=-0.164154 thr=(0.47,0.70) trades=53 sel(va_pnl_max(pnl_sum))=-0.164154 best=pnl=-0.071343@ep12\n",
      "[dir] ep 14 lr=2.00e-04 tr_loss=0.6371 va_loss=1.2718 f1m=0.134 auc=0.417 pnl_sum=-0.152429 thr=(0.47,0.70) trades=49 sel(va_pnl_max(pnl_sum))=-0.152429 best=pnl=-0.071343@ep12\n",
      "[dir] ep 15 lr=2.00e-04 tr_loss=0.6177 va_loss=1.1674 f1m=0.134 auc=0.397 pnl_sum=-0.079557 thr=(0.47,0.65) trades=42 sel(va_pnl_max(pnl_sum))=-0.079557 best=pnl=-0.071343@ep12\n",
      "[dir] ep 16 lr=2.00e-04 tr_loss=0.6191 va_loss=1.4187 f1m=0.134 auc=0.424 pnl_sum=-0.175091 thr=(0.47,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175091 best=pnl=-0.071343@ep12\n",
      "[dir] ep 17 lr=1.00e-04 tr_loss=0.6097 va_loss=1.4378 f1m=0.134 auc=0.424 pnl_sum=-0.175091 thr=(0.47,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175091 best=pnl=-0.071343@ep12\n",
      "[dir] ep 18 lr=1.00e-04 tr_loss=0.6171 va_loss=1.4155 f1m=0.134 auc=0.433 pnl_sum=-0.143225 thr=(0.47,0.70) trades=51 sel(va_pnl_max(pnl_sum))=-0.143225 best=pnl=-0.071343@ep12\n",
      "[dir] ep 19 lr=1.00e-04 tr_loss=0.5807 va_loss=1.2634 f1m=0.134 auc=0.420 pnl_sum=-0.075703 thr=(0.47,0.65) trades=41 sel(va_pnl_max(pnl_sum))=-0.075703 best=pnl=-0.071343@ep12\n",
      "[dir] ep 20 lr=1.00e-04 tr_loss=0.5871 va_loss=1.3371 f1m=0.134 auc=0.424 pnl_sum=-0.097686 thr=(0.47,0.70) trades=54 sel(va_pnl_max(pnl_sum))=-0.097686 best=pnl=-0.071343@ep12\n",
      "PnL on fold-test: | thr_trade= 0.46516785319782633 | thr_dir= 0.6 | pnl_sum= 0.03327862173318863 | pnl_mean= 0.00014282669872045517 | trades= 38.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 1634 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7922 va_loss=0.6418 f1m=0.418 auc=0.341 sel(va_auc)=0.340984 best=0.340984@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7588 va_loss=0.7098 f1m=0.366 auc=0.329 sel(va_auc)=0.328725 best=0.340984@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7276 va_loss=0.7289 f1m=0.360 auc=0.322 sel(va_auc)=0.322292 best=0.340984@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7111 va_loss=0.7904 f1m=0.278 auc=0.307 sel(va_auc)=0.306816 best=0.340984@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7072 va_loss=0.8022 f1m=0.313 auc=0.316 sel(va_auc)=0.315510 best=0.340984@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.6944 va_loss=0.8641 f1m=0.283 auc=0.334 sel(va_auc)=0.334029 best=0.340984@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6985 va_loss=0.9441 f1m=0.296 auc=0.330 sel(va_auc)=0.330030 best=0.340984@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6940 va_loss=0.9921 f1m=0.293 auc=0.322 sel(va_auc)=0.322118 best=0.340984@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6806 va_loss=1.0466 f1m=0.294 auc=0.322 sel(va_auc)=0.322031 best=0.340984@ep01\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.486 | q05=0.491 | q10=0.495 | q25=0.533 | q50=0.580 | q75=0.621 | q90=0.636 | q95=0.638 | q99=0.646\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7539 va_loss=0.7963 f1m=0.277 auc=0.393 pnl_sum=-0.154638 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.154638 best=pnl=-0.154638@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7920 va_loss=0.7069 f1m=0.312 auc=0.351 pnl_sum=-0.154638 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.154638 best=pnl=-0.154638@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7340 va_loss=0.7163 f1m=0.253 auc=0.316 pnl_sum=-0.154638 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.154638 best=pnl=-0.154638@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7307 va_loss=0.7049 f1m=0.356 auc=0.351 pnl_sum=-0.191076 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.191076 best=pnl=-0.154638@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7069 va_loss=0.7212 f1m=0.234 auc=0.309 pnl_sum=-0.154638 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.154638 best=pnl=-0.154638@ep01\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7184 va_loss=0.7256 f1m=0.314 auc=0.268 pnl_sum=-0.154638 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.154638 best=pnl=-0.154638@ep01\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6986 va_loss=0.7358 f1m=0.326 auc=0.236 pnl_sum=-0.157687 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.157687 best=pnl=-0.154638@ep01\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.6963 va_loss=0.7463 f1m=0.273 auc=0.217 pnl_sum=-0.175832 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175832 best=pnl=-0.154638@ep01\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.6910 va_loss=0.7687 f1m=0.268 auc=0.213 pnl_sum=-0.157687 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.157687 best=pnl=-0.154638@ep01\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.6627 va_loss=0.7908 f1m=0.268 auc=0.193 pnl_sum=-0.185485 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.185485 best=pnl=-0.154638@ep01\n",
      "[dir] ep 11 lr=2.00e-04 tr_loss=0.6626 va_loss=0.8143 f1m=0.271 auc=0.177 pnl_sum=-0.135001 thr=(0.55,0.60) trades=45 sel(va_pnl_max(pnl_sum))=-0.135001 best=pnl=-0.135001@ep11\n",
      "[dir] ep 12 lr=2.00e-04 tr_loss=0.6557 va_loss=0.8706 f1m=0.247 auc=0.172 pnl_sum=-0.157687 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.157687 best=pnl=-0.135001@ep11\n",
      "[dir] ep 13 lr=2.00e-04 tr_loss=0.6472 va_loss=0.8395 f1m=0.260 auc=0.179 pnl_sum=-0.059103 thr=(0.05,0.70) trades=40 sel(va_pnl_max(pnl_sum))=-0.059103 best=pnl=-0.059103@ep13\n",
      "[dir] ep 14 lr=2.00e-04 tr_loss=0.6464 va_loss=0.8816 f1m=0.259 auc=0.178 pnl_sum=-0.154638 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.154638 best=pnl=-0.059103@ep13\n",
      "[dir] ep 15 lr=2.00e-04 tr_loss=0.6448 va_loss=0.8615 f1m=0.249 auc=0.188 pnl_sum=-0.067414 thr=(0.05,0.70) trades=41 sel(va_pnl_max(pnl_sum))=-0.067414 best=pnl=-0.059103@ep13\n",
      "[dir] ep 16 lr=2.00e-04 tr_loss=0.6255 va_loss=0.9234 f1m=0.247 auc=0.190 pnl_sum=-0.137842 thr=(0.05,0.70) trades=49 sel(va_pnl_max(pnl_sum))=-0.137842 best=pnl=-0.059103@ep13\n",
      "[dir] ep 17 lr=2.00e-04 tr_loss=0.6294 va_loss=0.9084 f1m=0.251 auc=0.195 pnl_sum=-0.079799 thr=(0.05,0.70) trades=46 sel(va_pnl_max(pnl_sum))=-0.079799 best=pnl=-0.059103@ep13\n",
      "[dir] ep 18 lr=1.00e-04 tr_loss=0.6116 va_loss=0.9785 f1m=0.255 auc=0.197 pnl_sum=-0.185485 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.185485 best=pnl=-0.059103@ep13\n",
      "[dir] ep 19 lr=1.00e-04 tr_loss=0.6052 va_loss=0.9691 f1m=0.255 auc=0.202 pnl_sum=-0.199163 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.199163 best=pnl=-0.059103@ep13\n",
      "[dir] ep 20 lr=1.00e-04 tr_loss=0.6055 va_loss=0.9787 f1m=0.249 auc=0.205 pnl_sum=-0.161085 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.161085 best=pnl=-0.059103@ep13\n",
      "[dir] ep 21 lr=1.00e-04 tr_loss=0.5761 va_loss=0.9657 f1m=0.259 auc=0.204 pnl_sum=-0.175832 thr=(0.63,0.50) trades=40 sel(va_pnl_max(pnl_sum))=-0.175832 best=pnl=-0.059103@ep13\n",
      "PnL on fold-test: | thr_trade= 0.05 | thr_dir= 0.5 | pnl_sum= 0.249380424618721 | pnl_mean= 0.0010703022126108408 | trades= 233.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 1867 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7652 va_loss=0.4191 f1m=0.463 auc=0.565 sel(va_auc)=0.565454 best=0.565454@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7109 va_loss=0.3911 f1m=0.463 auc=0.635 sel(va_auc)=0.635261 best=0.635261@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6891 va_loss=0.3356 f1m=0.463 auc=0.648 sel(va_auc)=0.647699 best=0.647699@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6850 va_loss=0.3207 f1m=0.463 auc=0.658 sel(va_auc)=0.657649 best=0.657649@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6831 va_loss=0.3191 f1m=0.463 auc=0.671 sel(va_auc)=0.671020 best=0.671020@ep05\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6787 va_loss=0.3146 f1m=0.463 auc=0.688 sel(va_auc)=0.688433 best=0.688433@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6719 va_loss=0.3131 f1m=0.463 auc=0.698 sel(va_auc)=0.697606 best=0.697606@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6728 va_loss=0.3113 f1m=0.463 auc=0.706 sel(va_auc)=0.705690 best=0.705690@ep08\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6689 va_loss=0.3146 f1m=0.463 auc=0.703 sel(va_auc)=0.702581 best=0.705690@ep08\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6685 va_loss=0.3139 f1m=0.463 auc=0.705 sel(va_auc)=0.704913 best=0.705690@ep08\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.6624 va_loss=0.3146 f1m=0.463 auc=0.704 sel(va_auc)=0.703669 best=0.705690@ep08\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.6615 va_loss=0.3131 f1m=0.463 auc=0.706 sel(va_auc)=0.706157 best=0.706157@ep12\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.6579 va_loss=0.3112 f1m=0.463 auc=0.704 sel(va_auc)=0.703514 best=0.706157@ep12\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.6588 va_loss=0.3309 f1m=0.463 auc=0.692 sel(va_auc)=0.691698 best=0.706157@ep12\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.6654 va_loss=0.3201 f1m=0.463 auc=0.711 sel(va_auc)=0.711443 best=0.711443@ep15\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.6494 va_loss=0.3176 f1m=0.463 auc=0.697 sel(va_auc)=0.697450 best=0.711443@ep15\n",
      "[trade] ep 17 lr=2.00e-04 tr_loss=0.6553 va_loss=0.3253 f1m=0.463 auc=0.666 sel(va_auc)=0.665734 best=0.711443@ep15\n",
      "[trade] ep 18 lr=2.00e-04 tr_loss=0.6477 va_loss=0.3185 f1m=0.463 auc=0.697 sel(va_auc)=0.697139 best=0.711443@ep15\n",
      "[trade] ep 19 lr=2.00e-04 tr_loss=0.6430 va_loss=0.3160 f1m=0.463 auc=0.649 sel(va_auc)=0.648632 best=0.711443@ep15\n",
      "[trade] ep 20 lr=1.00e-04 tr_loss=0.6431 va_loss=0.3379 f1m=0.463 auc=0.624 sel(va_auc)=0.623601 best=0.711443@ep15\n",
      "[trade] ep 21 lr=1.00e-04 tr_loss=0.6352 va_loss=0.3253 f1m=0.463 auc=0.620 sel(va_auc)=0.620025 best=0.711443@ep15\n",
      "[trade] ep 22 lr=1.00e-04 tr_loss=0.6359 va_loss=0.3189 f1m=0.463 auc=0.618 sel(va_auc)=0.617848 best=0.711443@ep15\n",
      "[trade] ep 23 lr=1.00e-04 tr_loss=0.6305 va_loss=0.3293 f1m=0.463 auc=0.608 sel(va_auc)=0.608053 best=0.711443@ep15\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.893 | q05=0.902 | q10=0.914 | q25=0.927 | q50=0.934 | q75=0.948 | q90=0.959 | q95=0.960 | q99=0.961\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7758 va_loss=0.6905 f1m=0.475 auc=0.536 pnl_sum=-0.010133 thr=(0.95,0.55) trades=55 sel(va_pnl_max(pnl_sum))=-0.010133 best=pnl=-0.010133@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7660 va_loss=0.6984 f1m=0.438 auc=0.497 pnl_sum=0.039122 thr=(0.95,0.60) trades=50 sel(va_pnl_max(pnl_sum))=0.039122 best=pnl=0.039122@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7116 va_loss=0.6960 f1m=0.530 auc=0.504 pnl_sum=0.107713 thr=(0.05,0.50) trades=233 sel(va_pnl_max(pnl_sum))=0.107713 best=pnl=0.107713@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7174 va_loss=0.7043 f1m=0.394 auc=0.503 pnl_sum=0.046128 thr=(0.05,0.60) trades=124 sel(va_pnl_max(pnl_sum))=0.046128 best=pnl=0.107713@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7047 va_loss=0.6973 f1m=0.463 auc=0.509 pnl_sum=0.050364 thr=(0.05,0.55) trades=144 sel(va_pnl_max(pnl_sum))=0.050364 best=pnl=0.107713@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7206 va_loss=0.6913 f1m=0.587 auc=0.519 pnl_sum=0.288659 thr=(0.05,0.50) trades=233 sel(va_pnl_max(pnl_sum))=0.288659 best=pnl=0.288659@ep06\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6865 va_loss=0.6937 f1m=0.560 auc=0.527 pnl_sum=0.220521 thr=(0.05,0.50) trades=233 sel(va_pnl_max(pnl_sum))=0.220521 best=pnl=0.288659@ep06\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.6880 va_loss=0.6925 f1m=0.635 auc=0.568 pnl_sum=0.457505 thr=(0.05,0.50) trades=233 sel(va_pnl_max(pnl_sum))=0.457505 best=pnl=0.457505@ep08\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.6855 va_loss=0.6970 f1m=0.586 auc=0.539 pnl_sum=0.286257 thr=(0.05,0.50) trades=233 sel(va_pnl_max(pnl_sum))=0.286257 best=pnl=0.457505@ep08\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.6824 va_loss=0.6975 f1m=0.606 auc=0.530 pnl_sum=0.340012 thr=(0.05,0.50) trades=233 sel(va_pnl_max(pnl_sum))=0.340012 best=pnl=0.457505@ep08\n",
      "[dir] ep 11 lr=2.00e-04 tr_loss=0.6689 va_loss=0.7005 f1m=0.590 auc=0.520 pnl_sum=0.294034 thr=(0.05,0.55) trades=199 sel(va_pnl_max(pnl_sum))=0.294034 best=pnl=0.457505@ep08\n",
      "[dir] ep 12 lr=2.00e-04 tr_loss=0.6663 va_loss=0.7159 f1m=0.576 auc=0.524 pnl_sum=0.267162 thr=(0.05,0.55) trades=222 sel(va_pnl_max(pnl_sum))=0.267162 best=pnl=0.457505@ep08\n",
      "[dir] ep 13 lr=1.00e-04 tr_loss=0.6508 va_loss=0.7290 f1m=0.557 auc=0.525 pnl_sum=0.223378 thr=(0.05,0.55) trades=193 sel(va_pnl_max(pnl_sum))=0.223378 best=pnl=0.457505@ep08\n",
      "[dir] ep 14 lr=1.00e-04 tr_loss=0.6555 va_loss=0.7303 f1m=0.555 auc=0.529 pnl_sum=0.250616 thr=(0.05,0.60) trades=175 sel(va_pnl_max(pnl_sum))=0.250616 best=pnl=0.457505@ep08\n",
      "[dir] ep 15 lr=1.00e-04 tr_loss=0.6531 va_loss=0.7356 f1m=0.560 auc=0.543 pnl_sum=0.270365 thr=(0.05,0.60) trades=172 sel(va_pnl_max(pnl_sum))=0.270365 best=pnl=0.457505@ep08\n",
      "[dir] ep 16 lr=1.00e-04 tr_loss=0.6554 va_loss=0.7368 f1m=0.566 auc=0.549 pnl_sum=0.255409 thr=(0.05,0.55) trades=215 sel(va_pnl_max(pnl_sum))=0.255409 best=pnl=0.457505@ep08\n",
      "PnL on fold-test: | thr_trade= 0.05 | thr_dir= 0.6 | pnl_sum= 0.036805327981710434 | pnl_mean= 0.00015796278603374958 | trades= 45.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.218591</td>\n",
       "      <td>0.389474</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.257085</td>\n",
       "      <td>0.373448</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.465168</td>\n",
       "      <td>0.6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.163090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.463134</td>\n",
       "      <td>0.482351</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.515068</td>\n",
       "      <td>0.302439</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.193133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.218591      0.389474       0.001153        0.050000   \n",
       "1     2        0.257085      0.373448       0.000143        0.465168   \n",
       "2     3        0.463134      0.482351       0.001070        0.050000   \n",
       "3     4        0.515068      0.302439       0.000158        0.050000   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0           0.5          233.0         1.000000  \n",
       "1           0.6           38.0         0.163090  \n",
       "2           0.5          233.0         1.000000  \n",
       "3           0.6           45.0         0.193133  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN (fold-test внутри CV-part):\n",
      "fold                 2.500000\n",
      "trade_test_f1m       0.363470\n",
      "dir_test_f1m         0.386928\n",
      "best_pnl_mean        0.000631\n",
      "best_thr_trade       0.153792\n",
      "best_thr_dir         0.550000\n",
      "n_trades_best      137.250000\n",
      "trade_rate_best      0.589056\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training (ONLY on CV-part)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold (fit only on train times)\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples (по AUC)\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\",\n",
    "        select_metric=\"va_auc\",\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples (train/val/test индексы фильтруем)\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "            \"trade_rate_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # dir: учим на trade-only, но PnL-proxy считаем на полном idx_va (full val)\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\",\n",
    "        select_metric=\"va_pnl_max\",\n",
    "        trade_model_for_pnl=m_trade,\n",
    "        idx_val_pnl=idx_va,   # <-- полный val для pnl-proxy\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on fold TEST\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te, CFG)\n",
    "    prob_dir_te, _       = predict_probs_on_indices(m_dir,   X_scaled, edge_feat, idx_te, CFG)\n",
    "\n",
    "    \n",
    "    objective = CFG.get(\"pnl_objective\", \"pnl_sum\")\n",
    "    min_tr_eval = int(CFG.get(\"eval_min_trades\", 0))\n",
    "\n",
    "    sweep = sweep_thresholds(\n",
    "        prob_trade_te, prob_dir_te, er_te,\n",
    "        CFG,\n",
    "        min_trades=min_tr_eval,\n",
    "        objective=objective\n",
    "    )\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on fold-test:\",\n",
    "        \"| thr_trade=\", best[\"thr_trade\"],\n",
    "        \"| thr_dir=\", best[\"thr_dir\"],\n",
    "        f\"| {objective}=\", best[objective],\n",
    "        \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "        \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN (fold-test внутри CV-part):\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": [
    "## 11. Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50d16463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL TRAIN/TEST (CV=90% | FINAL=10%)\n",
      "Final split sizes:\n",
      "  train_final: 2104\n",
      "  val_final  : 233\n",
      "  FINAL test : 260\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : 0.0001522971724625677\n",
      "  pnl_sum  : 0.03959726542234421\n",
      "  n_trades : 95\n",
      "  trade_rate: 0.36538461538461536\n",
      "  sharpe (per-bar proxy): 0.45627262557609977\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.7 thr_dir: 0.5\n",
      "  pnl_mean : 0.0014860207447782159 trades: 234.0\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Final train on CV(90%) and evaluate once on FINAL(10%)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAIN/TEST (CV=90% | FINAL=10%)\")\n",
    "\n",
    "# 1) final train/val split внутри CV-part (по времени)\n",
    "val_w_final = max(1, int(CFG[\"val_window_frac\"] * n_samples_cv))\n",
    "train_end = n_samples_cv - val_w_final\n",
    "\n",
    "idx_train_final = np.arange(0, train_end, dtype=np.int64)\n",
    "idx_val_final   = np.arange(train_end, n_samples_cv, dtype=np.int64)\n",
    "idx_test_final  = idx_final_test.astype(np.int64)  # финальный holdout\n",
    "\n",
    "print(\"Final split sizes:\")\n",
    "print(\"  train_final:\", len(idx_train_final))\n",
    "print(\"  val_final  :\", len(idx_val_final))\n",
    "print(\"  FINAL test :\", len(idx_test_final))\n",
    "\n",
    "# 2) scaling (fit only on train_final)\n",
    "X_scaled_final, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train_final, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=summary['best_thr_trade'][3],\n",
    "    thr_dir=summary['best_thr_dir'][3],\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c4946a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.9004 va_loss=0.6494 f1m=0.380 auc=0.521 sel(va_auc)=0.521290 best=0.521290@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7021 va_loss=0.6661 f1m=0.499 auc=0.521 sel(va_auc)=0.520901 best=0.521290@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6776 va_loss=0.6786 f1m=0.509 auc=0.533 sel(va_auc)=0.532867 best=0.532867@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6539 va_loss=0.6744 f1m=0.508 auc=0.538 sel(va_auc)=0.537762 best=0.537762@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6531 va_loss=0.6743 f1m=0.505 auc=0.520 sel(va_auc)=0.519658 best=0.537762@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6434 va_loss=0.6756 f1m=0.489 auc=0.518 sel(va_auc)=0.517793 best=0.537762@ep04\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6408 va_loss=0.7092 f1m=0.536 auc=0.520 sel(va_auc)=0.520202 best=0.537762@ep04\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6290 va_loss=0.6960 f1m=0.500 auc=0.491 sel(va_auc)=0.490831 best=0.537762@ep04\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6368 va_loss=0.6976 f1m=0.497 auc=0.491 sel(va_auc)=0.490909 best=0.537762@ep04\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.6333 va_loss=0.7113 f1m=0.501 auc=0.492 sel(va_auc)=0.491841 best=0.537762@ep04\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.6332 va_loss=0.7112 f1m=0.507 auc=0.487 sel(va_auc)=0.487257 best=0.537762@ep04\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.6260 va_loss=0.7055 f1m=0.501 auc=0.486 sel(va_auc)=0.485703 best=0.537762@ep04\n",
      "Trade-only sizes for DIR:\n",
      "  train_final_T: 963\n",
      "  val_final_T  : 143\n",
      "  test_final_T : 207\n",
      "[trade prob stats] val_pnl (for dir selector): q01=0.414 | q05=0.419 | q10=0.421 | q25=0.465 | q50=0.627 | q75=0.739 | q90=0.765 | q95=0.777 | q99=0.782\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8359 va_loss=0.6886 f1m=0.344 auc=0.673 pnl_sum=-0.009139 thr=(0.05,0.55) trades=128 sel(va_pnl_max(pnl_sum))=-0.009139 best=pnl=-0.009139@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7293 va_loss=0.6824 f1m=0.545 auc=0.679 pnl_sum=0.309683 thr=(0.05,0.50) trades=233 sel(va_pnl_max(pnl_sum))=0.309683 best=pnl=0.309683@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7274 va_loss=0.6818 f1m=0.629 auc=0.708 pnl_sum=0.460168 thr=(0.55,0.50) trades=142 sel(va_pnl_max(pnl_sum))=0.460168 best=pnl=0.460168@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7152 va_loss=0.6844 f1m=0.617 auc=0.730 pnl_sum=0.530647 thr=(0.05,0.50) trades=233 sel(va_pnl_max(pnl_sum))=0.530647 best=pnl=0.530647@ep04\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7075 va_loss=0.6924 f1m=0.350 auc=0.701 pnl_sum=0.296969 thr=(0.05,0.55) trades=216 sel(va_pnl_max(pnl_sum))=0.296969 best=pnl=0.530647@ep04\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7057 va_loss=0.6858 f1m=0.350 auc=0.696 pnl_sum=0.264080 thr=(0.55,0.55) trades=128 sel(va_pnl_max(pnl_sum))=0.264080 best=pnl=0.530647@ep04\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6905 va_loss=0.6840 f1m=0.350 auc=0.717 pnl_sum=0.376695 thr=(0.05,0.55) trades=103 sel(va_pnl_max(pnl_sum))=0.376695 best=pnl=0.530647@ep04\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.7033 va_loss=0.6903 f1m=0.350 auc=0.679 pnl_sum=0.247636 thr=(0.55,0.50) trades=142 sel(va_pnl_max(pnl_sum))=0.247636 best=pnl=0.530647@ep04\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7049 va_loss=0.6871 f1m=0.584 auc=0.640 pnl_sum=0.499974 thr=(0.55,0.50) trades=142 sel(va_pnl_max(pnl_sum))=0.499974 best=pnl=0.530647@ep04\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.7002 va_loss=0.6879 f1m=0.350 auc=0.684 pnl_sum=0.247636 thr=(0.55,0.50) trades=142 sel(va_pnl_max(pnl_sum))=0.247636 best=pnl=0.530647@ep04\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.6958 va_loss=0.6855 f1m=0.350 auc=0.753 pnl_sum=0.247636 thr=(0.55,0.50) trades=142 sel(va_pnl_max(pnl_sum))=0.247636 best=pnl=0.530647@ep04\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.6809 va_loss=0.6828 f1m=0.350 auc=0.718 pnl_sum=0.247636 thr=(0.55,0.50) trades=142 sel(va_pnl_max(pnl_sum))=0.247636 best=pnl=0.530647@ep04\n",
      "\n",
      "Chosen thresholds on val_final:\n",
      "  thr_trade*: 0.05\n",
      "  thr_dir*  : 0.5\n",
      "  val pnl_mean: 0.0022774548269808292 | val trades: 233\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : 0.001403758185915649\n",
      "  pnl_sum  : 0.3649771213531494\n",
      "  n_trades : 260\n",
      "  trade_rate: 1.0\n",
      "  sharpe (per-bar proxy): 2.7240368831237403\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.05 thr_dir: 0.5\n",
      "  pnl_mean : 0.001403758185915649 trades: 260.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3) train TRADE on train_final, select by AUC on val_final\n",
    "m_trade_final, r_trade_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final, idx_val_final, idx_test_final,\n",
    "    CFG,\n",
    "    stage_name=\"trade\",\n",
    "    select_metric=\"va_auc\",\n",
    ")\n",
    "\n",
    "# 4) train DIR on trade-only samples (train/val/test filtered),\n",
    "#    but pnl-proxy computed on full val_final; selector hard-fallback already inside\n",
    "idx_train_final_T = subset_trade_indices(idx_train_final, sample_t, y_trade)\n",
    "idx_val_final_T   = subset_trade_indices(idx_val_final,   sample_t, y_trade)\n",
    "idx_test_final_T  = subset_trade_indices(idx_test_final,  sample_t, y_trade)\n",
    "\n",
    "print(\"Trade-only sizes for DIR:\")\n",
    "print(\"  train_final_T:\", len(idx_train_final_T))\n",
    "print(\"  val_final_T  :\", len(idx_val_final_T))\n",
    "print(\"  test_final_T :\", len(idx_test_final_T))\n",
    "\n",
    "m_dir_final, r_dir_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final_T, idx_val_final_T, idx_test_final_T,\n",
    "    CFG,\n",
    "    stage_name=\"dir\",\n",
    "    select_metric=\"va_pnl_max\",\n",
    "    trade_model_for_pnl=m_trade_final,\n",
    "    idx_val_pnl=idx_val_final,   # pnl-proxy на полном val_final\n",
    ")\n",
    "\n",
    "# 5) выбрать пороги по val_final (grid sweep)\n",
    "prob_trade_val, er_val = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "prob_dir_val, _        = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "\n",
    "sweep_val = sweep_thresholds(prob_trade_val, prob_dir_val, er_val, CFG)\n",
    "best_val = sweep_val.iloc[0].to_dict()\n",
    "thr_trade_star = float(best_val[\"thr_trade\"])\n",
    "thr_dir_star   = float(best_val[\"thr_dir\"])\n",
    "\n",
    "print(\"\\nChosen thresholds on val_final:\")\n",
    "print(\"  thr_trade*:\", thr_trade_star)\n",
    "print(\"  thr_dir*  :\", thr_dir_star)\n",
    "print(\"  val pnl_mean:\", float(best_val[\"pnl_mean\"]), \"| val trades:\", int(best_val[\"n_trades\"]))\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=thr_trade_star,\n",
    "    thr_dir=thr_dir_star,\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
