{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX (with self-loops): [[0, 1], [0, 2], [2, 1], [0, 0], [1, 1], [2, 2]]\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1], [0, 0], [1, 1], [2, 2]]\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),  \n",
    "    # NEW: holdout final test split (по времени, на sample-space)\n",
    "    \"final_test_frac\": 0.10, \n",
    "\n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 84],  # 30m,1h,2h,4h,7h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 1*12,       # 1h     # нужен для sample_t (чтобы TB-exit не вылезал за конец)\n",
    "    \"lookback\": 7*12,   \n",
    "    \"tb_pt_mult\": 1.2,\n",
    "    \"tb_sl_mult\": 1.1,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "    # training (общие)\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.2,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "\n",
    "    \"proxy_min_trades\": 20,        # защита от \"лучший pnl = 0 потому что 0 трейдов\"\n",
    "\n",
    "        # --- GAT (spatial)\n",
    "    \"gat_heads\": 2,          # попробуй 1/2/4 (hidden не обязан делиться идеально)\n",
    "\n",
    "    # --- TCN (temporal)\n",
    "    \"tcn_channels\": 64,      # ширина temporal-канала\n",
    "    \"tcn_layers\": 4,         # число residual TCN блоков\n",
    "    \"tcn_kernel\": 3,         # kernel size\n",
    "    \"tcn_dropout\": 0.2,      # обычно = CFG[\"dropout\"]\n",
    "    \"tcn_causal\": True,      # True = no leakage (рекомендуется)\n",
    "    \"tcn_pool\": \"last\",      # \"last\" или \"mean\"\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "\n",
    "def add_self_loops_edge_index(edge_index: torch.Tensor, num_nodes: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    edge_index: (E,2) [src,dst]\n",
    "    returns: (E+N,2) with added (i,i)\n",
    "    \"\"\"\n",
    "    loops = torch.arange(num_nodes, dtype=edge_index.dtype).view(-1, 1)\n",
    "    loops = torch.cat([loops, loops], dim=1)  # (N,2) i->i\n",
    "    return torch.cat([edge_index, loops], dim=0)\n",
    "\n",
    "EDGE_INDEX = add_self_loops_edge_index(EDGE_INDEX, num_nodes=len(ASSETS))\n",
    "print(\"EDGE_INDEX (with self-loops):\", EDGE_INDEX.tolist())\n",
    "\n",
    "CFG[\"thr_trade_grid\"] = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "CFG[\"thr_dir_grid\"]   = [0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "\n",
    "# 2) минимальное число сделок, которое мы хотим ВЫНУЖДАТЬ при выборе порогов\n",
    "CFG[\"eval_min_trades\"] = 20           # применяется в sweep на test/val/holdout\n",
    "CFG[\"proxy_min_trades\"] = 20          # оставляем как было, но теперь реально достижимо\n",
    "\n",
    "# 3) динамические целевые уровни сделок (чтобы пороги подстраивались под распределение p_trade)\n",
    "CFG[\"proxy_target_trades\"] = [20, 40, 60, 80, 120]  # будет превращено в пороги по квантилям\n",
    "\n",
    "# 4) что оптимизируем на сетке: pnl_sum обычно стабильнее чем pnl_mean\n",
    "CFG[\"pnl_objective\"] = \"pnl_sum\"      # \"pnl_mean\" тоже можно\n",
    "print(\"CFG thresholds updated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (2693, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int, part = [0,100]) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.iloc[int(len(df)*part[0]/100) : int(len(df)*part[1]/100)]\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels, part = [0, 80]), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels, part = [0, 80]), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels, part = [0, 80]), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (2693, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [ 655 1311  727]\n",
      "Trade ratio: 0.5131823245451169\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=1*12, \n",
    "    vol_window=7*12,\n",
    "    pt_mult=1.2,\n",
    "    sl_mult=1.1,\n",
    "    min_barrier=0.001,\n",
    "    max_barrier=0.006,\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (2693, 3, 15) edge_feat: (2693, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 2597 t range: 83 2679\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb5de4",
   "metadata": {},
   "source": [
    "## Train (folds) - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9bad799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout split:\n",
      "  n_samples total: 2597\n",
      "  n_samples CV   : 2337 (90.0%)\n",
      "  n_samples FINAL: 260 (10.0%)\n",
      "  CV range   : 0 2336\n",
      "  FINAL range: 2337 2596\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: final holdout split (90% CV + 10% final test), time-ordered\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_final_holdout_split(n_samples: int, final_test_frac: float):\n",
    "    if not (0.0 < final_test_frac < 0.5):\n",
    "        raise ValueError(\"final_test_frac should be in (0, 0.5)\")\n",
    "\n",
    "    n_final = max(1, int(round(final_test_frac * n_samples)))\n",
    "    n_cv = n_samples - n_final\n",
    "    if n_cv <= 10:\n",
    "        raise ValueError(\"Too few samples left for CV after holdout split.\")\n",
    "\n",
    "    idx_cv = np.arange(0, n_cv, dtype=np.int64)\n",
    "    idx_final = np.arange(n_cv, n_samples, dtype=np.int64)\n",
    "    return idx_cv, idx_final, n_cv, n_final\n",
    "\n",
    "idx_cv_all, idx_final_test, n_samples_cv, n_samples_final = make_final_holdout_split(\n",
    "    n_samples=n_samples,\n",
    "    final_test_frac=CFG[\"final_test_frac\"],\n",
    ")\n",
    "\n",
    "print(\"Holdout split:\")\n",
    "print(\"  n_samples total:\", n_samples)\n",
    "print(\"  n_samples CV   :\", n_samples_cv, f\"({100*(n_samples_cv/n_samples):.1f}%)\")\n",
    "print(\"  n_samples FINAL:\", n_samples_final, f\"({100*(n_samples_final/n_samples):.1f}%)\")\n",
    "print(\"  CV range   :\", idx_cv_all[0], idx_cv_all[-1])\n",
    "print(\"  FINAL range:\", idx_final_test[0], idx_final_test[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1168 | val 233 | test 233\n",
      " fold 2: train 1401 | val 233 | test 233\n",
      " fold 3: train 1634 | val 233 | test 233\n",
      " fold 4: train 1867 | val 233 | test 233\n",
      "\n",
      "FINAL HOLDOUT:\n",
      " final_test size: 260\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test) on CV-part only\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "\n",
    "        idx_train = np.arange(0, tr_end, dtype=np.int64)\n",
    "        idx_val   = np.arange(tr_end, va_end, dtype=np.int64)\n",
    "        idx_test  = np.arange(va_end, te_end, dtype=np.int64)\n",
    "\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "\n",
    "    return splits\n",
    "\n",
    "# IMPORTANT: строим сплиты только на 90% (CV-part)\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples_cv,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "for i, (a, b, c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT:\")\n",
    "print(\" final_test size:\", len(idx_final_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready. logits: torch.Size([4, 2]) finite: True\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: SGA-TCN model (drop-in replacement for GNN_LSTM_Classifier)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "\n",
    "\n",
    "# ЛОГИЧЕСКИЙ БЛОК: SpatialGraphAttention with self-loop edge_attr padding\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class SpatialGraphAttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention with edge_attr in attention scorer:\n",
    "      score_e = a^T [h_src || h_dst || edge_emb]\n",
    "      attn normalized per-dst over incoming edges\n",
    "      msg = W_msg(h_src)\n",
    "      agg_dst = sum(attn * msg)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, out_dim: int, edge_dim: int, heads: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.heads = max(1, int(heads))\n",
    "        self.dropout = float(dropout)\n",
    "\n",
    "        self.head_dim = max(1, int(math.ceil(out_dim / self.heads)))\n",
    "        self.inner_dim = self.heads * self.head_dim\n",
    "\n",
    "        self.lin_node = nn.Linear(in_dim, self.inner_dim, bias=False)\n",
    "        self.lin_edge = nn.Linear(edge_dim, self.inner_dim, bias=False)\n",
    "        self.lin_msg  = nn.Linear(self.inner_dim, self.inner_dim, bias=False)\n",
    "\n",
    "        self.attn_vec = nn.Parameter(torch.empty(self.heads, 3 * self.head_dim))\n",
    "\n",
    "        self.out_proj = nn.Linear(self.inner_dim, out_dim, bias=False)\n",
    "        self.res_proj = nn.Identity() if in_dim == out_dim else nn.Linear(in_dim, out_dim, bias=False)\n",
    "\n",
    "        self.ln = nn.LayerNorm(out_dim)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.out_drop = nn.Dropout(dropout)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in [self.lin_node, self.lin_edge, self.lin_msg, self.out_proj]:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if isinstance(self.res_proj, nn.Linear):\n",
    "            nn.init.xavier_uniform_(self.res_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_vec)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_attr: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x:         (B,N,Fin)\n",
    "        edge_attr: (B,E_attr,W)  (может быть меньше чем E_index из-за self-loops)\n",
    "        edge_index:(E_index,2)   includes self-loops\n",
    "        returns:   (B,N,out_dim)\n",
    "        \"\"\"\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        edge_attr = torch.nan_to_num(edge_attr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        B, N, _ = x.shape\n",
    "        E_index = edge_index.shape[0]\n",
    "        E_attr = edge_attr.shape[1]\n",
    "        W = edge_attr.shape[2]\n",
    "\n",
    "        # --- pad edge_attr with zeros for self-loops if needed\n",
    "        if E_attr < E_index:\n",
    "            pad = torch.zeros((B, E_index - E_attr, W), device=edge_attr.device, dtype=edge_attr.dtype)\n",
    "            edge_attr = torch.cat([edge_attr, pad], dim=1)\n",
    "        elif E_attr > E_index:\n",
    "            edge_attr = edge_attr[:, :E_index, :]\n",
    "\n",
    "        src_idx = edge_index[:, 0]\n",
    "        dst_idx = edge_index[:, 1]\n",
    "\n",
    "        h = self.lin_node(x)  # (B,N,inner)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        h = h.view(B, N, self.heads, self.head_dim)\n",
    "\n",
    "        eemb = self.lin_edge(edge_attr)  # (B,E,inner)\n",
    "        eemb = torch.nan_to_num(eemb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        eemb = eemb.view(B, E_index, self.heads, self.head_dim)\n",
    "\n",
    "        h_src = h[:, src_idx, :, :]  # (B,E,heads,dh)\n",
    "        h_dst = h[:, dst_idx, :, :]  # (B,E,heads,dh)\n",
    "\n",
    "        cat = torch.cat([h_src, h_dst, eemb], dim=-1)  # (B,E,heads,3*dh)\n",
    "        scores = (cat * self.attn_vec[None, None, :, :]).sum(dim=-1)  # (B,E,heads)\n",
    "        scores = self.act(scores)\n",
    "\n",
    "        alphas = torch.zeros_like(scores)  # (B,E,heads)\n",
    "        for n in range(N):\n",
    "            mask = (dst_idx == n)\n",
    "            if int(mask.sum()) == 0:\n",
    "                continue\n",
    "            s = scores[:, mask, :]\n",
    "            a = torch.softmax(s, dim=1)\n",
    "            a = self.attn_drop(a)\n",
    "            alphas[:, mask, :] = a\n",
    "\n",
    "        msg = self.lin_msg(h_src.reshape(B, E_index, self.inner_dim)).view(B, E_index, self.heads, self.head_dim)\n",
    "\n",
    "        agg = torch.zeros((B, N, self.heads, self.head_dim), device=x.device, dtype=x.dtype)\n",
    "        for e_i in range(E_index):\n",
    "            dst = int(dst_idx[e_i].item())\n",
    "            agg[:, dst, :, :] += alphas[:, e_i, :].unsqueeze(-1) * msg[:, e_i, :, :]\n",
    "\n",
    "        out = agg.reshape(B, N, self.inner_dim)\n",
    "        out = self.out_proj(out)\n",
    "        out = self.out_drop(out)\n",
    "\n",
    "        res = self.res_proj(x)\n",
    "        y = self.ln(res + out)\n",
    "        return torch.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "class SpatialGraphAttentionMP(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies SpatialGraphAttentionLayer independently at each timestep t:\n",
    "      x_seq: (B,L,N,F) -> h_seq: (B,L,N,H)\n",
    "\n",
    "    Handles edge_attr padding if EDGE_INDEX includes self-loops but e_seq doesn't.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, hidden: int, edge_dim: int, heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.gat = SpatialGraphAttentionLayer(in_dim=in_dim, out_dim=hidden, edge_dim=edge_dim, heads=heads, dropout=dropout)\n",
    "\n",
    "    def forward_once(self, x_t: torch.Tensor, edge_attr_t: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        return self.gat(x_t, edge_attr_t, edge_index)\n",
    "\n",
    "    def forward(self, x_seq: torch.Tensor, e_seq: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        x_seq = torch.nan_to_num(x_seq, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        e_seq = torch.nan_to_num(e_seq, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        B, L, N, _ = x_seq.shape\n",
    "        hs = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            hs.append(ht)\n",
    "        return torch.stack(hs, dim=1)  # (B,L,N,H)\n",
    "\n",
    "\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"Causal Conv1d: pads only on the left => no future leakage.\"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, dilation: int = 1):\n",
    "        super().__init__()\n",
    "        self.kernel_size = int(kernel_size)\n",
    "        self.dilation = int(dilation)\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=self.kernel_size, dilation=self.dilation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,C,L)\n",
    "        pad_left = (self.kernel_size - 1) * self.dilation\n",
    "        x = F.pad(x, (pad_left, 0))\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, dilation: int, dropout: float, causal: bool = True):\n",
    "        super().__init__()\n",
    "        self.causal = bool(causal)\n",
    "\n",
    "        if self.causal:\n",
    "            conv1 = CausalConv1d(in_ch, out_ch, kernel_size, dilation=dilation)\n",
    "            conv2 = CausalConv1d(out_ch, out_ch, kernel_size, dilation=dilation)\n",
    "        else:\n",
    "            # non-causal WITHOUT future leakage is tricky; safest is causal=True.\n",
    "            # If you set causal=False, consider it \"experimental\".\n",
    "            pad = ((kernel_size - 1) * dilation) // 2\n",
    "            conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, dilation=dilation, padding=pad)\n",
    "            conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, dilation=dilation, padding=pad)\n",
    "\n",
    "        self.conv1 = conv1\n",
    "        self.conv2 = conv2\n",
    "\n",
    "        self.act = nn.GELU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Identity() if in_ch == out_ch else nn.Conv1d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv1d,)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,C,L)\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        y = self.conv1(x)\n",
    "        y = self.act(y)\n",
    "        y = self.drop(y)\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        y = self.act(y)\n",
    "        y = self.drop(y)\n",
    "\n",
    "        res = self.downsample(x)\n",
    "        out = self.act(y + res)\n",
    "        return torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, in_ch: int, channels: list[int], kernel_size: int, dropout: float, causal: bool = True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i, out_ch in enumerate(channels):\n",
    "            dilation = 2 ** i\n",
    "            layers.append(\n",
    "                TemporalBlock(\n",
    "                    in_ch=in_ch,\n",
    "                    out_ch=out_ch,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=dilation,\n",
    "                    dropout=dropout,\n",
    "                    causal=causal,\n",
    "                )\n",
    "            )\n",
    "            in_ch = out_ch\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    DROP-IN replacement:\n",
    "      input:  x_seq (B,L,N,F), e_seq (B,L,E,W), edge_index (E,2)\n",
    "      output: logits (B,2)\n",
    "\n",
    "    Internally это SGA-TCN:\n",
    "      - Spatial: Graph Attention per timestep (edge_attr in scorer)\n",
    "      - Temporal: TCN on target_node sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = int(target_node)\n",
    "\n",
    "        # --- read new params from global CFG (fallback to reasonable defaults)\n",
    "        _cfg = globals().get(\"CFG\", {})\n",
    "        gat_heads = int(_cfg.get(\"gat_heads\", 1))\n",
    "\n",
    "        tcn_channels = int(_cfg.get(\"tcn_channels\", hidden))\n",
    "        tcn_layers_n = int(_cfg.get(\"tcn_layers\", 4))\n",
    "        tcn_kernel = int(_cfg.get(\"tcn_kernel\", 3))\n",
    "        tcn_dropout = float(_cfg.get(\"tcn_dropout\", dropout))\n",
    "        tcn_causal = bool(_cfg.get(\"tcn_causal\", True))\n",
    "        tcn_pool = str(_cfg.get(\"tcn_pool\", \"last\"))\n",
    "\n",
    "        self.tcn_pool = tcn_pool\n",
    "\n",
    "        # --- spatial stack\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(int(gnn_layers)):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(\n",
    "                SpatialGraphAttentionMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, heads=gat_heads, dropout=dropout)\n",
    "            )\n",
    "\n",
    "        # --- temporal TCN\n",
    "        self.tcn_in = nn.Linear(hidden, tcn_channels)\n",
    "        self.tcn = TemporalConvNet(\n",
    "            in_ch=tcn_channels,\n",
    "            channels=[tcn_channels] * tcn_layers_n,\n",
    "            kernel_size=tcn_kernel,\n",
    "            dropout=tcn_dropout,\n",
    "            causal=tcn_causal,\n",
    "        )\n",
    "\n",
    "        # --- head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(tcn_channels),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(tcn_channels, tcn_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(tcn_channels, n_classes),\n",
    "        )\n",
    "\n",
    "        # init linears\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        e = torch.nan_to_num(e, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        h_tgt = torch.nan_to_num(h_tgt, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        z = self.tcn_in(h_tgt)          # (B,L,C)\n",
    "        z = torch.nan_to_num(z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        z = z.transpose(1, 2)           # (B,C,L)\n",
    "\n",
    "        y = self.tcn(z)                 # (B,C,L)\n",
    "\n",
    "        if self.tcn_pool == \"mean\":\n",
    "            emb = y.mean(dim=-1)        # (B,C)\n",
    "        else:\n",
    "            emb = y[:, :, -1]           # (B,C) safe for causal\n",
    "\n",
    "        logits = self.head(emb)         # (B,2)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "# ---- quick sanity check (shape + no NaNs)\n",
    "B, L, N, Fdim = 4, CFG[\"lookback\"], 3, X_node_raw.shape[-1]\n",
    "E = EDGE_INDEX.shape[0]\n",
    "W = edge_feat.shape[-1]\n",
    "\n",
    "x_dummy = torch.randn(B, L, N, Fdim)\n",
    "e_dummy = torch.randn(B, L, E, W)\n",
    "\n",
    "m = GNN_LSTM_Classifier(\n",
    "    node_in=Fdim,\n",
    "    edge_dim=W,\n",
    "    hidden=CFG[\"hidden\"],\n",
    "    gnn_layers=CFG[\"gnn_layers\"],\n",
    "    lstm_hidden=CFG[\"lstm_hidden\"],   # ignored (compat)\n",
    "    lstm_layers=CFG[\"lstm_layers\"],   # ignored (compat)\n",
    "    dropout=CFG[\"dropout\"],\n",
    "    target_node=TARGET_NODE,\n",
    "    n_classes=2\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = m(x_dummy, e_dummy, EDGE_INDEX)\n",
    "print(\"Model ready. logits:\", out.shape, \"finite:\", torch.isfinite(out).all().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn, y_key: str = \"trade\"):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        y = (y_trade_b if y_key == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "\n",
    "    ys = np.concatenate(ys) if len(ys) else np.array([], dtype=np.int64)\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, None, ys, probs, ers\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:, 1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss / max(n, 1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_only(model, loader):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "    return probs, ers\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps, min_trades: int = 0):\n",
    "    \"\"\"\n",
    "    Возвращает лучший pnl_mean по grid (per-bar), плюс пороги и статистику.\n",
    "    min_trades используется как фильтр: комбинации, где сделок меньше, пропускаются.\n",
    "    Если ни одна комбинация не прошла min_trades — вернём best без фильтра (но это будет fallback-сценарий).\n",
    "    \"\"\"\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    sign = np.where(p_up >= 0.5, 1.0, -1.0).astype(np.float32)\n",
    "    cost = float(cost_bps) * 1e-4\n",
    "    N = len(exit_ret)\n",
    "\n",
    "    best = {\n",
    "        \"pnl_mean\": -1e18,\n",
    "        \"pnl_sum\": -1e18,\n",
    "        \"thr_trade\": None,\n",
    "        \"thr_dir\": None,\n",
    "        \"n_trades\": 0,\n",
    "        \"trade_rate\": 0.0,\n",
    "        \"min_trades_used\": int(min_trades),\n",
    "        \"passed_min_trades\": False,\n",
    "    }\n",
    "\n",
    "    # 1) строгий проход (>=min_trades)\n",
    "    for thr_t in thr_trade_grid:\n",
    "        mt = (p_trade >= thr_t)\n",
    "        for thr_d in thr_dir_grid:\n",
    "            mask = mt & (conf_dir >= thr_d)\n",
    "            n_tr = int(mask.sum())\n",
    "            if n_tr < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "            pnl_sum = float(pnl.sum())\n",
    "            pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "            if pnl_mean > best[\"pnl_mean\"]:\n",
    "                best.update({\n",
    "                    \"pnl_mean\": pnl_mean,\n",
    "                    \"pnl_sum\": pnl_sum,\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": n_tr,\n",
    "                    \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                    \"passed_min_trades\": True,\n",
    "                })\n",
    "\n",
    "    # 2) если ничего не прошло min_trades — найдём best без фильтра (для fallback-логов)\n",
    "    if best[\"thr_trade\"] is None:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            mt = (p_trade >= thr_t)\n",
    "            for thr_d in thr_dir_grid:\n",
    "                mask = mt & (conf_dir >= thr_d)\n",
    "                n_tr = int(mask.sum())\n",
    "                pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "                pnl_sum = float(pnl.sum())\n",
    "                pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "                if pnl_mean > best[\"pnl_mean\"]:\n",
    "                    best.update({\n",
    "                        \"pnl_mean\": pnl_mean,\n",
    "                        \"pnl_sum\": pnl_sum,\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": n_tr,\n",
    "                        \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def _make_ce_weights_binary(y_np: np.ndarray) -> torch.Tensor:\n",
    "    y_np = np.asarray(y_np, dtype=np.int64)\n",
    "    counts = np.bincount(y_np, minlength=2).astype(np.float64)\n",
    "    counts = np.maximum(counts, 1.0)\n",
    "    w = counts.sum() / (2.0 * counts)  # inverse freq\n",
    "    return torch.tensor(w, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "    select_metric: str | None = None,        # \"va_auc\" | \"va_f1m\" | \"va_pnl_max\"\n",
    "    trade_model_for_pnl=None,\n",
    "    idx_val_pnl=None,\n",
    "):\n",
    "    if select_metric is None:\n",
    "        select_metric = \"va_auc\"\n",
    "    if select_metric not in (\"va_auc\", \"va_f1m\", \"va_pnl_max\"):\n",
    "        raise ValueError(\"select_metric must be one of: 'va_auc', 'va_f1m', 'va_pnl_max'\")\n",
    "\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if stage_name != \"dir\":\n",
    "            raise ValueError(\"select_metric='va_pnl_max' supported only for stage_name='dir'\")\n",
    "        if trade_model_for_pnl is None or idx_val_pnl is None:\n",
    "            raise ValueError(\"For va_pnl_max you must pass trade_model_for_pnl and idx_val_pnl.\")\n",
    "\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val,   L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test,  L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True,  drop_last=False, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    va_pnl_loader = None\n",
    "    if stage_name == \"dir\" and (idx_val_pnl is not None):\n",
    "        va_pnl_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val_pnl, L)\n",
    "        va_pnl_loader = DataLoader(va_pnl_ds, batch_size=cfg[\"batch_size\"], shuffle=False, drop_last=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # --- class weights (делает обучение стабильнее на фолдах)\n",
    "    t_train = sample_t[idx_train]\n",
    "    y_train_np = (y_trade_arr[t_train] if stage_name == \"trade\" else y_dir_arr[t_train]).astype(np.int64)\n",
    "    ce_w = _make_ce_weights_binary(y_train_np)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=ce_w)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\"))\n",
    "\n",
    "    # --- trade probs на полном val для PnL proxy (считаем 1 раз)\n",
    "    prob_trade_val_pnl = None\n",
    "    if stage_name == \"dir\" and (trade_model_for_pnl is not None) and (va_pnl_loader is not None):\n",
    "        prob_trade_val_pnl, _ = predict_probs_only(trade_model_for_pnl, va_pnl_loader)\n",
    "        debug_trade_prob_stats(prob_trade_val_pnl, title=\"val_pnl (for dir selector)\")\n",
    "\n",
    "    # --- proxy grids (ВАЖНО: делаем thr_trade_grid динамической!)\n",
    "    proxy_min_trades = int(cfg.get(\"proxy_min_trades\", 0))\n",
    "    objective = str(cfg.get(\"pnl_objective\", \"pnl_sum\"))\n",
    "    thr_dir_grid_proxy = cfg.get(\"thr_dir_grid\", [0.5])\n",
    "\n",
    "    if (stage_name == \"dir\") and (prob_trade_val_pnl is not None):\n",
    "        thr_trade_grid_proxy = build_trade_threshold_grid(\n",
    "            p_trade=prob_trade_val_pnl[:, 1],\n",
    "            base_grid=cfg.get(\"thr_trade_grid\", [0.5]),\n",
    "            target_trades_list=cfg.get(\"proxy_target_trades\", [proxy_min_trades]),\n",
    "            min_thr=0.01, max_thr=0.99\n",
    "        )\n",
    "    else:\n",
    "        thr_trade_grid_proxy = cfg.get(\"thr_trade_grid\", [0.5])\n",
    "\n",
    "    best_score = -1e18\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "    best_used = select_metric\n",
    "\n",
    "    best_score_auc = -1e18\n",
    "    best_state_auc = None\n",
    "    best_epoch_auc = -1\n",
    "\n",
    "    best_score_pnl = -1e18\n",
    "    best_state_pnl = None\n",
    "    best_epoch_pnl = -1\n",
    "    seen_pnl_ok = False\n",
    "\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\"tr_loss\": [], \"va_loss\": [], \"va_f1m\": [], \"va_auc\": [],\n",
    "            \"va_pnl_obj\": [], \"va_pnl_n_trades\": [], \"va_sel\": [], \"va_sel_mode\": []}\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"] + 1):\n",
    "        # ---- TRAIN\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for x, e, y_trade_b, y_dir_b, er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            y = (y_trade_b if stage_name == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot / max(n, 1)\n",
    "\n",
    "        # ---- VAL metrics\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, va_loader, loss_fn, y_key=stage_name\n",
    "        )\n",
    "\n",
    "        # ---- VAL PnL proxy (dir only)\n",
    "        va_pnl_best = {\"thr_trade\": np.nan, \"thr_dir\": np.nan, \"n_trades\": 0, \"trade_rate\": np.nan,\n",
    "                       \"pnl_sum\": np.nan, \"pnl_mean\": np.nan, \"pnl_per_trade\": np.nan,\n",
    "                       \"passed_min_trades\": False, \"min_trades_used\": proxy_min_trades}\n",
    "\n",
    "        if stage_name == \"dir\" and (prob_trade_val_pnl is not None) and (va_pnl_loader is not None):\n",
    "            prob_dir_val_pnl, er_dir_val_pnl = predict_probs_only(model, va_pnl_loader)\n",
    "\n",
    "            va_pnl_best = pnl_proxy_grid_max(\n",
    "                prob_trade=prob_trade_val_pnl,\n",
    "                prob_dir=prob_dir_val_pnl,\n",
    "                exit_ret=er_dir_val_pnl,\n",
    "                thr_trade_grid=thr_trade_grid_proxy,\n",
    "                thr_dir_grid=thr_dir_grid_proxy,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "                min_trades=proxy_min_trades,\n",
    "                objective=objective,\n",
    "            )\n",
    "\n",
    "        # ---- selection\n",
    "        sel_val = np.nan\n",
    "        sel_mode = select_metric\n",
    "\n",
    "        if select_metric in (\"va_auc\", \"va_f1m\"):\n",
    "            sel_val = (va_auc if select_metric == \"va_auc\" else va_f1m)\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "\n",
    "            if sel_val > best_score:\n",
    "                best_score = float(sel_val)\n",
    "                best_epoch = ep\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "        else:\n",
    "            # va_pnl_max with fallback\n",
    "            pnl_obj = float(va_pnl_best.get(objective, np.nan))\n",
    "            n_tr = int(va_pnl_best.get(\"n_trades\", 0))\n",
    "            pnl_ok = (np.isfinite(pnl_obj) and (n_tr >= proxy_min_trades))\n",
    "\n",
    "            # обновим best_auc\n",
    "            if np.isfinite(va_auc) and (float(va_auc) > best_score_auc):\n",
    "                best_score_auc = float(va_auc)\n",
    "                best_epoch_auc = ep\n",
    "                best_state_auc = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            # обновим best_pnl только если pnl_ok\n",
    "            if pnl_ok and (pnl_obj > best_score_pnl):\n",
    "                best_score_pnl = pnl_obj\n",
    "                best_epoch_pnl = ep\n",
    "                best_state_pnl = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            if pnl_ok:\n",
    "                seen_pnl_ok = True\n",
    "                sel_val = pnl_obj\n",
    "                sel_mode = f\"va_pnl_max({objective})\"\n",
    "            else:\n",
    "                sel_val = float(va_auc) if np.isfinite(va_auc) else -1e18\n",
    "                sel_mode = f\"va_auc_fallback({n_tr}/{proxy_min_trades})\"\n",
    "\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "            improved = False\n",
    "            if not seen_pnl_ok:\n",
    "                improved = (np.isfinite(va_auc) and (float(va_auc) >= best_score_auc))\n",
    "            else:\n",
    "                improved = pnl_ok and (pnl_obj >= best_score_pnl)\n",
    "\n",
    "            bad = 0 if improved else (bad + 1)\n",
    "\n",
    "        # ---- logs\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "        hist[\"va_pnl_obj\"].append(float(va_pnl_best.get(objective, np.nan)))\n",
    "        hist[\"va_pnl_n_trades\"].append(int(va_pnl_best.get(\"n_trades\", 0)))\n",
    "        hist[\"va_sel\"].append(float(sel_val) if np.isfinite(sel_val) else np.nan)\n",
    "        hist[\"va_sel_mode\"].append(sel_mode)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "\n",
    "        if stage_name == \"dir\":\n",
    "            best_str = (f\"pnl={best_score_pnl:.6f}@ep{best_epoch_pnl:02d}\" if best_state_pnl is not None\n",
    "                        else f\"auc={best_score_auc:.6f}@ep{best_epoch_auc:02d}\")\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"{objective}={va_pnl_best.get(objective, np.nan):.6f} \"\n",
    "                f\"thr=({va_pnl_best.get('thr_trade', np.nan):.2f},{va_pnl_best.get('thr_dir', np.nan):.2f}) \"\n",
    "                f\"trades={va_pnl_best.get('n_trades', 0)} \"\n",
    "                f\"sel({sel_mode})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "        else:\n",
    "            best_str = f\"{best_score:.6f}@ep{best_epoch:02d}\" if best_epoch > 0 else \"none\"\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"sel({select_metric})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "\n",
    "        if bad >= patience:\n",
    "            break\n",
    "\n",
    "    # ---- choose final best state\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if best_state_pnl is not None:\n",
    "            model.load_state_dict(best_state_pnl)\n",
    "            best_score = best_score_pnl\n",
    "            best_epoch = best_epoch_pnl\n",
    "            best_used = f\"va_pnl_max({objective})\"\n",
    "        else:\n",
    "            model.load_state_dict(best_state_auc)\n",
    "            best_score = best_score_auc\n",
    "            best_epoch = best_epoch_auc\n",
    "            best_used = \"va_auc_fallback_only\"\n",
    "    else:\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "            best_used = select_metric\n",
    "\n",
    "    # финальные VAL/TEST\n",
    "    va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(model, va_loader, loss_fn, y_key=stage_name)\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(model, te_loader, loss_fn, y_key=stage_name)\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": float(best_score),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"select_metric\": select_metric,\n",
    "        \"best_used\": best_used,\n",
    "\n",
    "        \"val_loss\": va_loss, \"val_acc\": va_acc, \"val_f1m\": va_f1m, \"val_auc\": va_auc, \"val_cm\": va_cm,\n",
    "        \"val_y\": va_y, \"val_prob\": va_prob, \"val_er\": va_er,\n",
    "\n",
    "        \"test_loss\": te_loss, \"test_acc\": te_acc, \"test_f1m\": te_f1m, \"test_auc\": te_auc, \"test_cm\": te_cm,\n",
    "        \"test_y\": te_y, \"test_prob\": te_prob, \"test_er\": te_er,\n",
    "\n",
    "        \"hist\": hist,\n",
    "    }\n",
    "    return model, res\n",
    "✅ Блок 3: правка блока “Run folds” (чтобы sweep на TEST не выбирал 0 сделок)\n",
    "Меняем только место, где делается sweep = sweep_thresholds(...).\n",
    "\n",
    "python\n",
    "Копировать код\n",
    "# ЛОГИЧЕСКИЙ БЛОК: fold-test sweep with min_trades constraint\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "# ... внутри твоего for fi, (...) in enumerate(walk_splits, 1): после получения prob_trade_te/prob_dir_te ...\n",
    "\n",
    "objective = CFG.get(\"pnl_objective\", \"pnl_sum\")\n",
    "min_tr_eval = int(CFG.get(\"eval_min_trades\", 0))\n",
    "\n",
    "sweep = sweep_thresholds(\n",
    "    prob_trade_te, prob_dir_te, er_te,\n",
    "    CFG,\n",
    "    min_trades=min_tr_eval,\n",
    "    objective=objective\n",
    ")\n",
    "best = sweep.iloc[0].to_dict()\n",
    "\n",
    "print(\"PnL on fold-test:\",\n",
    "      \"| thr_trade=\", best[\"thr_trade\"],\n",
    "      \"| thr_dir=\", best[\"thr_dir\"],\n",
    "      f\"| {objective}=\", best[objective],\n",
    "      \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "      \"| trades=\", best[\"n_trades\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Better threshold sweep (dynamic thr_trade + min_trades constraint)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "def build_trade_threshold_grid(\n",
    "    p_trade: np.ndarray,\n",
    "    base_grid: list[float] | None = None,\n",
    "    target_trades_list: list[int] | None = None,\n",
    "    min_thr: float = 0.01,\n",
    "    max_thr: float = 0.99,\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Делает пороги thr_trade не только фиксированные, но и \"по квантилям\",\n",
    "    чтобы можно было получать заданное число сделок даже при некалиброванных вероятностях.\n",
    "\n",
    "    target_trades_list: список желаемых n_trades (например [20,40,80])\n",
    "    Возвращает список порогов.\n",
    "    \"\"\"\n",
    "    p_trade = np.asarray(p_trade, dtype=np.float64)\n",
    "    p_trade = p_trade[np.isfinite(p_trade)]\n",
    "    if p_trade.size == 0:\n",
    "        return base_grid or [0.5]\n",
    "\n",
    "    thrs = set()\n",
    "    if base_grid:\n",
    "        for t in base_grid:\n",
    "            thrs.add(float(t))\n",
    "\n",
    "    if target_trades_list:\n",
    "        N = p_trade.size\n",
    "        # порог = значение, которое оставляет примерно k наблюдений сверху\n",
    "        for k in target_trades_list:\n",
    "            k = int(k)\n",
    "            if k <= 0:\n",
    "                continue\n",
    "            if k >= N:\n",
    "                thr = float(np.min(p_trade))  # чтобы взять всё\n",
    "            else:\n",
    "                # k сверху => квантиль 1 - k/N\n",
    "                q = 1.0 - (k / N)\n",
    "                thr = float(np.quantile(p_trade, q))\n",
    "            thr = float(np.clip(thr, min_thr, max_thr))\n",
    "            thrs.add(thr)\n",
    "\n",
    "    thrs = sorted(thrs)\n",
    "    # небольшая чистка дублей/почти-дублей\n",
    "    out = []\n",
    "    for t in thrs:\n",
    "        if not out or abs(t - out[-1]) > 1e-6:\n",
    "            out.append(float(t))\n",
    "    return out\n",
    "\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade, prob_dir, exit_ret,\n",
    "    thr_trade: float, thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    conf_dir = np.maximum(p_up, 1.0 - p_up)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (float(cost_bps) * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    n_tr = int(trade_mask.sum())\n",
    "    out = {\n",
    "        \"n\": int(len(exit_ret)),\n",
    "        \"n_trades\": n_tr,\n",
    "        \"trade_rate\": float(n_tr / max(1, len(exit_ret))),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()) if len(exit_ret) else np.nan,\n",
    "        \"pnl_per_trade\": float(pnl.sum() / max(1, n_tr)),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)) if len(exit_ret) else np.nan,\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg, min_trades: int = 0, objective: str = \"pnl_sum\"):\n",
    "    \"\"\"\n",
    "    Ищет лучшие (thr_trade, thr_dir) на сетке.\n",
    "    ВАЖНО: добавили min_trades (иначе часто \"лучше всего\" 0 сделок => pnl=0).\n",
    "    \"\"\"\n",
    "    if objective not in (\"pnl_sum\", \"pnl_mean\", \"pnl_per_trade\"):\n",
    "        raise ValueError(\"objective must be one of: pnl_sum, pnl_mean, pnl_per_trade\")\n",
    "\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    thr_trade_grid = build_trade_threshold_grid(\n",
    "        p_trade=p_trade,\n",
    "        base_grid=cfg.get(\"thr_trade_grid\", [0.5]),\n",
    "        target_trades_list=cfg.get(\"proxy_target_trades\", None),\n",
    "        min_thr=0.01,\n",
    "        max_thr=0.99,\n",
    "    )\n",
    "    thr_dir_grid = cfg.get(\"thr_dir_grid\", [0.5])\n",
    "\n",
    "    rows = []\n",
    "    for thr_t in thr_trade_grid:\n",
    "        for thr_d in thr_dir_grid:\n",
    "            m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cfg[\"cost_bps\"])\n",
    "            if int(m[\"n_trades\"]) < int(min_trades):\n",
    "                continue\n",
    "            rows.append({\"thr_trade\": float(thr_t), \"thr_dir\": float(thr_d), **m})\n",
    "\n",
    "    # fallback: если min_trades слишком строгий, ослабим до \"хотя бы 1 сделка\"\n",
    "    if not rows and min_trades > 0:\n",
    "        return sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg, min_trades=1, objective=objective)\n",
    "\n",
    "    # последний fallback: разрешим 0 сделок (на случай реально мёртвого сигнала)\n",
    "    if not rows:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            for thr_d in thr_dir_grid:\n",
    "                m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cfg[\"cost_bps\"])\n",
    "                rows.append({\"thr_trade\": float(thr_t), \"thr_dir\": float(thr_d), **m})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values([objective, \"pnl_sum\"], ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps,\n",
    "                       min_trades: int = 0, objective: str = \"pnl_sum\"):\n",
    "    \"\"\"\n",
    "    Упрощённая версия для train_binary_classifier (быстрое max по сетке).\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for thr_t in thr_trade_grid:\n",
    "        for thr_d in thr_dir_grid:\n",
    "            m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cost_bps)\n",
    "            if int(m[\"n_trades\"]) < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            score = float(m[objective])\n",
    "            if (best is None) or (score > best[\"_score\"]):\n",
    "                best = {\n",
    "                    \"_score\": score,\n",
    "                    \"pnl_sum\": m[\"pnl_sum\"],\n",
    "                    \"pnl_mean\": m[\"pnl_mean\"],\n",
    "                    \"pnl_per_trade\": m[\"pnl_per_trade\"],\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": int(m[\"n_trades\"]),\n",
    "                    \"trade_rate\": float(m[\"trade_rate\"]),\n",
    "                    \"passed_min_trades\": True,\n",
    "                    \"min_trades_used\": int(min_trades),\n",
    "                }\n",
    "\n",
    "    # fallback: если ничего не прошло min_trades — попробуем хотя бы 1 сделку\n",
    "    if best is None and min_trades > 0:\n",
    "        return pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps,\n",
    "                                  min_trades=1, objective=objective)\n",
    "\n",
    "    # последний fallback: разрешим 0 сделок\n",
    "    if best is None:\n",
    "        best = {\n",
    "            \"_score\": -1e18,\n",
    "            \"pnl_sum\": -1e18,\n",
    "            \"pnl_mean\": -1e18,\n",
    "            \"pnl_per_trade\": -1e18,\n",
    "            \"thr_trade\": float(thr_trade_grid[0]) if len(thr_trade_grid) else 0.5,\n",
    "            \"thr_dir\": float(thr_dir_grid[0]) if len(thr_dir_grid) else 0.5,\n",
    "            \"n_trades\": 0,\n",
    "            \"trade_rate\": 0.0,\n",
    "            \"passed_min_trades\": False,\n",
    "            \"min_trades_used\": int(min_trades),\n",
    "        }\n",
    "        # найдём реальный best без ограничений (даже 0 сделок)\n",
    "        for thr_t in thr_trade_grid:\n",
    "            for thr_d in thr_dir_grid:\n",
    "                m = two_stage_pnl_by_threshold(prob_trade, prob_dir, exit_ret, thr_t, thr_d, cost_bps)\n",
    "                score = float(m[objective])\n",
    "                if score > best[\"_score\"]:\n",
    "                    best.update({\n",
    "                        \"_score\": score,\n",
    "                        \"pnl_sum\": m[\"pnl_sum\"],\n",
    "                        \"pnl_mean\": m[\"pnl_mean\"],\n",
    "                        \"pnl_per_trade\": m[\"pnl_per_trade\"],\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": int(m[\"n_trades\"]),\n",
    "                        \"trade_rate\": float(m[\"trade_rate\"]),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "    best.pop(\"_score\", None)\n",
    "    return best\n",
    "\n",
    "\n",
    "def debug_trade_prob_stats(prob_trade: np.ndarray, title: str = \"\"):\n",
    "    p = prob_trade[:, 1]\n",
    "    qs = [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]\n",
    "    vals = np.quantile(p, qs)\n",
    "    msg = \" | \".join([f\"q{int(q*100):02d}={v:.3f}\" for q, v in zip(qs, vals)])\n",
    "    print(f\"[trade prob stats]{(' ' + title) if title else ''}: {msg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5c430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: shared helper for probs on arbitrary indices\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_on_indices(model, X_scaled, edge_feat, indices, cfg):\n",
    "    ds = LobGraphSequenceDataset2Stage(\n",
    "        X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, cfg[\"lookback\"]\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, yt, yd, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(probs), np.concatenate(ers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1168 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7723 va_loss=0.7036 f1m=0.427 auc=0.529 sel(va_auc)=0.529138 best=0.529138@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7415 va_loss=0.6689 f1m=0.474 auc=0.549 sel(va_auc)=0.549029 best=0.549029@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7307 va_loss=0.6705 f1m=0.440 auc=0.541 sel(va_auc)=0.540793 best=0.549029@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7287 va_loss=0.6700 f1m=0.431 auc=0.546 sel(va_auc)=0.545998 best=0.549029@ep02\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7134 va_loss=0.6716 f1m=0.392 auc=0.548 sel(va_auc)=0.547708 best=0.549029@ep02\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6897 va_loss=0.6649 f1m=0.404 auc=0.541 sel(va_auc)=0.541336 best=0.549029@ep02\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.7098 va_loss=0.6672 f1m=0.380 auc=0.550 sel(va_auc)=0.550039 best=0.550039@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6902 va_loss=0.6639 f1m=0.380 auc=0.559 sel(va_auc)=0.559441 best=0.559441@ep08\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6865 va_loss=0.6639 f1m=0.380 auc=0.560 sel(va_auc)=0.560451 best=0.560451@ep09\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6878 va_loss=0.6646 f1m=0.380 auc=0.560 sel(va_auc)=0.560373 best=0.560451@ep09\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.6868 va_loss=0.6664 f1m=0.380 auc=0.569 sel(va_auc)=0.568765 best=0.568765@ep11\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.6913 va_loss=0.6667 f1m=0.380 auc=0.572 sel(va_auc)=0.571950 best=0.571950@ep12\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.6724 va_loss=0.6653 f1m=0.380 auc=0.557 sel(va_auc)=0.557420 best=0.571950@ep12\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.6713 va_loss=0.6661 f1m=0.380 auc=0.548 sel(va_auc)=0.547863 best=0.571950@ep12\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.6760 va_loss=0.6681 f1m=0.380 auc=0.535 sel(va_auc)=0.535354 best=0.571950@ep12\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.6863 va_loss=0.6674 f1m=0.380 auc=0.544 sel(va_auc)=0.543667 best=0.571950@ep12\n",
      "[trade] ep 17 lr=1.00e-04 tr_loss=0.6752 va_loss=0.6647 f1m=0.380 auc=0.556 sel(va_auc)=0.555711 best=0.571950@ep12\n",
      "[trade] ep 18 lr=1.00e-04 tr_loss=0.6815 va_loss=0.6644 f1m=0.380 auc=0.551 sel(va_auc)=0.551282 best=0.571950@ep12\n",
      "[trade] ep 19 lr=1.00e-04 tr_loss=0.6759 va_loss=0.6641 f1m=0.380 auc=0.558 sel(va_auc)=0.558120 best=0.571950@ep12\n",
      "[trade] ep 20 lr=1.00e-04 tr_loss=0.6740 va_loss=0.6649 f1m=0.380 auc=0.555 sel(va_auc)=0.555167 best=0.571950@ep12\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9608 va_loss=0.7205 f1m=0.495 auc=0.526 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.526500 best=auc=0.526500@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8934 va_loss=0.7268 f1m=0.533 auc=0.526 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.526000 best=auc=0.526500@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.8568 va_loss=0.7253 f1m=0.549 auc=0.531 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.531000 best=auc=0.531000@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.8363 va_loss=0.7126 f1m=0.475 auc=0.518 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.518500 best=auc=0.531000@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.8399 va_loss=0.7173 f1m=0.439 auc=0.495 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.494500 best=auc=0.531000@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.8115 va_loss=0.7144 f1m=0.433 auc=0.488 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.488000 best=auc=0.531000@ep03\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.7995 va_loss=0.7108 f1m=0.467 auc=0.484 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.484000 best=auc=0.531000@ep03\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7789 va_loss=0.7128 f1m=0.481 auc=0.483 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.483500 best=auc=0.531000@ep03\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7818 va_loss=0.7115 f1m=0.474 auc=0.480 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.480000 best=auc=0.531000@ep03\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.7761 va_loss=0.7080 f1m=0.459 auc=0.480 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.480500 best=auc=0.531000@ep03\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.7960 va_loss=0.7041 f1m=0.430 auc=0.484 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/20))=0.484000 best=auc=0.531000@ep03\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0 | trades= 0.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1401 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.9046 va_loss=0.6084 f1m=0.449 auc=0.509 sel(va_auc)=0.508571 best=0.508571@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.8093 va_loss=0.6005 f1m=0.425 auc=0.511 sel(va_auc)=0.511232 best=0.511232@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7612 va_loss=0.6032 f1m=0.440 auc=0.508 sel(va_auc)=0.508473 best=0.511232@ep02\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7519 va_loss=0.6436 f1m=0.480 auc=0.491 sel(va_auc)=0.491232 best=0.511232@ep02\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7077 va_loss=0.6317 f1m=0.432 auc=0.476 sel(va_auc)=0.475567 best=0.511232@ep02\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.7053 va_loss=0.6232 f1m=0.416 auc=0.461 sel(va_auc)=0.461281 best=0.511232@ep02\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.7004 va_loss=0.6078 f1m=0.426 auc=0.454 sel(va_auc)=0.453793 best=0.511232@ep02\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.7035 va_loss=0.6206 f1m=0.423 auc=0.453 sel(va_auc)=0.453005 best=0.511232@ep02\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.7073 va_loss=0.6248 f1m=0.423 auc=0.453 sel(va_auc)=0.453399 best=0.511232@ep02\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.7030 va_loss=0.6175 f1m=0.426 auc=0.447 sel(va_auc)=0.447488 best=0.511232@ep02\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9432 va_loss=0.8524 f1m=0.367 auc=0.499 pnl_max=0.000037 thr=(0.60,0.50) trades=6 sel(va_auc_fallback(6/20))=0.498866 best=auc=0.498866@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.9290 va_loss=1.0090 f1m=0.241 auc=0.478 pnl_max=0.000005 thr=(0.60,0.60) trades=4 sel(va_auc_fallback(4/20))=0.478458 best=auc=0.498866@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.8909 va_loss=0.9983 f1m=0.224 auc=0.481 pnl_max=0.000005 thr=(0.60,0.65) trades=4 sel(va_auc_fallback(4/20))=0.480726 best=auc=0.498866@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.8752 va_loss=0.9204 f1m=0.276 auc=0.499 pnl_max=0.000005 thr=(0.60,0.60) trades=4 sel(va_auc_fallback(4/20))=0.498866 best=auc=0.498866@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.8591 va_loss=0.8847 f1m=0.258 auc=0.517 pnl_max=0.000005 thr=(0.60,0.60) trades=4 sel(va_auc_fallback(4/20))=0.517007 best=auc=0.517007@ep05\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.8157 va_loss=0.8690 f1m=0.258 auc=0.515 pnl_max=0.000007 thr=(0.55,0.70) trades=2 sel(va_auc_fallback(2/20))=0.514739 best=auc=0.517007@ep05\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.7947 va_loss=0.8172 f1m=0.307 auc=0.499 pnl_max=0.000007 thr=(0.55,0.70) trades=2 sel(va_auc_fallback(2/20))=0.498866 best=auc=0.517007@ep05\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.8026 va_loss=0.8299 f1m=0.275 auc=0.517 pnl_max=0.000005 thr=(0.55,0.65) trades=4 sel(va_auc_fallback(4/20))=0.517007 best=auc=0.517007@ep05\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.7734 va_loss=0.8384 f1m=0.276 auc=0.512 pnl_max=0.000005 thr=(0.55,0.65) trades=4 sel(va_auc_fallback(4/20))=0.512472 best=auc=0.517007@ep05\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.8078 va_loss=0.8448 f1m=0.258 auc=0.526 pnl_max=0.000005 thr=(0.55,0.65) trades=4 sel(va_auc_fallback(4/20))=0.526077 best=auc=0.526077@ep10\n",
      "[dir] ep 11 lr=2.00e-04 tr_loss=0.7665 va_loss=0.8458 f1m=0.258 auc=0.510 pnl_max=0.000005 thr=(0.60,0.60) trades=4 sel(va_auc_fallback(4/20))=0.510204 best=auc=0.526077@ep10\n",
      "[dir] ep 12 lr=2.00e-04 tr_loss=0.7643 va_loss=0.8609 f1m=0.240 auc=0.483 pnl_max=0.000005 thr=(0.60,0.60) trades=4 sel(va_auc_fallback(4/20))=0.482993 best=auc=0.526077@ep10\n",
      "[dir] ep 13 lr=2.00e-04 tr_loss=0.7791 va_loss=0.8365 f1m=0.238 auc=0.494 pnl_max=0.000005 thr=(0.60,0.60) trades=4 sel(va_auc_fallback(4/20))=0.494331 best=auc=0.526077@ep10\n",
      "[dir] ep 14 lr=2.00e-04 tr_loss=0.7268 va_loss=0.8144 f1m=0.240 auc=0.488 pnl_max=0.000005 thr=(0.55,0.60) trades=4 sel(va_auc_fallback(4/20))=0.487528 best=auc=0.526077@ep10\n",
      "[dir] ep 15 lr=1.00e-04 tr_loss=0.7145 va_loss=0.8173 f1m=0.240 auc=0.494 pnl_max=0.000000 thr=(0.55,0.70) trades=0 sel(va_auc_fallback(0/20))=0.494331 best=auc=0.526077@ep10\n",
      "[dir] ep 16 lr=1.00e-04 tr_loss=0.7180 va_loss=0.8167 f1m=0.222 auc=0.508 pnl_max=0.000000 thr=(0.55,0.70) trades=0 sel(va_auc_fallback(0/20))=0.507937 best=auc=0.526077@ep10\n",
      "[dir] ep 17 lr=1.00e-04 tr_loss=0.7332 va_loss=0.8160 f1m=0.222 auc=0.503 pnl_max=0.000000 thr=(0.55,0.70) trades=0 sel(va_auc_fallback(0/20))=0.503401 best=auc=0.526077@ep10\n",
      "[dir] ep 18 lr=1.00e-04 tr_loss=0.7196 va_loss=0.8267 f1m=0.184 auc=0.499 pnl_max=0.000000 thr=(0.55,0.70) trades=0 sel(va_auc_fallback(0/20))=0.498866 best=auc=0.526077@ep10\n",
      "PnL on fold-test: | thr_trade= 0.55 | thr_dir= 0.6 | pnl_mean= 5.4612009989796206e-05 | trades= 3.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 1634 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8003 va_loss=0.9380 f1m=0.341 auc=0.528 sel(va_auc)=0.528169 best=0.528169@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7586 va_loss=0.9059 f1m=0.302 auc=0.534 sel(va_auc)=0.534081 best=0.534081@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7660 va_loss=0.8371 f1m=0.317 auc=0.550 sel(va_auc)=0.549904 best=0.549904@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7119 va_loss=0.8140 f1m=0.318 auc=0.535 sel(va_auc)=0.534864 best=0.549904@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7309 va_loss=0.7887 f1m=0.315 auc=0.511 sel(va_auc)=0.510607 best=0.549904@ep03\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.7017 va_loss=0.8225 f1m=0.290 auc=0.494 sel(va_auc)=0.494349 best=0.549904@ep03\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6913 va_loss=0.8459 f1m=0.240 auc=0.495 sel(va_auc)=0.494610 best=0.549904@ep03\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6980 va_loss=0.8368 f1m=0.234 auc=0.500 sel(va_auc)=0.500087 best=0.549904@ep03\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6932 va_loss=0.8306 f1m=0.234 auc=0.500 sel(va_auc)=0.499652 best=0.549904@ep03\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.6882 va_loss=0.8399 f1m=0.234 auc=0.496 sel(va_auc)=0.495827 best=0.549904@ep03\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.6788 va_loss=0.8604 f1m=0.234 auc=0.473 sel(va_auc)=0.473048 best=0.549904@ep03\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9036 va_loss=0.7629 f1m=0.457 auc=0.457 pnl_max=-0.000330 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000330 best=pnl=-0.000330@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8155 va_loss=0.7480 f1m=0.479 auc=0.471 pnl_max=-0.000320 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000320 best=pnl=-0.000320@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.8312 va_loss=0.7166 f1m=0.455 auc=0.475 pnl_max=-0.000202 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000202 best=pnl=-0.000202@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7803 va_loss=0.7058 f1m=0.471 auc=0.478 pnl_max=-0.000202 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000202 best=pnl=-0.000202@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7742 va_loss=0.7015 f1m=0.436 auc=0.470 pnl_max=-0.000074 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000074 best=pnl=-0.000074@ep05\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7457 va_loss=0.7024 f1m=0.495 auc=0.472 pnl_max=-0.000140 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000140 best=pnl=-0.000074@ep05\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.7775 va_loss=0.7041 f1m=0.468 auc=0.470 pnl_max=-0.000224 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000224 best=pnl=-0.000074@ep05\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.7209 va_loss=0.6997 f1m=0.475 auc=0.475 pnl_max=-0.000225 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000225 best=pnl=-0.000074@ep05\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.7276 va_loss=0.6960 f1m=0.494 auc=0.478 pnl_max=-0.000208 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000208 best=pnl=-0.000074@ep05\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.7337 va_loss=0.7045 f1m=0.451 auc=0.482 pnl_max=-0.000286 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000286 best=pnl=-0.000074@ep05\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.7180 va_loss=0.7086 f1m=0.429 auc=0.485 pnl_max=-0.000175 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000175 best=pnl=-0.000074@ep05\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.7167 va_loss=0.7094 f1m=0.451 auc=0.488 pnl_max=-0.000175 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000175 best=pnl=-0.000074@ep05\n",
      "[dir] ep 13 lr=1.00e-04 tr_loss=0.7108 va_loss=0.7094 f1m=0.432 auc=0.490 pnl_max=-0.000175 thr=(0.50,0.50) trades=22 sel(va_pnl_max)=-0.000175 best=pnl=-0.000074@ep05\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.00012216348841320723 | trades= 21.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 1867 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8431 va_loss=1.0795 f1m=0.139 auc=0.397 sel(va_auc)=0.397233 best=0.397233@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7673 va_loss=0.9190 f1m=0.133 auc=0.435 sel(va_auc)=0.435012 best=0.435012@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7511 va_loss=0.8371 f1m=0.159 auc=0.478 sel(va_auc)=0.477767 best=0.477767@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7241 va_loss=0.8413 f1m=0.126 auc=0.470 sel(va_auc)=0.470149 best=0.477767@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7128 va_loss=0.8155 f1m=0.114 auc=0.506 sel(va_auc)=0.506374 best=0.506374@ep05\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.7078 va_loss=0.7676 f1m=0.170 auc=0.513 sel(va_auc)=0.513371 best=0.513371@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.7018 va_loss=0.8336 f1m=0.121 auc=0.519 sel(va_auc)=0.519279 best=0.519279@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.7028 va_loss=0.8079 f1m=0.121 auc=0.491 sel(va_auc)=0.491294 best=0.519279@ep07\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6949 va_loss=0.7685 f1m=0.154 auc=0.488 sel(va_auc)=0.488495 best=0.519279@ep07\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6788 va_loss=0.7935 f1m=0.137 auc=0.497 sel(va_auc)=0.497357 best=0.519279@ep07\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.6856 va_loss=0.7634 f1m=0.213 auc=0.526 sel(va_auc)=0.525808 best=0.525808@ep11\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.6888 va_loss=0.7730 f1m=0.197 auc=0.553 sel(va_auc)=0.552550 best=0.552550@ep12\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.6817 va_loss=0.7559 f1m=0.283 auc=0.566 sel(va_auc)=0.566076 best=0.566076@ep13\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.6646 va_loss=0.7102 f1m=0.438 auc=0.579 sel(va_auc)=0.579291 best=0.579291@ep14\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.6626 va_loss=0.6450 f1m=0.536 auc=0.620 sel(va_auc)=0.619869 best=0.619869@ep15\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.6569 va_loss=0.5673 f1m=0.496 auc=0.638 sel(va_auc)=0.638215 best=0.638215@ep16\n",
      "[trade] ep 17 lr=2.00e-04 tr_loss=0.6574 va_loss=0.5002 f1m=0.481 auc=0.650 sel(va_auc)=0.649876 best=0.649876@ep17\n",
      "[trade] ep 18 lr=2.00e-04 tr_loss=0.6614 va_loss=0.4693 f1m=0.455 auc=0.646 sel(va_auc)=0.645833 best=0.649876@ep17\n",
      "[trade] ep 19 lr=2.00e-04 tr_loss=0.6536 va_loss=0.4521 f1m=0.474 auc=0.645 sel(va_auc)=0.644900 best=0.649876@ep17\n",
      "[trade] ep 20 lr=2.00e-04 tr_loss=0.6407 va_loss=0.4478 f1m=0.516 auc=0.645 sel(va_auc)=0.645056 best=0.649876@ep17\n",
      "[trade] ep 21 lr=2.00e-04 tr_loss=0.6342 va_loss=0.4674 f1m=0.550 auc=0.655 sel(va_auc)=0.654695 best=0.654695@ep21\n",
      "[trade] ep 22 lr=2.00e-04 tr_loss=0.6363 va_loss=0.4688 f1m=0.550 auc=0.653 sel(va_auc)=0.653141 best=0.654695@ep21\n",
      "[trade] ep 23 lr=2.00e-04 tr_loss=0.6373 va_loss=0.4560 f1m=0.538 auc=0.650 sel(va_auc)=0.649565 best=0.654695@ep21\n",
      "[trade] ep 24 lr=2.00e-04 tr_loss=0.6390 va_loss=0.5050 f1m=0.584 auc=0.645 sel(va_auc)=0.645056 best=0.654695@ep21\n",
      "[trade] ep 25 lr=2.00e-04 tr_loss=0.6160 va_loss=0.4819 f1m=0.597 auc=0.648 sel(va_auc)=0.648476 best=0.654695@ep21\n",
      "[trade] ep 26 lr=1.00e-04 tr_loss=0.6098 va_loss=0.5035 f1m=0.584 auc=0.653 sel(va_auc)=0.652519 best=0.654695@ep21\n",
      "[trade] ep 27 lr=1.00e-04 tr_loss=0.6029 va_loss=0.5163 f1m=0.587 auc=0.653 sel(va_auc)=0.653451 best=0.654695@ep21\n",
      "[trade] ep 28 lr=1.00e-04 tr_loss=0.6059 va_loss=0.5247 f1m=0.616 auc=0.660 sel(va_auc)=0.659826 best=0.659826@ep28\n",
      "[trade] ep 29 lr=1.00e-04 tr_loss=0.5922 va_loss=0.5025 f1m=0.621 auc=0.669 sel(va_auc)=0.668843 best=0.668843@ep29\n",
      "[trade] ep 30 lr=1.00e-04 tr_loss=0.5951 va_loss=0.5271 f1m=0.602 auc=0.666 sel(va_auc)=0.665578 best=0.668843@ep29\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.9028 va_loss=0.7953 f1m=0.489 auc=0.498 pnl_max=-0.000111 thr=(0.50,0.70) trades=69 sel(va_pnl_max)=-0.000111 best=pnl=-0.000111@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8299 va_loss=0.7781 f1m=0.427 auc=0.490 pnl_max=0.000032 thr=(0.50,0.70) trades=66 sel(va_pnl_max)=0.000032 best=pnl=0.000032@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7878 va_loss=0.7337 f1m=0.519 auc=0.492 pnl_max=0.000089 thr=(0.70,0.50) trades=150 sel(va_pnl_max)=0.000089 best=pnl=0.000089@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.8027 va_loss=0.7216 f1m=0.493 auc=0.490 pnl_max=0.000173 thr=(0.60,0.55) trades=103 sel(va_pnl_max)=0.000173 best=pnl=0.000173@ep04\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7616 va_loss=0.7195 f1m=0.479 auc=0.469 pnl_max=-0.000149 thr=(0.50,0.55) trades=103 sel(va_pnl_max)=-0.000149 best=pnl=0.000173@ep04\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7302 va_loss=0.7184 f1m=0.443 auc=0.451 pnl_max=-0.000132 thr=(0.50,0.55) trades=96 sel(va_pnl_max)=-0.000132 best=pnl=0.000173@ep04\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.7270 va_loss=0.7146 f1m=0.425 auc=0.442 pnl_max=-0.000014 thr=(0.50,0.55) trades=86 sel(va_pnl_max)=-0.000014 best=pnl=0.000173@ep04\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.7453 va_loss=0.7105 f1m=0.448 auc=0.443 pnl_max=0.000019 thr=(0.70,0.55) trades=64 sel(va_pnl_max)=0.000019 best=pnl=0.000173@ep04\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7256 va_loss=0.7085 f1m=0.437 auc=0.444 pnl_max=-0.000252 thr=(0.70,0.55) trades=52 sel(va_pnl_max)=-0.000252 best=pnl=0.000173@ep04\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.7190 va_loss=0.7081 f1m=0.445 auc=0.441 pnl_max=-0.000127 thr=(0.50,0.55) trades=58 sel(va_pnl_max)=-0.000127 best=pnl=0.000173@ep04\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.7417 va_loss=0.7079 f1m=0.423 auc=0.437 pnl_max=-0.000146 thr=(0.50,0.55) trades=61 sel(va_pnl_max)=-0.000146 best=pnl=0.000173@ep04\n",
      "[dir] ep 12 lr=1.00e-04 tr_loss=0.7149 va_loss=0.7074 f1m=0.412 auc=0.438 pnl_max=-0.000313 thr=(0.50,0.55) trades=67 sel(va_pnl_max)=-0.000313 best=pnl=0.000173@ep04\n",
      "PnL on fold-test: | thr_trade= 0.7 | thr_dir= 0.5 | pnl_mean= 0.0007062558433972299 | trades= 76.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.428922</td>\n",
       "      <td>0.272401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.266257</td>\n",
       "      <td>0.390608</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.012876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.191331</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.090129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.475698</td>\n",
       "      <td>0.583048</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.326180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.428922      0.272401       0.000000            0.50   \n",
       "1     2        0.266257      0.390608       0.000055            0.55   \n",
       "2     3        0.191331      0.432547       0.000122            0.50   \n",
       "3     4        0.475698      0.583048       0.000706            0.70   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0           0.5            0.0         0.000000  \n",
       "1           0.6            3.0         0.012876  \n",
       "2           0.5           21.0         0.090129  \n",
       "3           0.5           76.0         0.326180  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN (fold-test внутри CV-part):\n",
      "fold                2.500000\n",
      "trade_test_f1m      0.340552\n",
      "dir_test_f1m        0.419651\n",
      "best_pnl_mean       0.000221\n",
      "best_thr_trade      0.562500\n",
      "best_thr_dir        0.525000\n",
      "n_trades_best      25.000000\n",
      "trade_rate_best     0.107296\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training (ONLY on CV-part)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold (fit only on train times)\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples (по AUC)\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\",\n",
    "        select_metric=\"va_auc\",\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples (train/val/test индексы фильтруем)\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "            \"trade_rate_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # dir: учим на trade-only, но PnL-proxy считаем на полном idx_va (full val)\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\",\n",
    "        select_metric=\"va_pnl_max\",\n",
    "        trade_model_for_pnl=m_trade,\n",
    "        idx_val_pnl=idx_va,   # <-- полный val для pnl-proxy\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on fold TEST\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te, CFG)\n",
    "    prob_dir_te, _       = predict_probs_on_indices(m_dir,   X_scaled, edge_feat, idx_te, CFG)\n",
    "\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on fold-test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN (fold-test внутри CV-part):\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": [
    "## 11. Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50d16463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL TRAIN/TEST (CV=90% | FINAL=10%)\n",
      "Final split sizes:\n",
      "  train_final: 2104\n",
      "  val_final  : 233\n",
      "  FINAL test : 260\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : -8.062860433710739e-05\n",
      "  pnl_sum  : -0.020963437855243683\n",
      "  n_trades : 190\n",
      "  trade_rate: 0.7307692307692307\n",
      "  sharpe (per-bar proxy): -0.17655171541928572\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.5 thr_dir: 0.65\n",
      "  pnl_mean : 0.00020149454940110445 trades: 35.0\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Final train on CV(90%) and evaluate once on FINAL(10%)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAIN/TEST (CV=90% | FINAL=10%)\")\n",
    "\n",
    "# 1) final train/val split внутри CV-part (по времени)\n",
    "val_w_final = max(1, int(CFG[\"val_window_frac\"] * n_samples_cv))\n",
    "train_end = n_samples_cv - val_w_final\n",
    "\n",
    "idx_train_final = np.arange(0, train_end, dtype=np.int64)\n",
    "idx_val_final   = np.arange(train_end, n_samples_cv, dtype=np.int64)\n",
    "idx_test_final  = idx_final_test.astype(np.int64)  # финальный holdout\n",
    "\n",
    "print(\"Final split sizes:\")\n",
    "print(\"  train_final:\", len(idx_train_final))\n",
    "print(\"  val_final  :\", len(idx_val_final))\n",
    "print(\"  FINAL test :\", len(idx_test_final))\n",
    "\n",
    "# 2) scaling (fit only on train_final)\n",
    "X_scaled_final, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train_final, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=summary['best_thr_trade'][3],\n",
    "    thr_dir=summary['best_thr_dir'][3],\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c4946a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.8100 va_loss=0.7494 f1m=0.434 auc=0.560 sel(va_auc)=0.559596 best=0.559596@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7684 va_loss=0.7028 f1m=0.513 auc=0.578 sel(va_auc)=0.578399 best=0.578399@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7367 va_loss=0.7082 f1m=0.474 auc=0.589 sel(va_auc)=0.589355 best=0.589355@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.7313 va_loss=0.6809 f1m=0.536 auc=0.588 sel(va_auc)=0.588267 best=0.589355@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.7271 va_loss=0.6996 f1m=0.513 auc=0.593 sel(va_auc)=0.593473 best=0.593473@ep05\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.7052 va_loss=0.6833 f1m=0.568 auc=0.590 sel(va_auc)=0.590054 best=0.593473@ep05\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.7090 va_loss=0.6767 f1m=0.559 auc=0.580 sel(va_auc)=0.580420 best=0.593473@ep05\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6805 va_loss=0.6813 f1m=0.540 auc=0.565 sel(va_auc)=0.565268 best=0.593473@ep05\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6603 va_loss=0.7111 f1m=0.538 auc=0.564 sel(va_auc)=0.564413 best=0.593473@ep05\n",
      "[trade] ep 10 lr=1.00e-04 tr_loss=0.6567 va_loss=0.7275 f1m=0.540 auc=0.578 sel(va_auc)=0.577545 best=0.593473@ep05\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.6548 va_loss=0.7310 f1m=0.538 auc=0.580 sel(va_auc)=0.579798 best=0.593473@ep05\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.6457 va_loss=0.7295 f1m=0.538 auc=0.587 sel(va_auc)=0.587335 best=0.593473@ep05\n",
      "[trade] ep 13 lr=1.00e-04 tr_loss=0.6267 va_loss=0.7339 f1m=0.535 auc=0.582 sel(va_auc)=0.582284 best=0.593473@ep05\n",
      "Trade-only sizes for DIR:\n",
      "  train_final_T: 963\n",
      "  val_final_T  : 143\n",
      "  test_final_T : 207\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8185 va_loss=0.7203 f1m=0.525 auc=0.522 pnl_max=0.000177 thr=(0.50,0.55) trades=43 sel(va_pnl_max)=0.000177 best=pnl=0.000177@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.8085 va_loss=0.7311 f1m=0.469 auc=0.490 pnl_max=0.000019 thr=(0.55,0.50) trades=23 sel(va_pnl_max)=0.000019 best=pnl=0.000177@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7958 va_loss=0.7318 f1m=0.475 auc=0.445 pnl_max=0.000099 thr=(0.55,0.50) trades=23 sel(va_pnl_max)=0.000099 best=pnl=0.000177@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7429 va_loss=0.7273 f1m=0.414 auc=0.420 pnl_max=-0.000041 thr=(0.55,0.50) trades=23 sel(va_pnl_max)=-0.000041 best=pnl=0.000177@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7463 va_loss=0.7281 f1m=0.404 auc=0.405 pnl_max=-0.000241 thr=(0.55,0.50) trades=23 sel(va_pnl_max)=-0.000241 best=pnl=0.000177@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr_loss=0.7424 va_loss=0.7189 f1m=0.419 auc=0.409 pnl_max=-0.000154 thr=(0.55,0.50) trades=23 sel(va_pnl_max)=-0.000154 best=pnl=0.000177@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.7323 va_loss=0.7173 f1m=0.420 auc=0.414 pnl_max=-0.000022 thr=(0.55,0.50) trades=23 sel(va_pnl_max)=-0.000022 best=pnl=0.000177@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.7374 va_loss=0.7154 f1m=0.413 auc=0.416 pnl_max=-0.000072 thr=(0.50,0.55) trades=25 sel(va_pnl_max)=-0.000072 best=pnl=0.000177@ep01\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.7123 va_loss=0.7179 f1m=0.404 auc=0.407 pnl_max=-0.000113 thr=(0.50,0.55) trades=26 sel(va_pnl_max)=-0.000113 best=pnl=0.000177@ep01\n",
      "\n",
      "Chosen thresholds on val_final:\n",
      "  thr_trade*: 0.5\n",
      "  thr_dir*  : 0.65\n",
      "  val pnl_mean: 0.00023055086785461754 | val trades: 17\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : 5.6572487665107474e-05\n",
      "  pnl_sum  : 0.014708846807479858\n",
      "  n_trades : 44\n",
      "  trade_rate: 0.16923076923076924\n",
      "  sharpe (per-bar proxy): 0.27149010479468216\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.5 thr_dir: 0.5\n",
      "  pnl_mean : 0.00021631568961311132 trades: 155.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3) train TRADE on train_final, select by AUC on val_final\n",
    "m_trade_final, r_trade_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final, idx_val_final, idx_test_final,\n",
    "    CFG,\n",
    "    stage_name=\"trade\",\n",
    "    select_metric=\"va_auc\",\n",
    ")\n",
    "\n",
    "# 4) train DIR on trade-only samples (train/val/test filtered),\n",
    "#    but pnl-proxy computed on full val_final; selector hard-fallback already inside\n",
    "idx_train_final_T = subset_trade_indices(idx_train_final, sample_t, y_trade)\n",
    "idx_val_final_T   = subset_trade_indices(idx_val_final,   sample_t, y_trade)\n",
    "idx_test_final_T  = subset_trade_indices(idx_test_final,  sample_t, y_trade)\n",
    "\n",
    "print(\"Trade-only sizes for DIR:\")\n",
    "print(\"  train_final_T:\", len(idx_train_final_T))\n",
    "print(\"  val_final_T  :\", len(idx_val_final_T))\n",
    "print(\"  test_final_T :\", len(idx_test_final_T))\n",
    "\n",
    "m_dir_final, r_dir_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final_T, idx_val_final_T, idx_test_final_T,\n",
    "    CFG,\n",
    "    stage_name=\"dir\",\n",
    "    select_metric=\"va_pnl_max\",\n",
    "    trade_model_for_pnl=m_trade_final,\n",
    "    idx_val_pnl=idx_val_final,   # pnl-proxy на полном val_final\n",
    ")\n",
    "\n",
    "# 5) выбрать пороги по val_final (grid sweep)\n",
    "prob_trade_val, er_val = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "prob_dir_val, _        = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "\n",
    "sweep_val = sweep_thresholds(prob_trade_val, prob_dir_val, er_val, CFG)\n",
    "best_val = sweep_val.iloc[0].to_dict()\n",
    "thr_trade_star = float(best_val[\"thr_trade\"])\n",
    "thr_dir_star   = float(best_val[\"thr_dir\"])\n",
    "\n",
    "print(\"\\nChosen thresholds on val_final:\")\n",
    "print(\"  thr_trade*:\", thr_trade_star)\n",
    "print(\"  thr_dir*  :\", thr_dir_star)\n",
    "print(\"  val pnl_mean:\", float(best_val[\"pnl_mean\"]), \"| val trades:\", int(best_val[\"n_trades\"]))\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=thr_trade_star,\n",
    "    thr_dir=thr_dir_star,\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
