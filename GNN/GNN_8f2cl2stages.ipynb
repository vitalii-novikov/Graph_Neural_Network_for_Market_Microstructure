{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),\n",
    "    \"book_levels\": 15,\n",
    "\n",
    "    # sequence\n",
    "    \"lookback\": 48,   # L\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 96],  # 30m,1h,2h,4h,8h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 12,       # 1h\n",
    "    \"tb_vol_window\": 48,    # 4h\n",
    "    \"tb_pt_mult\": 1.5,\n",
    "    \"tb_sl_mult\": 1.5,\n",
    "    \"tb_min_barrier\": 0.0005,\n",
    "    \"tb_max_barrier\": 0.003,\n",
    "\n",
    "    # training (общие)\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.15,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "print(\"EDGE_INDEX:\", EDGE_INDEX.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (3367, 106)\n",
      "Columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4', 'asks_vol_ADA_5', 'asks_vol_ADA_6', 'asks_vol_ADA_7', 'asks_vol_ADA_8', 'asks_vol_ADA_9', 'asks_vol_ADA_10', 'asks_vol_ADA_11', 'asks_vol_ADA_12', 'asks_vol_ADA_13', 'asks_vol_ADA_14', 'BTC', 'spread_BTC', 'buys_BTC', 'sells_BTC', 'bids_vol_BTC_0', 'bids_vol_BTC_1', 'bids_vol_BTC_2', 'bids_vol_BTC_3', 'bids_vol_BTC_4', 'bids_vol_BTC_5', 'bids_vol_BTC_6', 'bids_vol_BTC_7', 'bids_vol_BTC_8', 'bids_vol_BTC_9', 'bids_vol_BTC_10', 'bids_vol_BTC_11', 'bids_vol_BTC_12', 'bids_vol_BTC_13', 'bids_vol_BTC_14', 'asks_vol_BTC_0', 'asks_vol_BTC_1', 'asks_vol_BTC_2', 'asks_vol_BTC_3', 'asks_vol_BTC_4', 'asks_vol_BTC_5', 'asks_vol_BTC_6', 'asks_vol_BTC_7', 'asks_vol_BTC_8', 'asks_vol_BTC_9', 'asks_vol_BTC_10', 'asks_vol_BTC_11', 'asks_vol_BTC_12', 'asks_vol_BTC_13', 'asks_vol_BTC_14', 'ETH', 'spread_ETH', 'buys_ETH', 'sells_ETH', 'bids_vol_ETH_0', 'bids_vol_ETH_1', 'bids_vol_ETH_2', 'bids_vol_ETH_3', 'bids_vol_ETH_4', 'bids_vol_ETH_5', 'bids_vol_ETH_6', 'bids_vol_ETH_7', 'bids_vol_ETH_8', 'bids_vol_ETH_9', 'bids_vol_ETH_10', 'bids_vol_ETH_11', 'bids_vol_ETH_12', 'bids_vol_ETH_13', 'bids_vol_ETH_14', 'asks_vol_ETH_0', 'asks_vol_ETH_1', 'asks_vol_ETH_2', 'asks_vol_ETH_3', 'asks_vol_ETH_4', 'asks_vol_ETH_5', 'asks_vol_ETH_6', 'asks_vol_ETH_7', 'asks_vol_ETH_8', 'asks_vol_ETH_9', 'asks_vol_ETH_10', 'asks_vol_ETH_11', 'asks_vol_ETH_12', 'asks_vol_ETH_13', 'asks_vol_ETH_14', 'lr_ADA', 'lr_BTC', 'lr_ETH']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "def load_all_assets():\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]  # например 15\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (3367, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [1269  743 1355]\n",
      "Trade ratio: 0.7793287793287793\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=CFG[\"tb_horizon\"],\n",
    "    vol_window=CFG[\"tb_vol_window\"],\n",
    "    pt_mult=CFG[\"tb_pt_mult\"],\n",
    "    sl_mult=CFG[\"tb_sl_mult\"],\n",
    "    min_barrier=CFG[\"tb_min_barrier\"],\n",
    "    max_barrier=CFG[\"tb_max_barrier\"],\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (3367, 3, 8) edge_feat: (3367, 3, 5)\n",
      "n_samples: 3307 t range: 47 3353\n",
      "node_feat_names: ['lr', 'spread', 'log_bids_sum', 'log_asks_sum', 'log_buys', 'log_sells', 'ofi', 'di_sum']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray):\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\",\n",
    "        \"spread\",\n",
    "        \"log_bids_sum\",\n",
    "        \"log_asks_sum\",\n",
    "        \"log_buys\",\n",
    "        \"log_sells\",\n",
    "        \"ofi\",\n",
    "        \"di_sum\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        # суммируем глубину по 0..L-1\n",
    "        bid_cols = [f\"bids_vol_{a}_{i}\" for i in range(book_levels)]\n",
    "        ask_cols = [f\"asks_vol_{a}_{i}\" for i in range(book_levels)]\n",
    "\n",
    "        bids_sum = df[bid_cols].sum(axis=1).values.astype(np.float32)\n",
    "        asks_sum = df[ask_cols].sum(axis=1).values.astype(np.float32)\n",
    "\n",
    "        log_bids_sum = safe_log1p(bids_sum).astype(np.float32)\n",
    "        log_asks_sum = safe_log1p(asks_sum).astype(np.float32)\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "        di_sum = ((bids_sum - asks_sum) / (bids_sum + asks_sum + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.stack(\n",
    "            [lr, spread, log_bids_sum, log_asks_sum, log_buys, log_sells, ofi, di_sum],\n",
    "            axis=1\n",
    "        )\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n",
    "print(\"node_feat_names:\", node_feat_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1653 | val 330 | test 330\n",
      " fold 2: train 1983 | val 330 | test 330\n",
      " fold 3: train 2313 | val 330 | test 330\n",
      " fold 4: train 2643 | val 330 | test 330\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "        idx_train = np.arange(0, tr_end)\n",
    "        idx_val   = np.arange(tr_end, va_end)\n",
    "        idx_test  = np.arange(va_end, te_end)\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "    return splits\n",
    "\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "\n",
    "for i, (a,b,c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: GNN + LSTM classifier (универсальный под 2 класса)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class EdgeGatedMP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_proj = nn.Linear(in_dim, hidden)\n",
    "        self.ln0 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden + edge_dim, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden + 1)  # msg(hidden) + gate(1)\n",
    "        )\n",
    "\n",
    "        self.upd = nn.Sequential(\n",
    "            nn.Linear(2*hidden, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward_once(self, x_t, edge_attr_t, edge_index):\n",
    "        B, N, _ = x_t.shape\n",
    "        E = edge_index.shape[0]\n",
    "\n",
    "        h = self.ln0(self.node_proj(x_t))  # (B,N,H)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        agg = torch.zeros((B, N, h.shape[-1]), device=h.device, dtype=h.dtype)\n",
    "\n",
    "        for e in range(E):\n",
    "            src = edge_index[e, 0].item()\n",
    "            dst = edge_index[e, 1].item()\n",
    "            h_src = h[:, src, :]\n",
    "            h_dst = h[:, dst, :]\n",
    "            ea = edge_attr_t[:, e, :]\n",
    "\n",
    "            z = torch.cat([h_src, h_dst, ea], dim=-1)\n",
    "            out = self.edge_mlp(z)\n",
    "            msg = out[:, :-1]\n",
    "            gate = torch.sigmoid(out[:, -1:])\n",
    "\n",
    "            agg[:, dst, :] += msg * gate\n",
    "\n",
    "        h2 = self.upd(torch.cat([h, agg], dim=-1))\n",
    "        h2 = self.ln1(h + self.dropout(h2))\n",
    "        h2 = torch.nan_to_num(h2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return h2\n",
    "\n",
    "    def forward(self, x_seq, e_seq, edge_index):\n",
    "        B, L, N, Fin = x_seq.shape\n",
    "        h_out = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            h_out.append(ht)\n",
    "        return torch.stack(h_out, dim=1)  # (B,L,N,H)\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = target_node\n",
    "\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(gnn_layers):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(EdgeGatedMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, dropout=dropout))\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(lstm_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, lstm_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, n_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        out, _ = self.lstm(h_tgt)\n",
    "        last = out[:, -1, :]\n",
    "        logits = self.head(last)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"Model ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        er_np = er.cpu().numpy()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))  # (B,2)\n",
    "        # y is passed inside loader by selecting correct field externally\n",
    "        # so here we assume loader yields y in y_trade_b (or y_dir_b) as \"y_trade_b\"\n",
    "        y = y_trade_b.to(DEVICE).long()\n",
    "\n",
    "        loss = loss_fn(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()  # (B,2)\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er_np)\n",
    "\n",
    "    ys = np.concatenate(ys)\n",
    "    probs = np.concatenate(probs)\n",
    "    ers = np.concatenate(ers)\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:,1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss/max(n,1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "def make_pos_weight(y01: np.ndarray):\n",
    "    pos = max(1, int((y01 == 1).sum()))\n",
    "    neg = max(1, int((y01 == 0).sum()))\n",
    "    return float(neg / pos)\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    stage_name:\n",
    "      - \"trade\": обучаем y_trade на всех samples\n",
    "      - \"dir\":   обучаем y_dir только на trade samples (idx_* уже должны быть отфильтрованы)\n",
    "    \"\"\"\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val, L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test, L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True, drop_last=True, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # label extraction for pos_weight\n",
    "    if stage_name == \"trade\":\n",
    "        ytr = y_trade_arr[sample_t[idx_train]]\n",
    "    elif stage_name == \"dir\":\n",
    "        ytr = y_dir_arr[sample_t[idx_train]]\n",
    "    else:\n",
    "        raise ValueError(\"stage_name must be 'trade' or 'dir'\")\n",
    "\n",
    "    pos_w = make_pos_weight(ytr)\n",
    "    loss_fn = nn.CrossEntropyLoss()  # базово CE\n",
    "    # (если хочешь pos_weight, то лучше BCE; но чтобы не усложнять logits->2, оставим CE + баланс через sampler/веса)\n",
    "    # Минимально: просто CE, а дисбаланс компенсируем тем, что Stage B обучается только на trade.\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type==\"cuda\"))\n",
    "\n",
    "    best_score = -1e9\n",
    "    best_state = None\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\"tr_loss\":[], \"va_loss\":[], \"va_f1m\":[], \"va_auc\":[]}\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"]+1):\n",
    "        model.train()\n",
    "        tot = 0.0; n = 0\n",
    "\n",
    "        for x,e,y_trade_b,y_dir_b,er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "\n",
    "            # select labels by stage\n",
    "            y = (y_trade_b if stage_name==\"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type==\"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item()*y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot/max(n,1)\n",
    "\n",
    "        # ---- eval (важно: eval_binary читает y из y_trade_b; поэтому подменяем порядок через wrapper-лоадер нельзя.\n",
    "        # минимально: просто используем loader, но в eval_binary считаем y = y_trade_b.\n",
    "        # => Для dir-stage нужно \"перепаковать\" y_dir в позицию y_trade_b (самый простой минимальный способ).\n",
    "        def wrap_loader_for_stage(loader, stage):\n",
    "            for x,e,y_trade_b,y_dir_b,er in loader:\n",
    "                if stage == \"trade\":\n",
    "                    yield x,e,y_trade_b,y_dir_b,er\n",
    "                else:\n",
    "                    # положить y_dir в slot y_trade_b\n",
    "                    yield x,e,y_dir_b,y_dir_b,er\n",
    "\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, wrap_loader_for_stage(va_loader, stage_name), loss_fn\n",
    "        )\n",
    "\n",
    "        score = va_f1m  # минимально и стабильно\n",
    "        sch.step(score)\n",
    "\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "        print(f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} tr={tr_loss:.4f} va={va_loss:.4f} f1m={va_f1m:.3f} auc={va_auc:.3f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(\n",
    "        model, wrap_loader_for_stage(te_loader, stage_name), loss_fn\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": best_score,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_f1m\": te_f1m,\n",
    "        \"test_auc\": te_auc,\n",
    "        \"test_cm\": te_cm,\n",
    "        \"hist\": hist,\n",
    "        \"test_y\": te_y,\n",
    "        \"test_prob\": te_prob,\n",
    "        \"test_er\": te_er,\n",
    "    }\n",
    "    return model, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: PnL по порогам уверенности (two-stage)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade,          # (N,2) softmax: [:,1]=p_trade\n",
    "    prob_dir,            # (N,2) softmax: [:,1]=p_up\n",
    "    exit_ret,            # (N,) realized log-ret to TB exit\n",
    "    thr_trade: float,\n",
    "    thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:,1]\n",
    "    p_up = prob_dir[:,1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (cost_bps * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(exit_ret),\n",
    "        \"n_trades\": int(trade_mask.sum()),\n",
    "        \"trade_rate\": float(trade_mask.mean()),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg):\n",
    "    rows = []\n",
    "    for thr_t in cfg[\"thr_trade_grid\"]:\n",
    "        for thr_d in cfg[\"thr_dir_grid\"]:\n",
    "            m = two_stage_pnl_by_threshold(\n",
    "                prob_trade=prob_trade,\n",
    "                prob_dir=prob_dir,\n",
    "                exit_ret=exit_ret,\n",
    "                thr_trade=thr_t,\n",
    "                thr_dir=thr_d,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "            )\n",
    "            rows.append({\"thr_trade\":thr_t, \"thr_dir\":thr_d, **m})\n",
    "    return pd.DataFrame(rows).sort_values([\"pnl_mean\",\"pnl_sum\"], ascending=False)\n",
    "\n",
    "print(\"Two-stage PnL threshold utils ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1653 330 330\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.8052 va=0.3942 f1m=0.464 auc=0.559\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.6693 va=0.4351 f1m=0.464 auc=0.617\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.6469 va=0.4370 f1m=0.486 auc=0.596\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.6337 va=0.4322 f1m=0.485 auc=0.601\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.6273 va=0.4150 f1m=0.486 auc=0.610\n",
      "[trade] ep 06 lr=2.00e-04 tr=0.6109 va=0.4143 f1m=0.504 auc=0.617\n",
      "[trade] ep 07 lr=2.00e-04 tr=0.5977 va=0.4060 f1m=0.486 auc=0.624\n",
      "[trade] ep 08 lr=2.00e-04 tr=0.5951 va=0.4126 f1m=0.557 auc=0.642\n",
      "[trade] ep 09 lr=2.00e-04 tr=0.5815 va=0.4193 f1m=0.556 auc=0.622\n",
      "[trade] ep 10 lr=2.00e-04 tr=0.5906 va=0.4167 f1m=0.541 auc=0.620\n",
      "[trade] ep 11 lr=2.00e-04 tr=0.5820 va=0.4259 f1m=0.559 auc=0.606\n",
      "[trade] ep 12 lr=2.00e-04 tr=0.5767 va=0.4285 f1m=0.553 auc=0.615\n",
      "[trade] ep 13 lr=2.00e-04 tr=0.5729 va=0.4384 f1m=0.549 auc=0.592\n",
      "[trade] ep 14 lr=2.00e-04 tr=0.5523 va=0.4519 f1m=0.545 auc=0.578\n",
      "[trade] ep 15 lr=2.00e-04 tr=0.5390 va=0.4551 f1m=0.548 auc=0.574\n",
      "[trade] ep 16 lr=1.00e-04 tr=0.5370 va=0.4716 f1m=0.539 auc=0.555\n",
      "[trade] ep 17 lr=1.00e-04 tr=0.5407 va=0.4879 f1m=0.526 auc=0.535\n",
      "[trade] ep 18 lr=1.00e-04 tr=0.5404 va=0.4819 f1m=0.534 auc=0.534\n",
      "[trade] ep 19 lr=1.00e-04 tr=0.5269 va=0.4878 f1m=0.528 auc=0.542\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.8348 va=0.6934 f1m=0.485 auc=0.510\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7751 va=0.6847 f1m=0.545 auc=0.549\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7231 va=0.7050 f1m=0.526 auc=0.571\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.7104 va=0.6889 f1m=0.563 auc=0.569\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6884 va=0.6910 f1m=0.532 auc=0.573\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6748 va=0.6998 f1m=0.549 auc=0.580\n",
      "[dir] ep 07 lr=2.00e-04 tr=0.6746 va=0.6811 f1m=0.541 auc=0.570\n",
      "[dir] ep 08 lr=2.00e-04 tr=0.6751 va=0.6900 f1m=0.554 auc=0.575\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.6472 va=0.7112 f1m=0.495 auc=0.569\n",
      "[dir] ep 10 lr=1.00e-04 tr=0.6465 va=0.7112 f1m=0.491 auc=0.563\n",
      "[dir] ep 11 lr=1.00e-04 tr=0.6319 va=0.7008 f1m=0.534 auc=0.561\n",
      "[dir] ep 12 lr=1.00e-04 tr=0.6302 va=0.7000 f1m=0.533 auc=0.560\n",
      "Best PnL on test: | thr_trade= 0.6 | thr_dir= 0.5 | pnl_mean= 0.0007026662351563573 | trades= 297.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1983 330 330\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.6965 va=0.3213 f1m=0.479 auc=0.578\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.6176 va=0.3441 f1m=0.477 auc=0.609\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.6142 va=0.3360 f1m=0.479 auc=0.612\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.5968 va=0.3146 f1m=0.479 auc=0.610\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5901 va=0.3370 f1m=0.478 auc=0.612\n",
      "[trade] ep 06 lr=2.00e-04 tr=0.5688 va=0.3330 f1m=0.475 auc=0.612\n",
      "[trade] ep 07 lr=2.00e-04 tr=0.5659 va=0.3275 f1m=0.476 auc=0.619\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.5471 va=0.2981 f1m=0.477 auc=0.621\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.5576 va=0.3091 f1m=0.475 auc=0.623\n",
      "[trade] ep 10 lr=1.00e-04 tr=0.5624 va=0.3084 f1m=0.475 auc=0.618\n",
      "[trade] ep 11 lr=1.00e-04 tr=0.5474 va=0.3049 f1m=0.474 auc=0.621\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.8135 va=0.7050 f1m=0.480 auc=0.526\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7530 va=0.7039 f1m=0.502 auc=0.532\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7038 va=0.6871 f1m=0.498 auc=0.559\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.6800 va=0.6847 f1m=0.504 auc=0.557\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6829 va=0.6880 f1m=0.421 auc=0.561\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6752 va=0.6884 f1m=0.497 auc=0.557\n",
      "[dir] ep 07 lr=2.00e-04 tr=0.6684 va=0.6910 f1m=0.516 auc=0.554\n",
      "[dir] ep 08 lr=2.00e-04 tr=0.6765 va=0.6885 f1m=0.539 auc=0.552\n",
      "[dir] ep 09 lr=2.00e-04 tr=0.6549 va=0.6868 f1m=0.487 auc=0.559\n",
      "[dir] ep 10 lr=2.00e-04 tr=0.6530 va=0.6885 f1m=0.526 auc=0.563\n",
      "[dir] ep 11 lr=2.00e-04 tr=0.6414 va=0.7001 f1m=0.539 auc=0.545\n",
      "[dir] ep 12 lr=2.00e-04 tr=0.6452 va=0.6920 f1m=0.530 auc=0.561\n",
      "[dir] ep 13 lr=2.00e-04 tr=0.6303 va=0.7006 f1m=0.571 auc=0.554\n",
      "[dir] ep 14 lr=2.00e-04 tr=0.6139 va=0.7191 f1m=0.548 auc=0.544\n",
      "[dir] ep 15 lr=2.00e-04 tr=0.6325 va=0.7162 f1m=0.467 auc=0.552\n",
      "[dir] ep 16 lr=2.00e-04 tr=0.6175 va=0.7089 f1m=0.538 auc=0.531\n",
      "[dir] ep 17 lr=2.00e-04 tr=0.6001 va=0.7079 f1m=0.551 auc=0.554\n",
      "[dir] ep 18 lr=1.00e-04 tr=0.5990 va=0.7191 f1m=0.549 auc=0.553\n",
      "[dir] ep 19 lr=1.00e-04 tr=0.5860 va=0.7205 f1m=0.567 auc=0.548\n",
      "[dir] ep 20 lr=1.00e-04 tr=0.5792 va=0.7244 f1m=0.568 auc=0.545\n",
      "[dir] ep 21 lr=1.00e-04 tr=0.5773 va=0.7270 f1m=0.547 auc=0.541\n",
      "Best PnL on test: | thr_trade= 0.7 | thr_dir= 0.6 | pnl_mean= 0.00019264969159848988 | trades= 150.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 2313 330 330\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.6417 va=0.2146 f1m=0.488 auc=0.607\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.5788 va=0.2149 f1m=0.488 auc=0.651\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.5567 va=0.2115 f1m=0.488 auc=0.673\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.5429 va=0.1962 f1m=0.488 auc=0.674\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5376 va=0.2098 f1m=0.488 auc=0.682\n",
      "[trade] ep 06 lr=1.00e-04 tr=0.5326 va=0.1843 f1m=0.488 auc=0.690\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.5225 va=0.1846 f1m=0.488 auc=0.719\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.5094 va=0.1825 f1m=0.488 auc=0.743\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.5122 va=0.1836 f1m=0.547 auc=0.760\n",
      "[trade] ep 10 lr=1.00e-04 tr=0.5070 va=0.1716 f1m=0.488 auc=0.774\n",
      "[trade] ep 11 lr=1.00e-04 tr=0.4909 va=0.1725 f1m=0.488 auc=0.788\n",
      "[trade] ep 12 lr=1.00e-04 tr=0.5027 va=0.1715 f1m=0.547 auc=0.787\n",
      "[trade] ep 13 lr=1.00e-04 tr=0.4978 va=0.1679 f1m=0.488 auc=0.773\n",
      "[trade] ep 14 lr=5.00e-05 tr=0.4890 va=0.1709 f1m=0.488 auc=0.746\n",
      "[trade] ep 15 lr=5.00e-05 tr=0.4940 va=0.1704 f1m=0.488 auc=0.764\n",
      "[trade] ep 16 lr=5.00e-05 tr=0.4851 va=0.1736 f1m=0.533 auc=0.787\n",
      "[trade] ep 17 lr=5.00e-05 tr=0.4826 va=0.1720 f1m=0.488 auc=0.758\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.9791 va=0.8428 f1m=0.336 auc=0.558\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7767 va=0.7287 f1m=0.468 auc=0.468\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7310 va=0.7353 f1m=0.427 auc=0.454\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.7068 va=0.7258 f1m=0.446 auc=0.494\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6859 va=0.7182 f1m=0.439 auc=0.504\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6890 va=0.7161 f1m=0.434 auc=0.484\n",
      "[dir] ep 07 lr=1.00e-04 tr=0.6742 va=0.7356 f1m=0.402 auc=0.449\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6652 va=0.7285 f1m=0.416 auc=0.468\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.6532 va=0.7251 f1m=0.439 auc=0.475\n",
      "[dir] ep 10 lr=1.00e-04 tr=0.6583 va=0.7274 f1m=0.441 auc=0.471\n",
      "Best PnL on test: | thr_trade= 0.7 | thr_dir= 0.7 | pnl_mean= 3.945907155866735e-05 | trades= 13.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 2643 330 330\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.6399 va=0.4171 f1m=0.470 auc=0.712\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.5360 va=0.4118 f1m=0.485 auc=0.715\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.5231 va=0.4153 f1m=0.534 auc=0.726\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.5205 va=0.4094 f1m=0.576 auc=0.741\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5008 va=0.4006 f1m=0.593 auc=0.756\n",
      "[trade] ep 06 lr=2.00e-04 tr=0.4949 va=0.3938 f1m=0.628 auc=0.758\n",
      "[trade] ep 07 lr=2.00e-04 tr=0.4837 va=0.4047 f1m=0.609 auc=0.749\n",
      "[trade] ep 08 lr=2.00e-04 tr=0.4681 va=0.4023 f1m=0.629 auc=0.759\n",
      "[trade] ep 09 lr=2.00e-04 tr=0.4755 va=0.4053 f1m=0.617 auc=0.758\n",
      "[trade] ep 10 lr=2.00e-04 tr=0.4528 va=0.4117 f1m=0.640 auc=0.755\n",
      "[trade] ep 11 lr=2.00e-04 tr=0.4551 va=0.4154 f1m=0.621 auc=0.752\n",
      "[trade] ep 12 lr=2.00e-04 tr=0.4523 va=0.4239 f1m=0.631 auc=0.749\n",
      "[trade] ep 13 lr=2.00e-04 tr=0.4477 va=0.4304 f1m=0.649 auc=0.740\n",
      "[trade] ep 14 lr=2.00e-04 tr=0.4498 va=0.4307 f1m=0.621 auc=0.749\n",
      "[trade] ep 15 lr=2.00e-04 tr=0.4386 va=0.4194 f1m=0.643 auc=0.758\n",
      "[trade] ep 16 lr=2.00e-04 tr=0.4320 va=0.4486 f1m=0.634 auc=0.731\n",
      "[trade] ep 17 lr=2.00e-04 tr=0.4276 va=0.4582 f1m=0.626 auc=0.718\n",
      "[trade] ep 18 lr=1.00e-04 tr=0.4240 va=0.4358 f1m=0.633 auc=0.739\n",
      "[trade] ep 19 lr=1.00e-04 tr=0.4162 va=0.4577 f1m=0.630 auc=0.728\n",
      "[trade] ep 20 lr=1.00e-04 tr=0.4196 va=0.4510 f1m=0.630 auc=0.731\n",
      "[trade] ep 21 lr=1.00e-04 tr=0.4092 va=0.4544 f1m=0.609 auc=0.733\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.8450 va=0.7013 f1m=0.507 auc=0.584\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7628 va=0.7960 f1m=0.339 auc=0.521\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7271 va=0.7157 f1m=0.482 auc=0.540\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.7097 va=0.7395 f1m=0.420 auc=0.549\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.7056 va=0.7453 f1m=0.447 auc=0.510\n",
      "[dir] ep 06 lr=1.00e-04 tr=0.6921 va=0.7281 f1m=0.442 auc=0.554\n",
      "[dir] ep 07 lr=1.00e-04 tr=0.6834 va=0.7426 f1m=0.414 auc=0.530\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6763 va=0.7134 f1m=0.474 auc=0.541\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.6682 va=0.7270 f1m=0.455 auc=0.552\n",
      "Best PnL on test: | thr_trade= 0.55 | thr_dir= 0.7 | pnl_mean= 1.5997124137356877e-05 | trades= 37.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.534862</td>\n",
       "      <td>0.575148</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.507407</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.604567</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.039394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.505582</td>\n",
       "      <td>0.498074</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.112121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.534862      0.575148       0.000703            0.60   \n",
       "1     2        0.488372      0.507407       0.000193            0.70   \n",
       "2     3        0.604567      0.477273       0.000039            0.70   \n",
       "3     4        0.505582      0.498074       0.000016            0.55   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0           0.5          297.0         0.900000  \n",
       "1           0.6          150.0         0.454545  \n",
       "2           0.7           13.0         0.039394  \n",
       "3           0.7           37.0         0.112121  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "fold                 2.500000\n",
      "trade_test_f1m       0.533346\n",
      "dir_test_f1m         0.514475\n",
      "best_pnl_mean        0.000238\n",
      "best_thr_trade       0.637500\n",
      "best_thr_dir         0.625000\n",
      "n_trades_best      124.250000\n",
      "trade_rate_best      0.376515\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\"\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    # если в какой-то части trade почти нет — пропускаем fold direction\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\"\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on TEST (в sample-space idx_te)\n",
    "    # Получим probs trade на idx_te (из r_trade) и probs dir на idx_te тоже нужно.\n",
    "    # r_dir тестился на idx_te_T, поэтому мы посчитаем prob_dir на idx_te через прогон модели по idx_te (без фильтра),\n",
    "    # чтобы sweep был по всем точкам (trade-маска будет от модели trade).\n",
    "\n",
    "    # helper: get probs on arbitrary indices\n",
    "    @torch.no_grad()\n",
    "    def predict_probs_on_indices(model, X_scaled, edge_feat, indices, stage_for_label=\"trade\"):\n",
    "        ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, CFG[\"lookback\"])\n",
    "        loader = DataLoader(ds, batch_size=CFG[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "        model.eval()\n",
    "        probs = []\n",
    "        ers = []\n",
    "        for x,e,yt,yd,er in loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            logits = model(x,e,EDGE_INDEX.to(DEVICE))\n",
    "            p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            probs.append(p)\n",
    "            ers.append(er.cpu().numpy())\n",
    "        return np.concatenate(probs), np.concatenate(ers)\n",
    "\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te)\n",
    "    prob_dir_te, _ = predict_probs_on_indices(m_dir, X_scaled, edge_feat, idx_te)\n",
    "\n",
    "    # exit_ret on same points (already in er_te)\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"Best PnL on test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN:\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
