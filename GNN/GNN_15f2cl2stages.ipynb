{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"1min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),\n",
    "\n",
    "    \"lookback\": 96,\n",
    "    \"tb_horizon\": 24,          \n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 96],  # 30m,1h,2h,4h,8h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 4*60,       # 4h     # нужен для sample_t (чтобы TB-exit не вылезал за конец)\n",
    "    \"tb_vol_window\": 8*60,    # 8h\n",
    "    \"tb_pt_mult\": 3,\n",
    "    \"tb_sl_mult\": 3,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "    # training (общие)\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.15,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "print(\"EDGE_INDEX:\", EDGE_INDEX.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (17109, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (17109, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [3996 9005 4108]\n",
      "Trade ratio: 0.47366882927114384\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=4*60, \n",
    "    vol_window=8*60,\n",
    "    pt_mult=3,\n",
    "    sl_mult=3,\n",
    "    min_barrier=0.001,\n",
    "    max_barrier=0.006,\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (17109, 3, 15) edge_feat: (17109, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 16773 t range: 95 16867\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 8386 | val 1677 | test 1677\n",
      " fold 2: train 10063 | val 1677 | test 1677\n",
      " fold 3: train 11740 | val 1677 | test 1677\n",
      " fold 4: train 13417 | val 1677 | test 1677\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "        idx_train = np.arange(0, tr_end)\n",
    "        idx_val   = np.arange(tr_end, va_end)\n",
    "        idx_test  = np.arange(va_end, te_end)\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "    return splits\n",
    "\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "\n",
    "for i, (a,b,c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: GNN + LSTM classifier (универсальный под 2 класса)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class EdgeGatedMP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_proj = nn.Linear(in_dim, hidden)\n",
    "        self.ln0 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden + edge_dim, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden + 1)  # msg(hidden) + gate(1)\n",
    "        )\n",
    "\n",
    "        self.upd = nn.Sequential(\n",
    "            nn.Linear(2*hidden, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward_once(self, x_t, edge_attr_t, edge_index):\n",
    "        B, N, _ = x_t.shape\n",
    "        E = edge_index.shape[0]\n",
    "\n",
    "        h = self.ln0(self.node_proj(x_t))  # (B,N,H)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        agg = torch.zeros((B, N, h.shape[-1]), device=h.device, dtype=h.dtype)\n",
    "\n",
    "        for e in range(E):\n",
    "            src = edge_index[e, 0].item()\n",
    "            dst = edge_index[e, 1].item()\n",
    "            h_src = h[:, src, :]\n",
    "            h_dst = h[:, dst, :]\n",
    "            ea = edge_attr_t[:, e, :]\n",
    "\n",
    "            z = torch.cat([h_src, h_dst, ea], dim=-1)\n",
    "            out = self.edge_mlp(z)\n",
    "            msg = out[:, :-1]\n",
    "            gate = torch.sigmoid(out[:, -1:])\n",
    "\n",
    "            agg[:, dst, :] += msg * gate\n",
    "\n",
    "        h2 = self.upd(torch.cat([h, agg], dim=-1))\n",
    "        h2 = self.ln1(h + self.dropout(h2))\n",
    "        h2 = torch.nan_to_num(h2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return h2\n",
    "\n",
    "    def forward(self, x_seq, e_seq, edge_index):\n",
    "        B, L, N, Fin = x_seq.shape\n",
    "        h_out = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            h_out.append(ht)\n",
    "        return torch.stack(h_out, dim=1)  # (B,L,N,H)\n",
    "\n",
    "class GNN_LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, node_in, edge_dim, hidden, gnn_layers, lstm_hidden, lstm_layers,\n",
    "                 dropout=0.1, target_node=2, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.target_node = target_node\n",
    "\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(gnn_layers):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(EdgeGatedMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, dropout=dropout))\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(lstm_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, lstm_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, n_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "        out, _ = self.lstm(h_tgt)\n",
    "        last = out[:, -1, :]\n",
    "        logits = self.head(last)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"Model ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        er_np = er.cpu().numpy()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))  # (B,2)\n",
    "        # y is passed inside loader by selecting correct field externally\n",
    "        # so here we assume loader yields y in y_trade_b (or y_dir_b) as \"y_trade_b\"\n",
    "        y = y_trade_b.to(DEVICE).long()\n",
    "\n",
    "        loss = loss_fn(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()  # (B,2)\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er_np)\n",
    "\n",
    "    ys = np.concatenate(ys)\n",
    "    probs = np.concatenate(probs)\n",
    "    ers = np.concatenate(ers)\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:,1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss/max(n,1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "def make_pos_weight(y01: np.ndarray):\n",
    "    pos = max(1, int((y01 == 1).sum()))\n",
    "    neg = max(1, int((y01 == 0).sum()))\n",
    "    return float(neg / pos)\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    stage_name:\n",
    "      - \"trade\": обучаем y_trade на всех samples\n",
    "      - \"dir\":   обучаем y_dir только на trade samples (idx_* уже должны быть отфильтрованы)\n",
    "    \"\"\"\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val, L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test, L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True, drop_last=True, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_LSTM_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # label extraction for pos_weight\n",
    "    if stage_name == \"trade\":\n",
    "        ytr = y_trade_arr[sample_t[idx_train]]\n",
    "    elif stage_name == \"dir\":\n",
    "        ytr = y_dir_arr[sample_t[idx_train]]\n",
    "    else:\n",
    "        raise ValueError(\"stage_name must be 'trade' or 'dir'\")\n",
    "\n",
    "    pos_w = make_pos_weight(ytr)\n",
    "    loss_fn = nn.CrossEntropyLoss()  # базово CE\n",
    "    # (если хочешь pos_weight, то лучше BCE; но чтобы не усложнять logits->2, оставим CE + баланс через sampler/веса)\n",
    "    # Минимально: просто CE, а дисбаланс компенсируем тем, что Stage B обучается только на trade.\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type==\"cuda\"))\n",
    "\n",
    "    best_score = -1e9\n",
    "    best_state = None\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\"tr_loss\":[], \"va_loss\":[], \"va_f1m\":[], \"va_auc\":[]}\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"]+1):\n",
    "        model.train()\n",
    "        tot = 0.0; n = 0\n",
    "\n",
    "        for x,e,y_trade_b,y_dir_b,er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "\n",
    "            # select labels by stage\n",
    "            y = (y_trade_b if stage_name==\"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type==\"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item()*y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot/max(n,1)\n",
    "\n",
    "        # ---- eval (важно: eval_binary читает y из y_trade_b; поэтому подменяем порядок через wrapper-лоадер нельзя.\n",
    "        # минимально: просто используем loader, но в eval_binary считаем y = y_trade_b.\n",
    "        # => Для dir-stage нужно \"перепаковать\" y_dir в позицию y_trade_b (самый простой минимальный способ).\n",
    "        def wrap_loader_for_stage(loader, stage):\n",
    "            for x,e,y_trade_b,y_dir_b,er in loader:\n",
    "                if stage == \"trade\":\n",
    "                    yield x,e,y_trade_b,y_dir_b,er\n",
    "                else:\n",
    "                    # положить y_dir в slot y_trade_b\n",
    "                    yield x,e,y_dir_b,y_dir_b,er\n",
    "\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, wrap_loader_for_stage(va_loader, stage_name), loss_fn\n",
    "        )\n",
    "\n",
    "        score = va_f1m  # минимально и стабильно\n",
    "        sch.step(score)\n",
    "\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "        print(f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} tr={tr_loss:.4f} va={va_loss:.4f} f1m={va_f1m:.3f} auc={va_auc:.3f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(\n",
    "        model, wrap_loader_for_stage(te_loader, stage_name), loss_fn\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": best_score,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_f1m\": te_f1m,\n",
    "        \"test_auc\": te_auc,\n",
    "        \"test_cm\": te_cm,\n",
    "        \"hist\": hist,\n",
    "        \"test_y\": te_y,\n",
    "        \"test_prob\": te_prob,\n",
    "        \"test_er\": te_er,\n",
    "    }\n",
    "    return model, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: PnL по порогам уверенности (two-stage)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade,          # (N,2) softmax: [:,1]=p_trade\n",
    "    prob_dir,            # (N,2) softmax: [:,1]=p_up\n",
    "    exit_ret,            # (N,) realized log-ret to TB exit\n",
    "    thr_trade: float,\n",
    "    thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:,1]\n",
    "    p_up = prob_dir[:,1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (cost_bps * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(exit_ret),\n",
    "        \"n_trades\": int(trade_mask.sum()),\n",
    "        \"trade_rate\": float(trade_mask.mean()),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg):\n",
    "    rows = []\n",
    "    for thr_t in cfg[\"thr_trade_grid\"]:\n",
    "        for thr_d in cfg[\"thr_dir_grid\"]:\n",
    "            m = two_stage_pnl_by_threshold(\n",
    "                prob_trade=prob_trade,\n",
    "                prob_dir=prob_dir,\n",
    "                exit_ret=exit_ret,\n",
    "                thr_trade=thr_t,\n",
    "                thr_dir=thr_d,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "            )\n",
    "            rows.append({\"thr_trade\":thr_t, \"thr_dir\":thr_d, **m})\n",
    "    return pd.DataFrame(rows).sort_values([\"pnl_mean\",\"pnl_sum\"], ascending=False)\n",
    "\n",
    "print(\"Two-stage PnL threshold utils ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 8386 1677 1677\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.6716 va=0.8684 f1m=0.348 auc=0.485\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.5983 va=0.8924 f1m=0.318 auc=0.473\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.5771 va=0.8433 f1m=0.396 auc=0.476\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.5722 va=0.9095 f1m=0.305 auc=0.476\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5588 va=0.8786 f1m=0.369 auc=0.475\n",
      "[trade] ep 06 lr=2.00e-04 tr=0.5492 va=0.9260 f1m=0.348 auc=0.472\n",
      "[trade] ep 07 lr=2.00e-04 tr=0.5360 va=0.9298 f1m=0.378 auc=0.445\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.4997 va=1.1444 f1m=0.332 auc=0.425\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.4454 va=1.1094 f1m=0.390 auc=0.434\n",
      "[trade] ep 10 lr=1.00e-04 tr=0.3912 va=1.1855 f1m=0.415 auc=0.465\n",
      "[trade] ep 11 lr=1.00e-04 tr=0.3404 va=1.2387 f1m=0.434 auc=0.512\n",
      "[trade] ep 12 lr=1.00e-04 tr=0.3049 va=1.4505 f1m=0.382 auc=0.526\n",
      "[trade] ep 13 lr=1.00e-04 tr=0.2706 va=1.5379 f1m=0.406 auc=0.506\n",
      "[trade] ep 14 lr=1.00e-04 tr=0.2549 va=1.6032 f1m=0.378 auc=0.500\n",
      "[trade] ep 15 lr=1.00e-04 tr=0.2414 va=1.6282 f1m=0.413 auc=0.499\n",
      "[trade] ep 16 lr=5.00e-05 tr=0.2244 va=1.6656 f1m=0.393 auc=0.494\n",
      "[trade] ep 17 lr=5.00e-05 tr=0.2109 va=2.0256 f1m=0.349 auc=0.470\n",
      "[trade] ep 18 lr=5.00e-05 tr=0.2041 va=1.9319 f1m=0.366 auc=0.486\n",
      "[trade] ep 19 lr=5.00e-05 tr=0.1947 va=1.8285 f1m=0.371 auc=0.493\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.8400 va=0.6997 f1m=0.523 auc=0.520\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7306 va=0.7239 f1m=0.499 auc=0.534\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.7078 va=0.7054 f1m=0.520 auc=0.538\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.6887 va=0.7059 f1m=0.522 auc=0.524\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6624 va=0.7321 f1m=0.458 auc=0.514\n",
      "[dir] ep 06 lr=1.00e-04 tr=0.6506 va=0.7346 f1m=0.460 auc=0.505\n",
      "[dir] ep 07 lr=1.00e-04 tr=0.6418 va=0.7433 f1m=0.446 auc=0.505\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6279 va=0.7575 f1m=0.430 auc=0.507\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.6294 va=0.7467 f1m=0.454 auc=0.506\n",
      "PnL on test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0001719191495794803 | trades= 642.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 10063 1677 1677\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.6973 va=0.7276 f1m=0.507 auc=0.537\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.6198 va=0.7324 f1m=0.506 auc=0.527\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.6012 va=0.7287 f1m=0.500 auc=0.521\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.5794 va=0.7497 f1m=0.499 auc=0.518\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5652 va=0.7662 f1m=0.496 auc=0.503\n",
      "[trade] ep 06 lr=1.00e-04 tr=0.5280 va=0.9140 f1m=0.428 auc=0.439\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.4453 va=0.9951 f1m=0.457 auc=0.435\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.3884 va=1.0572 f1m=0.458 auc=0.439\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.3735 va=1.1400 f1m=0.459 auc=0.437\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.7788 va=0.6445 f1m=0.443 auc=0.489\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.6927 va=0.6859 f1m=0.481 auc=0.486\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.6814 va=0.6745 f1m=0.472 auc=0.479\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.6533 va=0.6855 f1m=0.468 auc=0.487\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6430 va=0.7158 f1m=0.463 auc=0.488\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6313 va=0.7546 f1m=0.468 auc=0.477\n",
      "[dir] ep 07 lr=1.00e-04 tr=0.6098 va=0.7771 f1m=0.473 auc=0.492\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6003 va=0.8015 f1m=0.482 auc=0.497\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.5863 va=0.8157 f1m=0.481 auc=0.505\n",
      "[dir] ep 10 lr=1.00e-04 tr=0.5674 va=0.8665 f1m=0.481 auc=0.513\n",
      "[dir] ep 11 lr=1.00e-04 tr=0.5332 va=0.9387 f1m=0.487 auc=0.523\n",
      "[dir] ep 12 lr=1.00e-04 tr=0.5054 va=1.0407 f1m=0.472 auc=0.531\n",
      "[dir] ep 13 lr=1.00e-04 tr=0.4670 va=1.2290 f1m=0.413 auc=0.543\n",
      "[dir] ep 14 lr=1.00e-04 tr=0.4138 va=1.5044 f1m=0.337 auc=0.545\n",
      "[dir] ep 15 lr=1.00e-04 tr=0.3416 va=1.5342 f1m=0.398 auc=0.605\n",
      "[dir] ep 16 lr=5.00e-05 tr=0.3076 va=2.0439 f1m=0.266 auc=0.515\n",
      "[dir] ep 17 lr=5.00e-05 tr=0.2589 va=2.0908 f1m=0.274 auc=0.508\n",
      "[dir] ep 18 lr=5.00e-05 tr=0.2393 va=1.9858 f1m=0.354 auc=0.548\n",
      "[dir] ep 19 lr=5.00e-05 tr=0.2175 va=2.1154 f1m=0.312 auc=0.535\n",
      "PnL on test: | thr_trade= 0.7 | thr_dir= 0.65 | pnl_mean= -4.4413493014872074e-05 | trades= 72.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 11740 1677 1677\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.6916 va=0.7186 f1m=0.495 auc=0.476\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.6326 va=0.6658 f1m=0.501 auc=0.469\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.6062 va=0.6862 f1m=0.513 auc=0.476\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.5884 va=0.6626 f1m=0.546 auc=0.489\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5337 va=0.6380 f1m=0.568 auc=0.517\n",
      "[trade] ep 06 lr=2.00e-04 tr=0.4669 va=0.6311 f1m=0.573 auc=0.538\n",
      "[trade] ep 07 lr=2.00e-04 tr=0.4135 va=0.7354 f1m=0.569 auc=0.511\n",
      "[trade] ep 08 lr=2.00e-04 tr=0.3616 va=1.1616 f1m=0.494 auc=0.504\n",
      "[trade] ep 09 lr=2.00e-04 tr=0.3580 va=0.8887 f1m=0.572 auc=0.487\n",
      "[trade] ep 10 lr=2.00e-04 tr=0.3052 va=1.0299 f1m=0.535 auc=0.488\n",
      "[trade] ep 11 lr=1.00e-04 tr=0.2855 va=1.1484 f1m=0.528 auc=0.471\n",
      "[trade] ep 12 lr=1.00e-04 tr=0.2574 va=1.2355 f1m=0.519 auc=0.485\n",
      "[trade] ep 13 lr=1.00e-04 tr=0.2476 va=1.2772 f1m=0.500 auc=0.498\n",
      "[trade] ep 14 lr=1.00e-04 tr=0.2316 va=1.2961 f1m=0.505 auc=0.488\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.7616 va=0.8061 f1m=0.358 auc=0.525\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.6979 va=0.8051 f1m=0.330 auc=0.481\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.6827 va=0.7953 f1m=0.339 auc=0.469\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.6667 va=0.8045 f1m=0.329 auc=0.469\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6560 va=0.7723 f1m=0.403 auc=0.478\n",
      "[dir] ep 06 lr=2.00e-04 tr=0.6527 va=0.8132 f1m=0.353 auc=0.475\n",
      "[dir] ep 07 lr=2.00e-04 tr=0.6324 va=0.8531 f1m=0.342 auc=0.476\n",
      "[dir] ep 08 lr=2.00e-04 tr=0.6313 va=0.8016 f1m=0.413 auc=0.486\n",
      "[dir] ep 09 lr=2.00e-04 tr=0.5982 va=0.8214 f1m=0.423 auc=0.479\n",
      "[dir] ep 10 lr=2.00e-04 tr=0.5761 va=0.9182 f1m=0.381 auc=0.457\n",
      "[dir] ep 11 lr=2.00e-04 tr=0.5253 va=0.9337 f1m=0.455 auc=0.451\n",
      "[dir] ep 12 lr=2.00e-04 tr=0.3958 va=1.4557 f1m=0.311 auc=0.343\n",
      "[dir] ep 13 lr=2.00e-04 tr=0.2284 va=1.9382 f1m=0.274 auc=0.292\n",
      "[dir] ep 14 lr=2.00e-04 tr=0.2107 va=1.8365 f1m=0.347 auc=0.317\n",
      "[dir] ep 15 lr=2.00e-04 tr=0.1349 va=1.6973 f1m=0.433 auc=0.391\n",
      "[dir] ep 16 lr=1.00e-04 tr=0.1437 va=2.2127 f1m=0.299 auc=0.336\n",
      "[dir] ep 17 lr=1.00e-04 tr=0.0953 va=2.1001 f1m=0.399 auc=0.362\n",
      "[dir] ep 18 lr=1.00e-04 tr=0.1013 va=2.1089 f1m=0.407 auc=0.376\n",
      "[dir] ep 19 lr=1.00e-04 tr=0.0909 va=1.8064 f1m=0.486 auc=0.439\n",
      "[dir] ep 20 lr=1.00e-04 tr=0.0882 va=2.0980 f1m=0.445 auc=0.388\n",
      "[dir] ep 21 lr=1.00e-04 tr=0.0759 va=1.9872 f1m=0.483 auc=0.416\n",
      "[dir] ep 22 lr=1.00e-04 tr=0.0624 va=2.2408 f1m=0.437 auc=0.410\n",
      "[dir] ep 23 lr=1.00e-04 tr=0.0625 va=2.3468 f1m=0.442 auc=0.412\n",
      "[dir] ep 24 lr=5.00e-05 tr=0.0715 va=2.2148 f1m=0.476 auc=0.418\n",
      "[dir] ep 25 lr=5.00e-05 tr=0.0533 va=2.2821 f1m=0.453 auc=0.404\n",
      "[dir] ep 26 lr=5.00e-05 tr=0.0616 va=2.3418 f1m=0.436 auc=0.395\n",
      "[dir] ep 27 lr=5.00e-05 tr=0.0551 va=2.3353 f1m=0.460 auc=0.406\n",
      "PnL on test: | thr_trade= 0.7 | thr_dir= 0.7 | pnl_mean= -0.0005283327191136777 | trades= 599.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 13417 1677 1677\n",
      "[trade] ep 01 lr=2.00e-04 tr=0.7115 va=0.8361 f1m=0.425 auc=0.393\n",
      "[trade] ep 02 lr=2.00e-04 tr=0.6473 va=0.8352 f1m=0.403 auc=0.370\n",
      "[trade] ep 03 lr=2.00e-04 tr=0.6264 va=0.7972 f1m=0.367 auc=0.347\n",
      "[trade] ep 04 lr=2.00e-04 tr=0.6064 va=0.8629 f1m=0.390 auc=0.355\n",
      "[trade] ep 05 lr=2.00e-04 tr=0.5936 va=0.8813 f1m=0.391 auc=0.365\n",
      "[trade] ep 06 lr=1.00e-04 tr=0.5603 va=0.8714 f1m=0.366 auc=0.350\n",
      "[trade] ep 07 lr=1.00e-04 tr=0.4874 va=1.1466 f1m=0.363 auc=0.324\n",
      "[trade] ep 08 lr=1.00e-04 tr=0.4351 va=1.1216 f1m=0.389 auc=0.343\n",
      "[trade] ep 09 lr=1.00e-04 tr=0.4057 va=1.2212 f1m=0.416 auc=0.341\n",
      "[dir] ep 01 lr=2.00e-04 tr=0.7896 va=0.8286 f1m=0.313 auc=0.375\n",
      "[dir] ep 02 lr=2.00e-04 tr=0.7030 va=0.8154 f1m=0.286 auc=0.376\n",
      "[dir] ep 03 lr=2.00e-04 tr=0.6916 va=0.8397 f1m=0.217 auc=0.386\n",
      "[dir] ep 04 lr=2.00e-04 tr=0.6794 va=0.8192 f1m=0.244 auc=0.355\n",
      "[dir] ep 05 lr=2.00e-04 tr=0.6654 va=0.8395 f1m=0.250 auc=0.327\n",
      "[dir] ep 06 lr=1.00e-04 tr=0.6563 va=0.8429 f1m=0.294 auc=0.355\n",
      "[dir] ep 07 lr=1.00e-04 tr=0.6482 va=0.8432 f1m=0.305 auc=0.353\n",
      "[dir] ep 08 lr=1.00e-04 tr=0.6357 va=0.7911 f1m=0.362 auc=0.358\n",
      "[dir] ep 09 lr=1.00e-04 tr=0.6273 va=0.8700 f1m=0.318 auc=0.351\n",
      "[dir] ep 10 lr=1.00e-04 tr=0.6061 va=0.9297 f1m=0.309 auc=0.370\n",
      "[dir] ep 11 lr=1.00e-04 tr=0.5828 va=0.8841 f1m=0.338 auc=0.374\n",
      "[dir] ep 12 lr=1.00e-04 tr=0.5482 va=0.7312 f1m=0.420 auc=0.368\n",
      "[dir] ep 13 lr=1.00e-04 tr=0.5003 va=1.0556 f1m=0.339 auc=0.339\n",
      "[dir] ep 14 lr=1.00e-04 tr=0.4274 va=0.9348 f1m=0.375 auc=0.299\n",
      "[dir] ep 15 lr=1.00e-04 tr=0.3728 va=1.0351 f1m=0.392 auc=0.327\n",
      "[dir] ep 16 lr=1.00e-04 tr=0.3192 va=1.1624 f1m=0.369 auc=0.316\n",
      "[dir] ep 17 lr=5.00e-05 tr=0.2957 va=1.6169 f1m=0.305 auc=0.308\n",
      "[dir] ep 18 lr=5.00e-05 tr=0.2606 va=1.7322 f1m=0.282 auc=0.278\n",
      "[dir] ep 19 lr=5.00e-05 tr=0.2480 va=1.7011 f1m=0.297 auc=0.278\n",
      "[dir] ep 20 lr=5.00e-05 tr=0.2301 va=1.5716 f1m=0.343 auc=0.331\n",
      "PnL on test: | thr_trade= 0.7 | thr_dir= 0.7 | pnl_mean= -0.00040011756937019527 | trades= 141.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.288304</td>\n",
       "      <td>0.444498</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0.382826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472549</td>\n",
       "      <td>0.399464</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.65</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.042934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.358705</td>\n",
       "      <td>0.438351</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>599.0</td>\n",
       "      <td>0.357185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.655167</td>\n",
       "      <td>0.380466</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.084079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.288304      0.444498       0.000172             0.5   \n",
       "1     2        0.472549      0.399464      -0.000044             0.7   \n",
       "2     3        0.358705      0.438351      -0.000528             0.7   \n",
       "3     4        0.655167      0.380466      -0.000400             0.7   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0          0.50          642.0         0.382826  \n",
       "1          0.65           72.0         0.042934  \n",
       "2          0.70          599.0         0.357185  \n",
       "3          0.70          141.0         0.084079  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "fold                 2.500000\n",
      "trade_test_f1m       0.443681\n",
      "dir_test_f1m         0.415695\n",
      "best_pnl_mean       -0.000200\n",
      "best_thr_trade       0.650000\n",
      "best_thr_dir         0.637500\n",
      "n_trades_best      363.500000\n",
      "trade_rate_best      0.216756\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\"\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    # если в какой-то части trade почти нет — пропускаем fold direction\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\"\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on TEST (в sample-space idx_te)\n",
    "    # Получим probs trade на idx_te (из r_trade) и probs dir на idx_te тоже нужно.\n",
    "    # r_dir тестился на idx_te_T, поэтому мы посчитаем prob_dir на idx_te через прогон модели по idx_te (без фильтра),\n",
    "    # чтобы sweep был по всем точкам (trade-маска будет от модели trade).\n",
    "\n",
    "    # helper: get probs on arbitrary indices\n",
    "    @torch.no_grad()\n",
    "    def predict_probs_on_indices(model, X_scaled, edge_feat, indices, stage_for_label=\"trade\"):\n",
    "        ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, CFG[\"lookback\"])\n",
    "        loader = DataLoader(ds, batch_size=CFG[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "        model.eval()\n",
    "        probs = []\n",
    "        ers = []\n",
    "        for x,e,yt,yd,er in loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            logits = model(x,e,EDGE_INDEX.to(DEVICE))\n",
    "            p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            probs.append(p)\n",
    "            ers.append(er.cpu().numpy())\n",
    "        return np.concatenate(probs), np.concatenate(ers)\n",
    "\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te)\n",
    "    prob_dir_te, _ = predict_probs_on_indices(m_dir, X_scaled, edge_feat, idx_te)\n",
    "\n",
    "    # exit_ret on same points (already in er_te)\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN:\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
