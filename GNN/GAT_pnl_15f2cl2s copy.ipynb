{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a317d0",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e40529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "EDGE_INDEX: [[0, 1], [0, 2], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: imports + reproducibility + GLOBAL config\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(100)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# -------------------------------\n",
    "# GLOBAL CONFIG (всё тут)\n",
    "# -------------------------------\n",
    "CFG = {\n",
    "    # data\n",
    "    \"freq\": \"5min\",\n",
    "    \"data_dir\": Path(\"../dataset\"),  \n",
    "    # NEW: holdout final test split (по времени, на sample-space)\n",
    "    \"final_test_frac\": 0.10, \n",
    "\n",
    "    \"book_levels\": 15,         # сколько уровней стакана грузим\n",
    "    \"top_levels\": 5,           # DI_L0..DI_L4\n",
    "    \"near_levels\": 5,          # near=0..4, far=5..14\n",
    "\n",
    "    # walk-forward windows (в sample-space)\n",
    "    \"train_min_frac\": 0.50,\n",
    "    \"val_window_frac\": 0.10,\n",
    "    \"test_window_frac\": 0.10,\n",
    "    \"step_window_frac\": 0.10,\n",
    "\n",
    "    # scaling\n",
    "    \"max_abs_feat\": 10.0,\n",
    "\n",
    "    # correlations\n",
    "    \"corr_windows\": [6, 12, 24, 48, 84],  # 30m,1h,2h,4h,7h\n",
    "    \"edges\": [(\"ADA\",\"BTC\"), (\"ADA\",\"ETH\"), (\"ETH\",\"BTC\")],\n",
    "\n",
    "    # triple-barrier (labels)\n",
    "    \"tb_horizon\": 1*12,       # 1h     # нужен для sample_t (чтобы TB-exit не вылезал за конец)\n",
    "    \"lookback\": 7*12,   \n",
    "    \"tb_pt_mult\": 1.2,\n",
    "    \"tb_sl_mult\": 1.1,\n",
    "    \"tb_min_barrier\": 0.001,\n",
    "    \"tb_max_barrier\": 0.006,\n",
    "    # training (общие)\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 2e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"dropout\": 0.2,\n",
    "    \"hidden\": 64,\n",
    "    \"gnn_layers\": 2,\n",
    "    \"lstm_hidden\": 64,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"use_amp\": True,\n",
    "\n",
    "    \"temporal_mode\": \"transformer\",   # \"transformer\" | \"attnpool\"\n",
    "\n",
    "    # transformer params\n",
    "    \"n_heads\": 4,          # 2-4 обычно ок при hidden=64\n",
    "    \"n_layers\": 1,         # 1-2 слоя\n",
    "    \"attn_dropout\": 0.2,   # dropout внутри attention/ffn трансформера\n",
    "    \"use_posenc\": True,    # positional encoding on/off\n",
    "\n",
    "    # trading eval\n",
    "    \"cost_bps\": 2.0,\n",
    "\n",
    "    # confidence thresholds (для PnL по порогу)\n",
    "    \"thr_trade_grid\": [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    \"thr_dir_grid\":   [0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "\n",
    "    # ---- PnL proxy during DIR training (grid selector)\n",
    "    # можно сделать уже/шире, но по умолчанию переиспользуем thr_*_grid\n",
    "    \"proxy_thr_trade_grid\": None,  # None -> использовать thr_trade_grid\n",
    "    \"proxy_thr_dir_grid\":   None,  # None -> использовать thr_dir_grid\n",
    "    \"proxy_min_trades\": 50,        # защита от \"лучший pnl = 0 потому что 0 трейдов\"\n",
    "}\n",
    "\n",
    "ASSETS = [\"ADA\", \"BTC\", \"ETH\"]\n",
    "ASSET2IDX = {a:i for i,a in enumerate(ASSETS)}\n",
    "TARGET_ASSET = \"ETH\"\n",
    "TARGET_NODE = ASSET2IDX[TARGET_ASSET]\n",
    "\n",
    "EDGES = CFG[\"edges\"]\n",
    "EDGE_INDEX = torch.tensor([[ASSET2IDX[s], ASSET2IDX[t]] for (s,t) in EDGES], dtype=torch.long)  # [E,2]\n",
    "print(\"EDGE_INDEX:\", EDGE_INDEX.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7abcf5",
   "metadata": {},
   "source": [
    "## 1. load data + basic returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c84cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df: (2693, 106)\n",
      "Example columns: ['timestamp', 'ADA', 'spread_ADA', 'buys_ADA', 'sells_ADA', 'bids_vol_ADA_0', 'bids_vol_ADA_1', 'bids_vol_ADA_2', 'bids_vol_ADA_3', 'bids_vol_ADA_4', 'bids_vol_ADA_5', 'bids_vol_ADA_6', 'bids_vol_ADA_7', 'bids_vol_ADA_8', 'bids_vol_ADA_9', 'bids_vol_ADA_10', 'bids_vol_ADA_11', 'bids_vol_ADA_12', 'bids_vol_ADA_13', 'bids_vol_ADA_14', 'asks_vol_ADA_0', 'asks_vol_ADA_1', 'asks_vol_ADA_2', 'asks_vol_ADA_3', 'asks_vol_ADA_4']\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: load data + log returns (без target) + все уровни стакана\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def load_asset(asset: str, freq: str, data_dir: Path, book_levels: int, part = [0,100]) -> pd.DataFrame:\n",
    "    path = data_dir / f\"{asset}_{freq}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.iloc[int(len(df)*part[0]/100) : int(len(df)*part[1]/100)]\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"system_time\"]).dt.round(\"min\")\n",
    "    df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "\n",
    "    bid_cols = [f\"bids_notional_{i}\" for i in range(book_levels)]\n",
    "    ask_cols = [f\"asks_notional_{i}\" for i in range(book_levels)]\n",
    "\n",
    "    needed = [\"midpoint\", \"spread\", \"buys\", \"sells\"] + bid_cols + ask_cols\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{asset}: missing columns in CSV: {missing[:10]}{'...' if len(missing) > 10 else ''}\")\n",
    "\n",
    "    return df[needed]\n",
    "\n",
    "\n",
    "def load_all_assets() -> pd.DataFrame:\n",
    "    freq = CFG[\"freq\"]\n",
    "    data_dir = CFG[\"data_dir\"]\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "\n",
    "    def rename_asset_cols(df_one: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "        rename_map = {\n",
    "            \"midpoint\": asset,\n",
    "            \"buys\": f\"buys_{asset}\",\n",
    "            \"sells\": f\"sells_{asset}\",\n",
    "            \"spread\": f\"spread_{asset}\",\n",
    "        }\n",
    "        for i in range(book_levels):\n",
    "            rename_map[f\"bids_notional_{i}\"] = f\"bids_vol_{asset}_{i}\"\n",
    "            rename_map[f\"asks_notional_{i}\"] = f\"asks_vol_{asset}_{i}\"\n",
    "        return df_one.rename(columns=rename_map)\n",
    "\n",
    "    df_ADA = rename_asset_cols(load_asset(\"ADA\", freq, data_dir, book_levels, part = [0, 80]), \"ADA\")\n",
    "    df_BTC = rename_asset_cols(load_asset(\"BTC\", freq, data_dir, book_levels, part = [0, 80]), \"BTC\")\n",
    "    df_ETH = rename_asset_cols(load_asset(\"ETH\", freq, data_dir, book_levels, part = [0, 80]), \"ETH\")\n",
    "\n",
    "    df = df_ADA.join(df_BTC).join(df_ETH)\n",
    "    df = df.reset_index()  # timestamp column remains\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_all_assets()\n",
    "T = len(df)\n",
    "\n",
    "# log returns\n",
    "for a in ASSETS:\n",
    "    df[f\"lr_{a}\"] = np.log(df[a]).diff().fillna(0.0)\n",
    "\n",
    "print(\"Loaded df:\", df.shape)\n",
    "print(\"Example columns:\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f68a9e",
   "metadata": {},
   "source": [
    "## 2. multi-window correlations → edge features (T,E,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_array shape: (2693, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: multi-window correlations -> corr_array (T,E,W)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "candidate_windows = CFG[\"corr_windows\"]\n",
    "edges = EDGES\n",
    "\n",
    "n_w = len(candidate_windows)\n",
    "n_edges = len(edges)\n",
    "T = len(df)\n",
    "\n",
    "corr_array = np.zeros((T, n_edges, n_w), dtype=np.float32)\n",
    "\n",
    "for wi, w in enumerate(candidate_windows):\n",
    "    r_ADA_BTC = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "    r_ADA_ETH = df[\"lr_ADA\"].rolling(w, min_periods=1).corr(df[\"lr_ETH\"])\n",
    "    r_ETH_BTC = df[\"lr_ETH\"].rolling(w, min_periods=1).corr(df[\"lr_BTC\"])\n",
    "\n",
    "    corr_array[:, 0, wi] = np.nan_to_num(r_ADA_BTC)\n",
    "    corr_array[:, 1, wi] = np.nan_to_num(r_ADA_ETH)\n",
    "    corr_array[:, 2, wi] = np.nan_to_num(r_ETH_BTC)\n",
    "\n",
    "print(\"corr_array shape:\", corr_array.shape)  # (T,E,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923c7ce",
   "metadata": {},
   "source": [
    "## 3. triple-barrier → y_tb + exit_ret → two-stage labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2effb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB dist [down,flat,up]: [ 655 1311  727]\n",
      "Trade ratio: 0.5131823245451169\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: triple-barrier labels -> y_tb + exit_ret + two-stage labels\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def triple_barrier_labels_from_lr(\n",
    "    lr: pd.Series,\n",
    "    horizon: int,\n",
    "    vol_window: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    min_barrier: float,\n",
    "    max_barrier: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      y_tb: {0=down, 1=flat/no-trade, 2=up}\n",
    "      exit_ret: realized log-return to exit (tp/sl/timeout)\n",
    "      exit_t: exit index\n",
    "      thr: barrier per t\n",
    "    No leakage: vol is shift(1).\n",
    "    \"\"\"\n",
    "    lr = lr.astype(float).copy()\n",
    "    T = len(lr)\n",
    "\n",
    "    vol = lr.rolling(vol_window, min_periods=max(10, vol_window//10)).std().shift(1)\n",
    "    thr = (vol * np.sqrt(horizon)).clip(lower=min_barrier, upper=max_barrier)\n",
    "\n",
    "    y = np.ones(T, dtype=np.int64)\n",
    "    exit_ret = np.zeros(T, dtype=np.float32)\n",
    "    exit_t = np.arange(T, dtype=np.int64)\n",
    "\n",
    "    lr_np = lr.fillna(0.0).to_numpy(dtype=np.float64)\n",
    "    thr_np = thr.fillna(min_barrier).to_numpy(dtype=np.float64)\n",
    "\n",
    "    for t in range(T - horizon - 1):\n",
    "        up = pt_mult * thr_np[t]\n",
    "        dn = -sl_mult * thr_np[t]\n",
    "\n",
    "        cum = 0.0\n",
    "        hit = 1\n",
    "        et = t + horizon\n",
    "        er = 0.0\n",
    "\n",
    "        for dt in range(1, horizon + 1):\n",
    "            cum += lr_np[t + dt]\n",
    "            if cum >= up:\n",
    "                hit = 2\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "            if cum <= dn:\n",
    "                hit = 0\n",
    "                et = t + dt\n",
    "                er = cum\n",
    "                break\n",
    "\n",
    "        if hit == 1:\n",
    "            er = float(np.sum(lr_np[t+1:t+horizon+1]))\n",
    "            et = t + horizon\n",
    "\n",
    "        y[t] = hit\n",
    "        exit_ret[t] = er\n",
    "        exit_t[t] = et\n",
    "\n",
    "    return y, exit_ret, exit_t, thr_np\n",
    "\n",
    "# --- build TB on ETH ---\n",
    "y_tb, exit_ret, exit_t, thr = triple_barrier_labels_from_lr(\n",
    "    df[\"lr_ETH\"],\n",
    "    horizon=1*12, \n",
    "    vol_window=7*12,\n",
    "    pt_mult=1.2,\n",
    "    sl_mult=1.1,\n",
    "    min_barrier=0.001,\n",
    "    max_barrier=0.006,\n",
    ")\n",
    "\n",
    "# two-stage labels\n",
    "y_trade = (y_tb != 1).astype(np.int64)      # 1=trade, 0=no-trade\n",
    "y_dir   = (y_tb == 2).astype(np.int64)      # 1=up, 0=down (для trade-сэмплов)\n",
    "\n",
    "print(\"TB dist [down,flat,up]:\", np.bincount(y_tb, minlength=3))\n",
    "print(\"Trade ratio:\", y_trade.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413df19",
   "metadata": {},
   "source": [
    "## 4. build node tensor + edge tensor + sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0565bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_node_raw: (2693, 3, 15) edge_feat: (2693, 3, 5)\n",
      "node_feat_names: ['lr', 'spread', 'log_buys', 'log_sells', 'ofi', 'DI_15', 'DI_L0', 'DI_L1', 'DI_L2', 'DI_L3', 'DI_L4', 'near_ratio_bid', 'near_ratio_ask', 'di_near', 'di_far']\n",
      "n_samples: 2597 t range: 83 2679\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: build node features (T,N,F) + edge features (T,E,W) + sample_t\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def safe_log1p(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.maximum(x, 0.0))\n",
    "\n",
    "def build_node_tensor(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Фичи на asset:\n",
    "      lr, spread,\n",
    "      log_buys, log_sells, ofi,\n",
    "      DI_15,\n",
    "      DI_L0..DI_L4,\n",
    "      near_ratio_bid, near_ratio_ask,\n",
    "      di_near, di_far\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    feat_names = [\n",
    "        \"lr\", \"spread\",\n",
    "        \"log_buys\", \"log_sells\", \"ofi\",\n",
    "        \"DI_15\",\n",
    "        \"DI_L0\", \"DI_L1\", \"DI_L2\", \"DI_L3\", \"DI_L4\",\n",
    "        \"near_ratio_bid\", \"near_ratio_ask\",\n",
    "        \"di_near\", \"di_far\",\n",
    "    ]\n",
    "\n",
    "    book_levels = CFG[\"book_levels\"]\n",
    "    top_k = CFG[\"top_levels\"]     # 5\n",
    "    near_k = CFG[\"near_levels\"]   # 5\n",
    "    far_k = book_levels - near_k\n",
    "    if far_k <= 0:\n",
    "        raise ValueError(\"CFG['near_levels'] must be < CFG['book_levels']\")\n",
    "\n",
    "    for a in ASSETS:\n",
    "        lr = df[f\"lr_{a}\"].values.astype(np.float32)\n",
    "        spread = df[f\"spread_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        buys = df[f\"buys_{a}\"].values.astype(np.float32)\n",
    "        sells = df[f\"sells_{a}\"].values.astype(np.float32)\n",
    "\n",
    "        log_buys = safe_log1p(buys).astype(np.float32)\n",
    "        log_sells = safe_log1p(sells).astype(np.float32)\n",
    "\n",
    "        ofi = ((buys - sells) / (buys + sells + EPS)).astype(np.float32)\n",
    "\n",
    "        # уровни стакана\n",
    "        bids_lvls = np.stack([df[f\"bids_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "        asks_lvls = np.stack([df[f\"asks_vol_{a}_{i}\"].values.astype(np.float32) for i in range(book_levels)], axis=1)  # (T,15)\n",
    "\n",
    "        bid_sum_15 = bids_lvls.sum(axis=1)\n",
    "        ask_sum_15 = asks_lvls.sum(axis=1)\n",
    "        DI_15 = ((bid_sum_15 - ask_sum_15) / (bid_sum_15 + ask_sum_15 + EPS)).astype(np.float32)\n",
    "\n",
    "        # DI_L0..DI_L4\n",
    "        di_levels = []\n",
    "        for i in range(top_k):\n",
    "            b = bids_lvls[:, i]\n",
    "            s = asks_lvls[:, i]\n",
    "            di_levels.append(((b - s) / (b + s + EPS)).astype(np.float32))\n",
    "        DI_L0_4 = np.stack(di_levels, axis=1)  # (T,5)\n",
    "\n",
    "        # near vs far\n",
    "        bid_near = bids_lvls[:, :near_k].sum(axis=1)\n",
    "        ask_near = asks_lvls[:, :near_k].sum(axis=1)\n",
    "        bid_far = bids_lvls[:, near_k:].sum(axis=1)\n",
    "        ask_far = asks_lvls[:, near_k:].sum(axis=1)\n",
    "\n",
    "        near_ratio_bid = (bid_near / (bid_far + EPS)).astype(np.float32)\n",
    "        near_ratio_ask = (ask_near / (ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        di_near = ((bid_near - ask_near) / (bid_near + ask_near + EPS)).astype(np.float32)\n",
    "        di_far = ((bid_far - ask_far) / (bid_far + ask_far + EPS)).astype(np.float32)\n",
    "\n",
    "        Xa = np.column_stack([\n",
    "            lr, spread,\n",
    "            log_buys, log_sells, ofi,\n",
    "            DI_15,\n",
    "            DI_L0_4[:, 0], DI_L0_4[:, 1], DI_L0_4[:, 2], DI_L0_4[:, 3], DI_L0_4[:, 4],\n",
    "            near_ratio_bid, near_ratio_ask,\n",
    "            di_near, di_far\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        feats.append(Xa)\n",
    "\n",
    "    X = np.stack(feats, axis=1).astype(np.float32)  # (T,N,F)\n",
    "    return X, feat_names\n",
    "\n",
    "\n",
    "X_node_raw, node_feat_names = build_node_tensor(df)\n",
    "edge_feat = np.nan_to_num(corr_array.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "T = len(df)\n",
    "L = CFG[\"lookback\"]\n",
    "H = CFG[\"tb_horizon\"]\n",
    "\n",
    "# sample_t: чтобы можно было брать окно [t-L+1 ... t] и иметь будущий TB-exit без выхода за данные\n",
    "t_min = L - 1\n",
    "t_max = T - H - 2\n",
    "sample_t = np.arange(t_min, t_max + 1)\n",
    "n_samples = len(sample_t)\n",
    "\n",
    "print(\"X_node_raw:\", X_node_raw.shape, \"edge_feat:\", edge_feat.shape)\n",
    "print(\"node_feat_names:\", node_feat_names)\n",
    "print(\"n_samples:\", n_samples, \"t range:\", sample_t[0], sample_t[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb5de4",
   "metadata": {},
   "source": [
    "## Train (folds) - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9bad799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout split:\n",
      "  n_samples total: 2597\n",
      "  n_samples CV   : 2337 (90.0%)\n",
      "  n_samples FINAL: 260 (10.0%)\n",
      "  CV range   : 0 2336\n",
      "  FINAL range: 2337 2596\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: final holdout split (90% CV + 10% final test), time-ordered\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_final_holdout_split(n_samples: int, final_test_frac: float):\n",
    "    if not (0.0 < final_test_frac < 0.5):\n",
    "        raise ValueError(\"final_test_frac should be in (0, 0.5)\")\n",
    "\n",
    "    n_final = max(1, int(round(final_test_frac * n_samples)))\n",
    "    n_cv = n_samples - n_final\n",
    "    if n_cv <= 10:\n",
    "        raise ValueError(\"Too few samples left for CV after holdout split.\")\n",
    "\n",
    "    idx_cv = np.arange(0, n_cv, dtype=np.int64)\n",
    "    idx_final = np.arange(n_cv, n_samples, dtype=np.int64)\n",
    "    return idx_cv, idx_final, n_cv, n_final\n",
    "\n",
    "idx_cv_all, idx_final_test, n_samples_cv, n_samples_final = make_final_holdout_split(\n",
    "    n_samples=n_samples,\n",
    "    final_test_frac=CFG[\"final_test_frac\"],\n",
    ")\n",
    "\n",
    "print(\"Holdout split:\")\n",
    "print(\"  n_samples total:\", n_samples)\n",
    "print(\"  n_samples CV   :\", n_samples_cv, f\"({100*(n_samples_cv/n_samples):.1f}%)\")\n",
    "print(\"  n_samples FINAL:\", n_samples_final, f\"({100*(n_samples_final/n_samples):.1f}%)\")\n",
    "print(\"  CV range   :\", idx_cv_all[0], idx_cv_all[-1])\n",
    "print(\"  FINAL range:\", idx_final_test[0], idx_final_test[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd91f31",
   "metadata": {},
   "source": [
    "\n",
    "## 5. walk-forward splits (с глобальными окнами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efe2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_folds: 4\n",
      " fold 1: train 1168 | val 233 | test 233\n",
      " fold 2: train 1401 | val 233 | test 233\n",
      " fold 3: train 1634 | val 233 | test 233\n",
      " fold 4: train 1867 | val 233 | test 233\n",
      "\n",
      "FINAL HOLDOUT:\n",
      " final_test size: 260\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: walk-forward splits (expanding train + fixed val/test) on CV-part only\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def make_walk_forward_splits(n_samples: int,\n",
    "                             train_min_frac: float,\n",
    "                             val_window_frac: float,\n",
    "                             test_window_frac: float,\n",
    "                             step_window_frac: float):\n",
    "    train_min = int(train_min_frac * n_samples)\n",
    "    val_w  = max(1, int(val_window_frac * n_samples))\n",
    "    test_w = max(1, int(test_window_frac * n_samples))\n",
    "    step_w = max(1, int(step_window_frac * n_samples))\n",
    "\n",
    "    splits = []\n",
    "    start = train_min\n",
    "    while True:\n",
    "        tr_end = start\n",
    "        va_end = tr_end + val_w\n",
    "        te_end = va_end + test_w\n",
    "        if te_end > n_samples:\n",
    "            break\n",
    "\n",
    "        idx_train = np.arange(0, tr_end, dtype=np.int64)\n",
    "        idx_val   = np.arange(tr_end, va_end, dtype=np.int64)\n",
    "        idx_test  = np.arange(va_end, te_end, dtype=np.int64)\n",
    "\n",
    "        splits.append((idx_train, idx_val, idx_test))\n",
    "        start += step_w\n",
    "\n",
    "    return splits\n",
    "\n",
    "# IMPORTANT: строим сплиты только на 90% (CV-part)\n",
    "walk_splits = make_walk_forward_splits(\n",
    "    n_samples=n_samples_cv,\n",
    "    train_min_frac=CFG[\"train_min_frac\"],\n",
    "    val_window_frac=CFG[\"val_window_frac\"],\n",
    "    test_window_frac=CFG[\"test_window_frac\"],\n",
    "    step_window_frac=CFG[\"step_window_frac\"],\n",
    ")\n",
    "\n",
    "print(\"n_folds:\", len(walk_splits))\n",
    "for i, (a, b, c) in enumerate(walk_splits):\n",
    "    print(f\" fold {i+1}: train {len(a)} | val {len(b)} | test {len(c)}\")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT:\")\n",
    "print(\" final_test size:\", len(idx_final_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb84cf3",
   "metadata": {},
   "source": [
    "## 6. Dataset + scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3e3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Dataset + scaling (shared)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "class LobGraphSequenceDataset2Stage(Dataset):\n",
    "    \"\"\"\n",
    "    Возвращает (x_seq, e_seq, y_trade, y_dir, exit_ret)\n",
    "    y_dir корректен только когда y_trade==1, но мы возвращаем всегда.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_node, E_feat, y_trade, y_dir, exit_ret, sample_t, indices, lookback):\n",
    "        self.X_node = X_node\n",
    "        self.E_feat = E_feat\n",
    "        self.y_trade = y_trade\n",
    "        self.y_dir = y_dir\n",
    "        self.exit_ret = exit_ret\n",
    "        self.sample_t = sample_t\n",
    "        self.indices = indices\n",
    "        self.L = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sidx = self.indices[i]\n",
    "        t = self.sample_t[sidx]\n",
    "        t0 = t - self.L + 1\n",
    "\n",
    "        x_seq = self.X_node[t0:t+1]     # (L,N,F)\n",
    "        e_seq = self.E_feat[t0:t+1]     # (L,E,W)\n",
    "\n",
    "        yt = self.y_trade[t]\n",
    "        yd = self.y_dir[t]\n",
    "        er = self.exit_ret[t]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_seq),\n",
    "            torch.from_numpy(e_seq),\n",
    "            torch.tensor(yt, dtype=torch.long),\n",
    "            torch.tensor(yd, dtype=torch.long),\n",
    "            torch.tensor(er, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "def collate_fn_2stage(batch):\n",
    "    xs, es, yts, yds, ers = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(xs, 0),   # (B,L,N,F)\n",
    "        torch.stack(es, 0),   # (B,L,E,W)\n",
    "        torch.stack(yts, 0),  # (B,)\n",
    "        torch.stack(yds, 0),  # (B,)\n",
    "        torch.stack(ers, 0),  # (B,)\n",
    "    )\n",
    "\n",
    "def fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train, max_abs=10.0):\n",
    "    \"\"\"\n",
    "    Fit scaler on all times up to last train sample time (без leakage).\n",
    "    \"\"\"\n",
    "    last_train_t = sample_t[idx_train[-1]]\n",
    "    train_time_mask = np.arange(0, last_train_t + 1)\n",
    "\n",
    "    X_train_time = X_node_raw[train_time_mask]  # (Ttr,N,F)\n",
    "    Ttr, N, Fdim = X_train_time.shape\n",
    "\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0))\n",
    "    scaler.fit(X_train_time.reshape(-1, Fdim))\n",
    "\n",
    "    X_scaled = scaler.transform(X_node_raw.reshape(-1, Fdim)).reshape(X_node_raw.shape).astype(np.float32)\n",
    "    X_scaled = np.clip(X_scaled, -max_abs, max_abs).astype(np.float32)\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def subset_trade_indices(indices, sample_t, y_trade):\n",
    "    \"\"\"\n",
    "    indices в sample-space -> отфильтровать те, где y_trade[t]==1\n",
    "    \"\"\"\n",
    "    tt = sample_t[indices]\n",
    "    mask = (y_trade[tt] == 1)\n",
    "    return indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bcb07",
   "metadata": {},
   "source": [
    "## 7.Model (один класс, n_classes=2) + EdgeGatedMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3999c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[smoke transformer] logits: (2, 2)\n",
      "[smoke attnpool] logits: (2, 2)\n",
      "Model ready (Attention temporal).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: GNN + Attention Temporal Encoder classifier (универсальный под 2 класса)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EdgeGatedMP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_proj = nn.Linear(in_dim, hidden)\n",
    "        self.ln0 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden + edge_dim, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden + 1)  # msg(hidden) + gate(1)\n",
    "        )\n",
    "\n",
    "        self.upd = nn.Sequential(\n",
    "            nn.Linear(2*hidden, 2*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*hidden, hidden)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward_once(self, x_t, edge_attr_t, edge_index):\n",
    "        B, N, _ = x_t.shape\n",
    "        E = edge_index.shape[0]\n",
    "\n",
    "        h = self.ln0(self.node_proj(x_t))  # (B,N,H)\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        agg = torch.zeros((B, N, h.shape[-1]), device=h.device, dtype=h.dtype)\n",
    "\n",
    "        for e in range(E):\n",
    "            src = edge_index[e, 0].item()\n",
    "            dst = edge_index[e, 1].item()\n",
    "            h_src = h[:, src, :]\n",
    "            h_dst = h[:, dst, :]\n",
    "            ea = edge_attr_t[:, e, :]\n",
    "\n",
    "            z = torch.cat([h_src, h_dst, ea], dim=-1)\n",
    "            out = self.edge_mlp(z)\n",
    "            msg = out[:, :-1]\n",
    "            gate = torch.sigmoid(out[:, -1:])\n",
    "\n",
    "            agg[:, dst, :] += msg * gate\n",
    "\n",
    "        h2 = self.upd(torch.cat([h, agg], dim=-1))\n",
    "        h2 = self.ln1(h + self.dropout(h2))\n",
    "        h2 = torch.nan_to_num(h2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return h2\n",
    "\n",
    "    def forward(self, x_seq, e_seq, edge_index):\n",
    "        B, L, N, Fin = x_seq.shape\n",
    "        h_out = []\n",
    "        for t in range(L):\n",
    "            ht = self.forward_once(x_seq[:, t, :, :], e_seq[:, t, :, :], edge_index)\n",
    "            h_out.append(ht)\n",
    "        return torch.stack(h_out, dim=1)  # (B,L,N,H)\n",
    "\n",
    "\n",
    "class SinCosPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 512):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0), persistent=False)  # (1,max_len,d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,L,D)\n",
    "        L = x.size(1)\n",
    "        if L > self.pe.size(1):\n",
    "            # на всякий случай: если L больше max_len, просто без posenc\n",
    "            return x\n",
    "        return x + self.pe[:, :L, :].to(dtype=x.dtype, device=x.device)\n",
    "\n",
    "\n",
    "class TemporalAttnPool(nn.Module):\n",
    "    \"\"\"\n",
    "    score_t = v^T tanh(W h_t)\n",
    "    weights = softmax(score_t)\n",
    "    pooled = sum_t weights_t * h_t\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(hidden, hidden, bias=True)\n",
    "        self.v = nn.Parameter(torch.empty(hidden))\n",
    "        nn.init.normal_(self.v, std=0.02)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, h_seq: torch.Tensor):\n",
    "        # h_seq: (B,L,H)\n",
    "        u = torch.tanh(self.W(h_seq))                  # (B,L,H)\n",
    "        score = torch.matmul(u, self.v)                # (B,L)\n",
    "        w = torch.softmax(score, dim=1)                # (B,L)\n",
    "        pooled = torch.sum(h_seq * w.unsqueeze(-1), dim=1)  # (B,H)\n",
    "        pooled = self.dropout(pooled)\n",
    "        return pooled, w\n",
    "\n",
    "\n",
    "class TemporalTransformerEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        n_heads: int,\n",
    "        n_layers: int,\n",
    "        attn_dropout: float,\n",
    "        use_posenc: bool,\n",
    "        max_len: int = 512,\n",
    "        pool: str = \"last\",  # \"last\" | \"attnpool\"\n",
    "        posenc_learnable: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_posenc = bool(use_posenc)\n",
    "        self.pool = pool\n",
    "\n",
    "        if self.use_posenc:\n",
    "            if posenc_learnable:\n",
    "                self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "                self.pos_drop = nn.Dropout(attn_dropout)\n",
    "            else:\n",
    "                self.pos_enc = SinCosPositionalEncoding(d_model=d_model, max_len=max_len)\n",
    "                self.pos_drop = nn.Dropout(attn_dropout)\n",
    "\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=attn_dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.enc = nn.TransformerEncoder(layer, num_layers=n_layers)\n",
    "\n",
    "        self.attnpool = None\n",
    "        if pool == \"attnpool\":\n",
    "            self.attnpool = TemporalAttnPool(hidden=d_model, dropout=attn_dropout)\n",
    "\n",
    "    def forward(self, h_seq: torch.Tensor):\n",
    "        # h_seq: (B,L,D)\n",
    "        B, L, D = h_seq.shape\n",
    "        x = h_seq\n",
    "\n",
    "        if self.use_posenc:\n",
    "            if hasattr(self, \"pos_emb\"):\n",
    "                pos = torch.arange(L, device=x.device)\n",
    "                x = x + self.pos_emb(pos).unsqueeze(0).to(dtype=x.dtype)  # (1,L,D)\n",
    "                x = self.pos_drop(x)\n",
    "            else:\n",
    "                x = self.pos_drop(self.pos_enc(x))\n",
    "\n",
    "        x = self.enc(x)  # (B,L,D)\n",
    "\n",
    "        if self.pool == \"attnpool\":\n",
    "            pooled, w = self.attnpool(x)  # pooled (B,D)\n",
    "            return pooled, w\n",
    "\n",
    "        # default: last token\n",
    "        pooled = x[:, -1, :]  # (B,D)\n",
    "        return pooled, None\n",
    "\n",
    "\n",
    "class GNN_Attn_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Drop-in replacement for GNN_LSTM_Classifier:\n",
    "      - spatial: same EdgeGatedMP stack => h (B,L,N,H)\n",
    "      - target node => h_tgt (B,L,H)\n",
    "      - temporal: CFG[\"temporal_mode\"] in {\"transformer\",\"attnpool\"}\n",
    "      - head => logits (B,2)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_in,\n",
    "        edge_dim,\n",
    "        hidden,\n",
    "        gnn_layers,\n",
    "        lstm_hidden,   # keep name for compatibility; this is head/temporal_out dim now\n",
    "        lstm_layers,   # unused but kept for drop-in\n",
    "        dropout=0.1,\n",
    "        target_node=2,\n",
    "        n_classes=2,\n",
    "        cfg=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.target_node = target_node\n",
    "        self.cfg = cfg if cfg is not None else globals().get(\"CFG\", {})\n",
    "        self.temporal_mode = self.cfg.get(\"temporal_mode\", \"transformer\")\n",
    "\n",
    "        # --- spatial stack (unchanged behavior)\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(gnn_layers):\n",
    "            in_dim = node_in if i == 0 else hidden\n",
    "            self.gnns.append(EdgeGatedMP(in_dim=in_dim, hidden=hidden, edge_dim=edge_dim, dropout=dropout))\n",
    "\n",
    "        # --- temporal encoder\n",
    "        self.temporal_proj = nn.Identity() if hidden == lstm_hidden else nn.Linear(hidden, lstm_hidden)\n",
    "\n",
    "        if self.temporal_mode == \"transformer\":\n",
    "            n_heads = int(self.cfg.get(\"n_heads\", 4))\n",
    "            n_layers = int(self.cfg.get(\"n_layers\", 1))\n",
    "            attn_dropout = float(self.cfg.get(\"attn_dropout\", dropout))\n",
    "            use_posenc = bool(self.cfg.get(\"use_posenc\", True))\n",
    "            pool = self.cfg.get(\"transformer_pool\", \"last\")\n",
    "            posenc_learnable = bool(self.cfg.get(\"posenc_learnable\", False))\n",
    "            max_len = int(self.cfg.get(\"lookback\", 512))\n",
    "\n",
    "            if hidden % n_heads != 0:\n",
    "                raise ValueError(f\"hidden ({hidden}) must be divisible by n_heads ({n_heads}).\")\n",
    "\n",
    "            self.temporal = TemporalTransformerEncoder(\n",
    "                d_model=hidden,\n",
    "                n_heads=n_heads,\n",
    "                n_layers=n_layers,\n",
    "                attn_dropout=attn_dropout,\n",
    "                use_posenc=use_posenc,\n",
    "                max_len=max_len,\n",
    "                pool=pool,\n",
    "                posenc_learnable=posenc_learnable,\n",
    "            )\n",
    "\n",
    "        elif self.temporal_mode == \"attnpool\":\n",
    "            attn_dropout = float(self.cfg.get(\"attn_dropout\", dropout))\n",
    "            self.temporal = TemporalAttnPool(hidden=hidden, dropout=attn_dropout)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"CFG['temporal_mode'] must be 'transformer' or 'attnpool'\")\n",
    "\n",
    "        # --- head (как у тебя, только вход= ltsm_hidden)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(lstm_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, lstm_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, n_classes)\n",
    "        )\n",
    "\n",
    "        # init (как у тебя)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, e, edge_index):\n",
    "        h = x\n",
    "        for gnn in self.gnns:\n",
    "            h = gnn(h, e, edge_index)  # (B,L,N,H)\n",
    "\n",
    "        h_tgt = h[:, :, self.target_node, :]  # (B,L,H)\n",
    "\n",
    "        if self.temporal_mode == \"transformer\":\n",
    "            pooled, _ = self.temporal(h_tgt)   # (B,H)\n",
    "        else:\n",
    "            pooled, _ = self.temporal(h_tgt)   # (B,H)\n",
    "\n",
    "        pooled = torch.nan_to_num(pooled, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        pooled = self.temporal_proj(pooled)    # (B,lstm_hidden)\n",
    "\n",
    "        logits = self.head(pooled)             # (B,2)\n",
    "        return torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "# --- DROP-IN: чтобы вообще не менять train loops / train_binary_classifier\n",
    "#GNN_LSTM_Classifier = GNN_Attn_Classifier\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# SMOKE TEST (быстрый прогон)\n",
    "# -------------------------\n",
    "with torch.no_grad():\n",
    "    B = 2\n",
    "    L = int(CFG.get(\"lookback\", 16))\n",
    "    N = len(ASSETS)\n",
    "    node_in = X_node_raw.shape[-1] if \"X_node_raw\" in globals() else 15\n",
    "    edge_dim = edge_feat.shape[-1] if \"edge_feat\" in globals() else 5\n",
    "    E = EDGE_INDEX.shape[0] if \"EDGE_INDEX\" in globals() else 3\n",
    "\n",
    "    x = torch.randn(B, L, N, node_in).to(DEVICE)\n",
    "    e = torch.randn(B, L, E, edge_dim).to(DEVICE)\n",
    "\n",
    "    # 1) transformer\n",
    "    CFG[\"temporal_mode\"] = \"transformer\"\n",
    "    m = GNN_Attn_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=CFG[\"hidden\"], gnn_layers=CFG[\"gnn_layers\"],\n",
    "        lstm_hidden=CFG[\"lstm_hidden\"], lstm_layers=CFG[\"lstm_layers\"],\n",
    "        dropout=CFG[\"dropout\"], target_node=TARGET_NODE, n_classes=2,\n",
    "        cfg=CFG,\n",
    "    ).to(DEVICE)\n",
    "    y = m(x, e, EDGE_INDEX.to(DEVICE))\n",
    "    print(\"[smoke transformer] logits:\", tuple(y.shape))\n",
    "\n",
    "    # 2) attnpool\n",
    "    CFG[\"temporal_mode\"] = \"attnpool\"\n",
    "    m2 = GNN_Attn_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=CFG[\"hidden\"], gnn_layers=CFG[\"gnn_layers\"],\n",
    "        lstm_hidden=CFG[\"lstm_hidden\"], lstm_layers=CFG[\"lstm_layers\"],\n",
    "        dropout=CFG[\"dropout\"], target_node=TARGET_NODE, n_classes=2,\n",
    "        cfg=CFG,\n",
    "    ).to(DEVICE)\n",
    "    y2 = m2(x, e, EDGE_INDEX.to(DEVICE))\n",
    "    print(\"[smoke attnpool] logits:\", tuple(y2.shape))\n",
    "\n",
    "print(\"Model ready (Attention temporal).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be8053",
   "metadata": {},
   "source": [
    "## 8. Training/Eval: Stage A (trade) и Stage B (direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0561688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: train/eval helpers for two-stage\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_binary(model, loader, loss_fn, y_key: str = \"trade\"):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    probs = []\n",
    "    ers = []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        y = (y_trade_b if y_key == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        n += y.size(0)\n",
    "\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "\n",
    "    ys = np.concatenate(ys) if len(ys) else np.array([], dtype=np.int64)\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, None, ys, probs, ers\n",
    "\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(ys, y_pred)\n",
    "    f1m = f1_score(ys, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(ys, probs[:, 1]) if len(np.unique(ys)) == 2 else np.nan\n",
    "    cm = confusion_matrix(ys, y_pred)\n",
    "\n",
    "    return total_loss / max(n, 1), acc, f1m, auc, cm, ys, probs, ers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_only(model, loader):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, y_trade_b, y_dir_b, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.detach().cpu().numpy())\n",
    "    probs = np.concatenate(probs) if len(probs) else np.zeros((0, 2), dtype=np.float32)\n",
    "    ers = np.concatenate(ers) if len(ers) else np.array([], dtype=np.float32)\n",
    "    return probs, ers\n",
    "\n",
    "\n",
    "def pnl_proxy_grid_max(prob_trade, prob_dir, exit_ret, thr_trade_grid, thr_dir_grid, cost_bps, min_trades: int = 0):\n",
    "    \"\"\"\n",
    "    Возвращает лучший pnl_mean по grid (per-bar), плюс пороги и статистику.\n",
    "    min_trades используется как фильтр: комбинации, где сделок меньше, пропускаются.\n",
    "    Если ни одна комбинация не прошла min_trades — вернём best без фильтра (но это будет fallback-сценарий).\n",
    "    \"\"\"\n",
    "    p_trade = prob_trade[:, 1]\n",
    "    p_up = prob_dir[:, 1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    sign = np.where(p_up >= 0.5, 1.0, -1.0).astype(np.float32)\n",
    "    cost = float(cost_bps) * 1e-4\n",
    "    N = len(exit_ret)\n",
    "\n",
    "    best = {\n",
    "        \"pnl_mean\": -1e18,\n",
    "        \"pnl_sum\": -1e18,\n",
    "        \"thr_trade\": None,\n",
    "        \"thr_dir\": None,\n",
    "        \"n_trades\": 0,\n",
    "        \"trade_rate\": 0.0,\n",
    "        \"min_trades_used\": int(min_trades),\n",
    "        \"passed_min_trades\": False,\n",
    "    }\n",
    "\n",
    "    # 1) строгий проход (>=min_trades)\n",
    "    for thr_t in thr_trade_grid:\n",
    "        mt = (p_trade >= thr_t)\n",
    "        for thr_d in thr_dir_grid:\n",
    "            mask = mt & (conf_dir >= thr_d)\n",
    "            n_tr = int(mask.sum())\n",
    "            if n_tr < int(min_trades):\n",
    "                continue\n",
    "\n",
    "            pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "            pnl_sum = float(pnl.sum())\n",
    "            pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "            if pnl_mean > best[\"pnl_mean\"]:\n",
    "                best.update({\n",
    "                    \"pnl_mean\": pnl_mean,\n",
    "                    \"pnl_sum\": pnl_sum,\n",
    "                    \"thr_trade\": float(thr_t),\n",
    "                    \"thr_dir\": float(thr_d),\n",
    "                    \"n_trades\": n_tr,\n",
    "                    \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                    \"passed_min_trades\": True,\n",
    "                })\n",
    "\n",
    "    # 2) если ничего не прошло min_trades — найдём best без фильтра (для fallback-логов)\n",
    "    if best[\"thr_trade\"] is None:\n",
    "        for thr_t in thr_trade_grid:\n",
    "            mt = (p_trade >= thr_t)\n",
    "            for thr_d in thr_dir_grid:\n",
    "                mask = mt & (conf_dir >= thr_d)\n",
    "                n_tr = int(mask.sum())\n",
    "                pnl = (sign * exit_ret) * mask.astype(np.float32) - cost * mask.astype(np.float32)\n",
    "                pnl_sum = float(pnl.sum())\n",
    "                pnl_mean = float(pnl.mean()) if N > 0 else np.nan\n",
    "\n",
    "                if pnl_mean > best[\"pnl_mean\"]:\n",
    "                    best.update({\n",
    "                        \"pnl_mean\": pnl_mean,\n",
    "                        \"pnl_sum\": pnl_sum,\n",
    "                        \"thr_trade\": float(thr_t),\n",
    "                        \"thr_dir\": float(thr_d),\n",
    "                        \"n_trades\": n_tr,\n",
    "                        \"trade_rate\": float(n_tr / max(1, N)),\n",
    "                        \"passed_min_trades\": False,\n",
    "                    })\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def train_binary_classifier(\n",
    "    X_scaled, edge_feat,\n",
    "    y_trade_arr, y_dir_arr,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train, idx_val, idx_test,\n",
    "    cfg,\n",
    "    stage_name: str,\n",
    "    select_metric: str | None = None,        # \"va_auc\" | \"va_f1m\" | \"va_pnl_max\"\n",
    "    trade_model_for_pnl=None,                # для stage=\"dir\": фиксированная trade-модель\n",
    "    idx_val_pnl=None,                        # индексы (sample-space) для pnl-proxy, обычно полный idx_val\n",
    "):\n",
    "    \"\"\"\n",
    "    Градиентами оптимизируем: CrossEntropyLoss.\n",
    "    Селектор best checkpoint:\n",
    "      - trade: обычно va_auc\n",
    "      - dir:   va_pnl_max, но если best trades < proxy_min_trades => fallback на va_auc\n",
    "              (реализовано как: best_pnl если были эпохи с trades>=min, иначе best_auc)\n",
    "    \"\"\"\n",
    "    if select_metric is None:\n",
    "        select_metric = \"va_auc\"\n",
    "    if select_metric not in (\"va_auc\", \"va_f1m\", \"va_pnl_max\"):\n",
    "        raise ValueError(\"select_metric must be one of: 'va_auc', 'va_f1m', 'va_pnl_max'\")\n",
    "\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if stage_name != \"dir\":\n",
    "            raise ValueError(\"select_metric='va_pnl_max' supported only for stage_name='dir'\")\n",
    "        if trade_model_for_pnl is None or idx_val_pnl is None:\n",
    "            raise ValueError(\"For va_pnl_max you must pass trade_model_for_pnl and idx_val_pnl (full val indices).\")\n",
    "\n",
    "    L = cfg[\"lookback\"]\n",
    "\n",
    "    tr_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_train, L)\n",
    "    va_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val,   L)\n",
    "    te_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_test,  L)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=cfg[\"batch_size\"], shuffle=True,  drop_last=True, collate_fn=collate_fn_2stage)\n",
    "    va_loader = DataLoader(va_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "    te_loader = DataLoader(te_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    va_pnl_loader = None\n",
    "    if stage_name == \"dir\" and (idx_val_pnl is not None):\n",
    "        va_pnl_ds = LobGraphSequenceDataset2Stage(X_scaled, edge_feat, y_trade_arr, y_dir_arr, exit_ret, sample_t, idx_val_pnl, L)\n",
    "        va_pnl_loader = DataLoader(va_pnl_ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    node_in = X_scaled.shape[-1]\n",
    "    edge_dim = edge_feat.shape[-1]\n",
    "    model = GNN_Attn_Classifier(\n",
    "        node_in=node_in, edge_dim=edge_dim,\n",
    "        hidden=cfg[\"hidden\"], gnn_layers=cfg[\"gnn_layers\"],\n",
    "        lstm_hidden=cfg[\"lstm_hidden\"], lstm_layers=cfg[\"lstm_layers\"],\n",
    "        dropout=cfg[\"dropout\"], target_node=TARGET_NODE, n_classes=2,\n",
    "        cfg=cfg,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4)\n",
    "    scaler_amp = torch.amp.GradScaler('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\"))\n",
    "\n",
    "    # --- trade-prob на полном val для PnL proxy (считаем 1 раз)\n",
    "    prob_trade_val_pnl = None\n",
    "    if stage_name == \"dir\" and (trade_model_for_pnl is not None) and (va_pnl_loader is not None):\n",
    "        prob_trade_val_pnl, _ = predict_probs_only(trade_model_for_pnl, va_pnl_loader)\n",
    "\n",
    "    thr_trade_grid_proxy = cfg.get(\"proxy_thr_trade_grid\") or cfg.get(\"thr_trade_grid\", [0.5])\n",
    "    thr_dir_grid_proxy   = cfg.get(\"proxy_thr_dir_grid\")   or cfg.get(\"thr_dir_grid\",   [0.5])\n",
    "    proxy_min_trades = int(cfg.get(\"proxy_min_trades\", 0))\n",
    "\n",
    "    # --- best trackers\n",
    "    best_score = -1e18\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "    best_used = select_metric\n",
    "\n",
    "    # специальные трекеры для va_pnl_max с fallback\n",
    "    best_score_auc = -1e18\n",
    "    best_state_auc = None\n",
    "    best_epoch_auc = -1\n",
    "\n",
    "    best_score_pnl = -1e18\n",
    "    best_state_pnl = None\n",
    "    best_epoch_pnl = -1\n",
    "\n",
    "    seen_pnl_ok = False\n",
    "\n",
    "    patience = 8\n",
    "    bad = 0\n",
    "\n",
    "    hist = {\n",
    "        \"tr_loss\": [], \"va_loss\": [],\n",
    "        \"va_f1m\": [], \"va_auc\": [],\n",
    "        \"va_pnl_max\": [],\n",
    "        \"va_pnl_thr_trade\": [],\n",
    "        \"va_pnl_thr_dir\": [],\n",
    "        \"va_pnl_n_trades\": [],\n",
    "        \"va_sel\": [],\n",
    "        \"va_sel_mode\": []\n",
    "    }\n",
    "\n",
    "    for ep in range(1, cfg[\"epochs\"] + 1):\n",
    "        # ---- TRAIN\n",
    "        model.train()\n",
    "        tot = 0.0\n",
    "        n = 0\n",
    "\n",
    "        for x, e, y_trade_b, y_dir_b, er in tr_loader:\n",
    "            x = x.to(DEVICE).float()\n",
    "            e = e.to(DEVICE).float()\n",
    "            y = (y_trade_b if stage_name == \"trade\" else y_dir_b).to(DEVICE).long()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(cfg[\"use_amp\"] and DEVICE.type == \"cuda\")):\n",
    "                logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip\"])\n",
    "            scaler_amp.step(opt)\n",
    "            scaler_amp.update()\n",
    "\n",
    "            tot += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "\n",
    "        tr_loss = tot / max(n, 1)\n",
    "\n",
    "        # ---- VAL classification metrics\n",
    "        va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "            model, va_loader, loss_fn, y_key=stage_name\n",
    "        )\n",
    "\n",
    "        # ---- VAL PnL proxy (dir only)\n",
    "        va_pnl_best = {\"pnl_mean\": np.nan, \"thr_trade\": np.nan, \"thr_dir\": np.nan, \"n_trades\": 0, \"trade_rate\": np.nan,\n",
    "                       \"passed_min_trades\": False, \"min_trades_used\": proxy_min_trades}\n",
    "\n",
    "        if stage_name == \"dir\" and (prob_trade_val_pnl is not None) and (va_pnl_loader is not None):\n",
    "            prob_dir_val_pnl, er_dir_val_pnl = predict_probs_only(model, va_pnl_loader)\n",
    "\n",
    "            va_pnl_best = pnl_proxy_grid_max(\n",
    "                prob_trade=prob_trade_val_pnl,\n",
    "                prob_dir=prob_dir_val_pnl,\n",
    "                exit_ret=er_dir_val_pnl,\n",
    "                thr_trade_grid=thr_trade_grid_proxy,\n",
    "                thr_dir_grid=thr_dir_grid_proxy,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "                min_trades=proxy_min_trades,\n",
    "            )\n",
    "\n",
    "        # ---- selection\n",
    "        sel_val = np.nan\n",
    "        sel_mode = select_metric\n",
    "\n",
    "        if select_metric in (\"va_auc\", \"va_f1m\"):\n",
    "            sel_val = (va_auc if select_metric == \"va_auc\" else va_f1m)\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "\n",
    "            # единый best\n",
    "            prev_best = best_score\n",
    "            if sel_val > best_score:\n",
    "                best_score = sel_val\n",
    "                best_epoch = ep\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "        else:\n",
    "            # select_metric == \"va_pnl_max\" (dir only) with hard fallback\n",
    "            pnl_mean = float(va_pnl_best[\"pnl_mean\"])\n",
    "            n_tr = int(va_pnl_best[\"n_trades\"])\n",
    "            pnl_ok = (np.isfinite(pnl_mean) and (n_tr >= proxy_min_trades))\n",
    "\n",
    "            # обновим best_auc (fallback) всегда\n",
    "            if np.isfinite(va_auc) and (va_auc > best_score_auc):\n",
    "                best_score_auc = float(va_auc)\n",
    "                best_epoch_auc = ep\n",
    "                best_state_auc = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            # обновим best_pnl только если pnl_ok\n",
    "            if pnl_ok and (pnl_mean > best_score_pnl):\n",
    "                best_score_pnl = pnl_mean\n",
    "                best_epoch_pnl = ep\n",
    "                best_state_pnl = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            if pnl_ok:\n",
    "                seen_pnl_ok = True\n",
    "                sel_val = pnl_mean\n",
    "                sel_mode = \"va_pnl_max\"\n",
    "            else:\n",
    "                sel_val = float(va_auc) if np.isfinite(va_auc) else -1e18\n",
    "                sel_mode = f\"va_auc_fallback({n_tr}/{proxy_min_trades})\"\n",
    "\n",
    "            # scheduler всегда по текущему sel_val\n",
    "            if not np.isfinite(sel_val):\n",
    "                sel_val = -1e18\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "            # early stop: до первой валидной pnl-эпохи -> по AUC, после -> по PnL\n",
    "            improved = False\n",
    "            if not seen_pnl_ok:\n",
    "                # следим за ростом AUC\n",
    "                improved = (np.isfinite(va_auc) and (float(va_auc) >= best_score_auc))\n",
    "            else:\n",
    "                # следим за ростом PnL (только когда pnl_ok)\n",
    "                improved = pnl_ok and (pnl_mean >= best_score_pnl)\n",
    "\n",
    "            if improved:\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "        # если не pnl-метрика — scheduler тут\n",
    "        if select_metric != \"va_pnl_max\":\n",
    "            sch.step(float(sel_val))\n",
    "\n",
    "        # ---- logging + hist\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"va_loss\"].append(va_loss)\n",
    "        hist[\"va_f1m\"].append(va_f1m)\n",
    "        hist[\"va_auc\"].append(va_auc)\n",
    "\n",
    "        hist[\"va_pnl_max\"].append(float(va_pnl_best[\"pnl_mean\"]) if np.isfinite(va_pnl_best[\"pnl_mean\"]) else np.nan)\n",
    "        hist[\"va_pnl_thr_trade\"].append(float(va_pnl_best[\"thr_trade\"]) if va_pnl_best[\"thr_trade\"] is not None else np.nan)\n",
    "        hist[\"va_pnl_thr_dir\"].append(float(va_pnl_best[\"thr_dir\"]) if va_pnl_best[\"thr_dir\"] is not None else np.nan)\n",
    "        hist[\"va_pnl_n_trades\"].append(int(va_pnl_best[\"n_trades\"]))\n",
    "        hist[\"va_sel\"].append(float(sel_val) if np.isfinite(sel_val) else np.nan)\n",
    "        hist[\"va_sel_mode\"].append(sel_mode)\n",
    "\n",
    "        lr_now = opt.param_groups[0][\"lr\"]\n",
    "\n",
    "        # красивый best_str\n",
    "        if select_metric == \"va_pnl_max\":\n",
    "            if best_state_pnl is not None:\n",
    "                best_str = f\"pnl={best_score_pnl:.6f}@ep{best_epoch_pnl:02d}\"\n",
    "            else:\n",
    "                best_str = f\"auc={best_score_auc:.6f}@ep{best_epoch_auc:02d}\"\n",
    "        else:\n",
    "            best_str = f\"{best_score:.6f}@ep{best_epoch:02d}\" if best_epoch > 0 else \"none\"\n",
    "\n",
    "        if stage_name == \"dir\":\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"pnl_max={va_pnl_best['pnl_mean']:.6f} \"\n",
    "                f\"thr=({va_pnl_best['thr_trade']:.2f},{va_pnl_best['thr_dir']:.2f}) \"\n",
    "                f\"trades={va_pnl_best['n_trades']} \"\n",
    "                f\"sel({sel_mode})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"[{stage_name}] ep {ep:02d} lr={lr_now:.2e} \"\n",
    "                f\"tr_loss={tr_loss:.4f} va_loss={va_loss:.4f} \"\n",
    "                f\"f1m={va_f1m:.3f} auc={va_auc:.3f} \"\n",
    "                f\"sel({select_metric})={float(sel_val):.6f} best={best_str}\"\n",
    "            )\n",
    "\n",
    "        if bad >= patience:\n",
    "            break\n",
    "\n",
    "    # ---- choose final best state\n",
    "    if select_metric == \"va_pnl_max\":\n",
    "        if best_state_pnl is not None:\n",
    "            model.load_state_dict(best_state_pnl)\n",
    "            best_score = best_score_pnl\n",
    "            best_epoch = best_epoch_pnl\n",
    "            best_used = \"va_pnl_max\"\n",
    "        else:\n",
    "            model.load_state_dict(best_state_auc)\n",
    "            best_score = best_score_auc\n",
    "            best_epoch = best_epoch_auc\n",
    "            best_used = \"va_auc_fallback_only\"\n",
    "    else:\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "            best_used = select_metric\n",
    "\n",
    "    # финальные VAL/TEST по best_state\n",
    "    va_loss, va_acc, va_f1m, va_auc, va_cm, va_y, va_prob, va_er = eval_binary(\n",
    "        model, va_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "    te_loss, te_acc, te_f1m, te_auc, te_cm, te_y, te_prob, te_er = eval_binary(\n",
    "        model, te_loader, loss_fn, y_key=stage_name\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"best_val_score\": float(best_score),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"select_metric\": select_metric,\n",
    "        \"best_used\": best_used,\n",
    "\n",
    "        \"val_loss\": va_loss,\n",
    "        \"val_acc\": va_acc,\n",
    "        \"val_f1m\": va_f1m,\n",
    "        \"val_auc\": va_auc,\n",
    "        \"val_cm\": va_cm,\n",
    "        \"val_y\": va_y,\n",
    "        \"val_prob\": va_prob,\n",
    "        \"val_er\": va_er,\n",
    "\n",
    "        \"test_loss\": te_loss,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_f1m\": te_f1m,\n",
    "        \"test_auc\": te_auc,\n",
    "        \"test_cm\": te_cm,\n",
    "        \"test_y\": te_y,\n",
    "        \"test_prob\": te_prob,\n",
    "        \"test_er\": te_er,\n",
    "\n",
    "        \"hist\": hist,\n",
    "    }\n",
    "    return model, res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d8c16",
   "metadata": {},
   "source": [
    "## 9. Two-stage PnL by confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d7f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage PnL threshold utils ready.\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: PnL по порогам уверенности (two-stage)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "def two_stage_pnl_by_threshold(\n",
    "    prob_trade,          # (N,2) softmax: [:,1]=p_trade\n",
    "    prob_dir,            # (N,2) softmax: [:,1]=p_up\n",
    "    exit_ret,            # (N,) realized log-ret to TB exit\n",
    "    thr_trade: float,\n",
    "    thr_dir: float,\n",
    "    cost_bps: float,\n",
    "):\n",
    "    p_trade = prob_trade[:,1]\n",
    "    p_up = prob_dir[:,1]\n",
    "    p_dn = 1.0 - p_up\n",
    "    conf_dir = np.maximum(p_up, p_dn)\n",
    "\n",
    "    trade_mask = (p_trade >= thr_trade) & (conf_dir >= thr_dir)\n",
    "\n",
    "    action = np.zeros_like(exit_ret, dtype=np.float32)\n",
    "    action[trade_mask] = np.where(p_up[trade_mask] >= 0.5, 1.0, -1.0)\n",
    "\n",
    "    cost = (cost_bps * 1e-4) * trade_mask.astype(np.float32)\n",
    "    pnl = action * exit_ret - cost\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(exit_ret),\n",
    "        \"n_trades\": int(trade_mask.sum()),\n",
    "        \"trade_rate\": float(trade_mask.mean()),\n",
    "        \"pnl_sum\": float(pnl.sum()),\n",
    "        \"pnl_mean\": float(pnl.mean()),\n",
    "        \"pnl_sharpe\": float((pnl.mean() / (pnl.std() + 1e-12)) * np.sqrt(288)),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def sweep_thresholds(prob_trade, prob_dir, exit_ret, cfg):\n",
    "    rows = []\n",
    "    for thr_t in cfg[\"thr_trade_grid\"]:\n",
    "        for thr_d in cfg[\"thr_dir_grid\"]:\n",
    "            m = two_stage_pnl_by_threshold(\n",
    "                prob_trade=prob_trade,\n",
    "                prob_dir=prob_dir,\n",
    "                exit_ret=exit_ret,\n",
    "                thr_trade=thr_t,\n",
    "                thr_dir=thr_d,\n",
    "                cost_bps=cfg[\"cost_bps\"],\n",
    "            )\n",
    "            rows.append({\"thr_trade\":thr_t, \"thr_dir\":thr_d, **m})\n",
    "    return pd.DataFrame(rows).sort_values([\"pnl_mean\",\"pnl_sum\"], ascending=False)\n",
    "\n",
    "print(\"Two-stage PnL threshold utils ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5c430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: shared helper for probs on arbitrary indices\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_on_indices(model, X_scaled, edge_feat, indices, cfg):\n",
    "    ds = LobGraphSequenceDataset2Stage(\n",
    "        X_scaled, edge_feat, y_trade, y_dir, exit_ret, sample_t, indices, cfg[\"lookback\"]\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=cfg[\"batch_size\"], shuffle=False, collate_fn=collate_fn_2stage)\n",
    "\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ers = []\n",
    "    for x, e, yt, yd, er in loader:\n",
    "        x = x.to(DEVICE).float()\n",
    "        e = e.to(DEVICE).float()\n",
    "        logits = model(x, e, EDGE_INDEX.to(DEVICE))\n",
    "        p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ers.append(er.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(probs), np.concatenate(ers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15582194",
   "metadata": {},
   "source": [
    "## 10. Run folds: scale once → train trade → filter trades → train dir → PnL sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd76a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/4 sizes: 1168 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7668 va_loss=0.6946 f1m=0.380 auc=0.371 sel(va_auc)=0.370785 best=0.370785@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7084 va_loss=0.6893 f1m=0.380 auc=0.311 sel(va_auc)=0.311111 best=0.370785@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6913 va_loss=0.6864 f1m=0.380 auc=0.340 sel(va_auc)=0.339549 best=0.370785@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6940 va_loss=0.6756 f1m=0.380 auc=0.328 sel(va_auc)=0.327661 best=0.370785@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6685 va_loss=0.6733 f1m=0.380 auc=0.435 sel(va_auc)=0.435431 best=0.435431@ep05\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6625 va_loss=0.6795 f1m=0.380 auc=0.369 sel(va_auc)=0.369464 best=0.435431@ep05\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6741 va_loss=0.6705 f1m=0.380 auc=0.451 sel(va_auc)=0.451127 best=0.451127@ep07\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6688 va_loss=0.6735 f1m=0.380 auc=0.451 sel(va_auc)=0.450738 best=0.451127@ep07\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6519 va_loss=0.6745 f1m=0.380 auc=0.416 sel(va_auc)=0.416317 best=0.451127@ep07\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6555 va_loss=0.6791 f1m=0.404 auc=0.435 sel(va_auc)=0.434810 best=0.451127@ep07\n",
      "[trade] ep 11 lr=2.00e-04 tr_loss=0.6415 va_loss=0.6765 f1m=0.380 auc=0.466 sel(va_auc)=0.466434 best=0.466434@ep11\n",
      "[trade] ep 12 lr=2.00e-04 tr_loss=0.6413 va_loss=0.6871 f1m=0.431 auc=0.452 sel(va_auc)=0.451826 best=0.466434@ep11\n",
      "[trade] ep 13 lr=2.00e-04 tr_loss=0.6214 va_loss=0.7016 f1m=0.380 auc=0.489 sel(va_auc)=0.488733 best=0.488733@ep13\n",
      "[trade] ep 14 lr=2.00e-04 tr_loss=0.6230 va_loss=0.6901 f1m=0.403 auc=0.451 sel(va_auc)=0.451204 best=0.488733@ep13\n",
      "[trade] ep 15 lr=2.00e-04 tr_loss=0.6191 va_loss=0.7011 f1m=0.431 auc=0.440 sel(va_auc)=0.439627 best=0.488733@ep13\n",
      "[trade] ep 16 lr=2.00e-04 tr_loss=0.6248 va_loss=0.6775 f1m=0.380 auc=0.481 sel(va_auc)=0.480808 best=0.488733@ep13\n",
      "[trade] ep 17 lr=2.00e-04 tr_loss=0.6256 va_loss=0.6975 f1m=0.380 auc=0.485 sel(va_auc)=0.485237 best=0.488733@ep13\n",
      "[trade] ep 18 lr=1.00e-04 tr_loss=0.6104 va_loss=0.6901 f1m=0.380 auc=0.488 sel(va_auc)=0.488345 best=0.488733@ep13\n",
      "[trade] ep 19 lr=1.00e-04 tr_loss=0.6071 va_loss=0.6781 f1m=0.397 auc=0.495 sel(va_auc)=0.495260 best=0.495260@ep19\n",
      "[trade] ep 20 lr=1.00e-04 tr_loss=0.6056 va_loss=0.6891 f1m=0.414 auc=0.484 sel(va_auc)=0.484227 best=0.495260@ep19\n",
      "[trade] ep 21 lr=1.00e-04 tr_loss=0.6133 va_loss=0.6918 f1m=0.393 auc=0.489 sel(va_auc)=0.489355 best=0.495260@ep19\n",
      "[trade] ep 22 lr=1.00e-04 tr_loss=0.6052 va_loss=0.6895 f1m=0.407 auc=0.477 sel(va_auc)=0.477467 best=0.495260@ep19\n",
      "[trade] ep 23 lr=1.00e-04 tr_loss=0.6091 va_loss=0.6855 f1m=0.389 auc=0.482 sel(va_auc)=0.481507 best=0.495260@ep19\n",
      "[trade] ep 24 lr=5.00e-05 tr_loss=0.5991 va_loss=0.6890 f1m=0.397 auc=0.475 sel(va_auc)=0.474981 best=0.495260@ep19\n",
      "[trade] ep 25 lr=5.00e-05 tr_loss=0.6062 va_loss=0.6935 f1m=0.404 auc=0.474 sel(va_auc)=0.473504 best=0.495260@ep19\n",
      "[trade] ep 26 lr=5.00e-05 tr_loss=0.5981 va_loss=0.6934 f1m=0.426 auc=0.476 sel(va_auc)=0.475524 best=0.495260@ep19\n",
      "[trade] ep 27 lr=5.00e-05 tr_loss=0.5960 va_loss=0.6873 f1m=0.395 auc=0.495 sel(va_auc)=0.495183 best=0.495260@ep19\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8267 va_loss=0.7397 f1m=0.308 auc=0.480 pnl_max=0.000071 thr=(0.50,0.50) trades=6 sel(va_auc_fallback(6/50))=0.479500 best=auc=0.479500@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7561 va_loss=0.7180 f1m=0.328 auc=0.510 pnl_max=0.000003 thr=(0.50,0.60) trades=3 sel(va_auc_fallback(3/50))=0.509500 best=auc=0.509500@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7287 va_loss=0.7174 f1m=0.560 auc=0.511 pnl_max=0.000023 thr=(0.50,0.70) trades=1 sel(va_auc_fallback(1/50))=0.511000 best=auc=0.511000@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7191 va_loss=0.7249 f1m=0.540 auc=0.497 pnl_max=0.000042 thr=(0.50,0.70) trades=2 sel(va_auc_fallback(2/50))=0.497500 best=auc=0.511000@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7085 va_loss=0.7334 f1m=0.285 auc=0.493 pnl_max=0.000042 thr=(0.50,0.70) trades=2 sel(va_auc_fallback(2/50))=0.493500 best=auc=0.511000@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6620 va_loss=0.7468 f1m=0.294 auc=0.471 pnl_max=0.000000 thr=(0.55,0.50) trades=0 sel(va_auc_fallback(0/50))=0.471000 best=auc=0.511000@ep03\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6766 va_loss=0.7634 f1m=0.550 auc=0.469 pnl_max=0.000000 thr=(0.55,0.50) trades=0 sel(va_auc_fallback(0/50))=0.468500 best=auc=0.511000@ep03\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6677 va_loss=0.7807 f1m=0.577 auc=0.445 pnl_max=0.000000 thr=(0.55,0.50) trades=0 sel(va_auc_fallback(0/50))=0.444500 best=auc=0.511000@ep03\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6421 va_loss=0.7889 f1m=0.587 auc=0.444 pnl_max=0.000000 thr=(0.55,0.50) trades=0 sel(va_auc_fallback(0/50))=0.444000 best=auc=0.511000@ep03\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.6212 va_loss=0.8110 f1m=0.529 auc=0.456 pnl_max=0.000000 thr=(0.55,0.50) trades=0 sel(va_auc_fallback(0/50))=0.455500 best=auc=0.511000@ep03\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.6091 va_loss=0.8280 f1m=0.517 auc=0.461 pnl_max=0.000000 thr=(0.55,0.50) trades=0 sel(va_auc_fallback(0/50))=0.461500 best=auc=0.511000@ep03\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0 | trades= 0.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/4 sizes: 1401 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7589 va_loss=0.6182 f1m=0.429 auc=0.761 sel(va_auc)=0.760788 best=0.760788@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7037 va_loss=0.5824 f1m=0.429 auc=0.740 sel(va_auc)=0.740493 best=0.760788@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6951 va_loss=0.6010 f1m=0.429 auc=0.701 sel(va_auc)=0.701379 best=0.760788@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6845 va_loss=0.6038 f1m=0.429 auc=0.680 sel(va_auc)=0.680099 best=0.760788@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6875 va_loss=0.5926 f1m=0.429 auc=0.732 sel(va_auc)=0.731921 best=0.760788@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.6691 va_loss=0.5814 f1m=0.429 auc=0.727 sel(va_auc)=0.727389 best=0.760788@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6717 va_loss=0.5641 f1m=0.429 auc=0.743 sel(va_auc)=0.743251 best=0.760788@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6707 va_loss=0.5714 f1m=0.429 auc=0.701 sel(va_auc)=0.701084 best=0.760788@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6681 va_loss=0.5904 f1m=0.429 auc=0.642 sel(va_auc)=0.642365 best=0.760788@ep01\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7992 va_loss=0.5662 f1m=0.458 auc=0.372 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.371882 best=auc=0.371882@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7629 va_loss=0.6996 f1m=0.389 auc=0.245 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.244898 best=auc=0.371882@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7273 va_loss=0.7404 f1m=0.293 auc=0.138 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.138322 best=auc=0.371882@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7232 va_loss=0.6891 f1m=0.356 auc=0.243 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.242630 best=auc=0.371882@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.7176 va_loss=0.7338 f1m=0.366 auc=0.274 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.274376 best=auc=0.371882@ep01\n",
      "[dir] ep 06 lr=1.00e-04 tr_loss=0.6649 va_loss=0.7320 f1m=0.396 auc=0.259 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.258503 best=auc=0.371882@ep01\n",
      "[dir] ep 07 lr=1.00e-04 tr_loss=0.6695 va_loss=0.7338 f1m=0.341 auc=0.238 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.238095 best=auc=0.371882@ep01\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6764 va_loss=0.8313 f1m=0.187 auc=0.224 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.224490 best=auc=0.371882@ep01\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6622 va_loss=0.8383 f1m=0.192 auc=0.206 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.206349 best=auc=0.371882@ep01\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0 | trades= 0.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/4 sizes: 1634 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7725 va_loss=0.8634 f1m=0.234 auc=0.471 sel(va_auc)=0.470527 best=0.470527@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.6815 va_loss=0.9014 f1m=0.234 auc=0.267 sel(va_auc)=0.266562 best=0.470527@ep01\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6664 va_loss=0.8249 f1m=0.234 auc=0.242 sel(va_auc)=0.242480 best=0.470527@ep01\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6588 va_loss=0.9525 f1m=0.234 auc=0.232 sel(va_auc)=0.232307 best=0.470527@ep01\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6644 va_loss=0.9326 f1m=0.234 auc=0.234 sel(va_auc)=0.233872 best=0.470527@ep01\n",
      "[trade] ep 06 lr=1.00e-04 tr_loss=0.6556 va_loss=0.8373 f1m=0.212 auc=0.220 sel(va_auc)=0.220223 best=0.470527@ep01\n",
      "[trade] ep 07 lr=1.00e-04 tr_loss=0.6563 va_loss=0.9324 f1m=0.234 auc=0.227 sel(va_auc)=0.226656 best=0.470527@ep01\n",
      "[trade] ep 08 lr=1.00e-04 tr_loss=0.6460 va_loss=0.9166 f1m=0.234 auc=0.218 sel(va_auc)=0.217962 best=0.470527@ep01\n",
      "[trade] ep 09 lr=1.00e-04 tr_loss=0.6346 va_loss=0.9397 f1m=0.234 auc=0.211 sel(va_auc)=0.211355 best=0.470527@ep01\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7959 va_loss=0.8042 f1m=0.382 auc=0.310 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.310484 best=auc=0.310484@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7361 va_loss=0.7137 f1m=0.382 auc=0.244 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.243548 best=auc=0.310484@ep01\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7313 va_loss=0.7240 f1m=0.382 auc=0.282 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.281774 best=auc=0.310484@ep01\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6963 va_loss=0.7157 f1m=0.382 auc=0.268 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.267581 best=auc=0.310484@ep01\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6944 va_loss=0.7046 f1m=0.382 auc=0.268 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.268226 best=auc=0.310484@ep01\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.7029 va_loss=0.6968 f1m=0.382 auc=0.320 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.320484 best=auc=0.320484@ep06\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6734 va_loss=0.6860 f1m=0.382 auc=0.359 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.358548 best=auc=0.358548@ep07\n",
      "[dir] ep 08 lr=2.00e-04 tr_loss=0.6677 va_loss=0.6981 f1m=0.382 auc=0.395 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.395484 best=auc=0.395484@ep08\n",
      "[dir] ep 09 lr=2.00e-04 tr_loss=0.6591 va_loss=0.7032 f1m=0.382 auc=0.437 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.437419 best=auc=0.437419@ep09\n",
      "[dir] ep 10 lr=2.00e-04 tr_loss=0.6303 va_loss=0.6830 f1m=0.382 auc=0.517 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.517258 best=auc=0.517258@ep10\n",
      "[dir] ep 11 lr=2.00e-04 tr_loss=0.6269 va_loss=0.6750 f1m=0.382 auc=0.550 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.550323 best=auc=0.550323@ep11\n",
      "[dir] ep 12 lr=2.00e-04 tr_loss=0.6206 va_loss=0.6769 f1m=0.382 auc=0.515 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.514677 best=auc=0.550323@ep11\n",
      "[dir] ep 13 lr=2.00e-04 tr_loss=0.5981 va_loss=0.6787 f1m=0.382 auc=0.513 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.512581 best=auc=0.550323@ep11\n",
      "[dir] ep 14 lr=2.00e-04 tr_loss=0.5781 va_loss=0.6862 f1m=0.382 auc=0.476 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.476290 best=auc=0.550323@ep11\n",
      "[dir] ep 15 lr=2.00e-04 tr_loss=0.5800 va_loss=0.6985 f1m=0.382 auc=0.515 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.515484 best=auc=0.550323@ep11\n",
      "[dir] ep 16 lr=1.00e-04 tr_loss=0.5523 va_loss=0.6927 f1m=0.382 auc=0.447 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.447097 best=auc=0.550323@ep11\n",
      "[dir] ep 17 lr=1.00e-04 tr_loss=0.5561 va_loss=0.6869 f1m=0.382 auc=0.483 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.482581 best=auc=0.550323@ep11\n",
      "[dir] ep 18 lr=1.00e-04 tr_loss=0.5592 va_loss=0.6808 f1m=0.382 auc=0.531 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.531452 best=auc=0.550323@ep11\n",
      "[dir] ep 19 lr=1.00e-04 tr_loss=0.5049 va_loss=0.6801 f1m=0.379 auc=0.519 pnl_max=0.000000 thr=(0.50,0.50) trades=0 sel(va_auc_fallback(0/50))=0.519194 best=auc=0.550323@ep11\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.5 | pnl_mean= 0.0 | trades= 0.0\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/4 sizes: 1867 233 233\n",
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7845 va_loss=0.4433 f1m=0.463 auc=0.601 sel(va_auc)=0.601057 best=0.601057@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.7170 va_loss=0.4690 f1m=0.463 auc=0.705 sel(va_auc)=0.704602 best=0.704602@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.7019 va_loss=0.5196 f1m=0.463 auc=0.733 sel(va_auc)=0.732743 best=0.732743@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6746 va_loss=0.5147 f1m=0.463 auc=0.718 sel(va_auc)=0.718284 best=0.732743@ep03\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6728 va_loss=0.4326 f1m=0.463 auc=0.727 sel(va_auc)=0.726835 best=0.732743@ep03\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6638 va_loss=0.4154 f1m=0.463 auc=0.742 sel(va_auc)=0.741760 best=0.741760@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6599 va_loss=0.3915 f1m=0.463 auc=0.731 sel(va_auc)=0.730877 best=0.741760@ep06\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6430 va_loss=0.4361 f1m=0.463 auc=0.713 sel(va_auc)=0.713464 best=0.741760@ep06\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6426 va_loss=0.4236 f1m=0.463 auc=0.710 sel(va_auc)=0.710044 best=0.741760@ep06\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6427 va_loss=0.4311 f1m=0.461 auc=0.705 sel(va_auc)=0.705068 best=0.741760@ep06\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.6236 va_loss=0.3705 f1m=0.463 auc=0.703 sel(va_auc)=0.703047 best=0.741760@ep06\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.6330 va_loss=0.4200 f1m=0.548 auc=0.699 sel(va_auc)=0.699160 best=0.741760@ep06\n",
      "[trade] ep 13 lr=1.00e-04 tr_loss=0.6289 va_loss=0.4125 f1m=0.545 auc=0.702 sel(va_auc)=0.702114 best=0.741760@ep06\n",
      "[trade] ep 14 lr=1.00e-04 tr_loss=0.6188 va_loss=0.3954 f1m=0.463 auc=0.701 sel(va_auc)=0.700560 best=0.741760@ep06\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.7788 va_loss=0.6743 f1m=0.593 auc=0.614 pnl_max=0.001356 thr=(0.65,0.50) trades=220 sel(va_pnl_max)=0.001356 best=pnl=0.001356@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7023 va_loss=0.6706 f1m=0.655 auc=0.644 pnl_max=0.002104 thr=(0.50,0.50) trades=233 sel(va_pnl_max)=0.002104 best=pnl=0.002104@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.7066 va_loss=0.6715 f1m=0.687 auc=0.665 pnl_max=0.002675 thr=(0.50,0.50) trades=233 sel(va_pnl_max)=0.002675 best=pnl=0.002675@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.6925 va_loss=0.6679 f1m=0.665 auc=0.661 pnl_max=0.002403 thr=(0.50,0.50) trades=233 sel(va_pnl_max)=0.002403 best=pnl=0.002675@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6843 va_loss=0.6673 f1m=0.627 auc=0.652 pnl_max=0.001762 thr=(0.50,0.50) trades=233 sel(va_pnl_max)=0.001762 best=pnl=0.002675@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6877 va_loss=0.6690 f1m=0.420 auc=0.690 pnl_max=0.001544 thr=(0.50,0.55) trades=117 sel(va_pnl_max)=0.001544 best=pnl=0.002675@ep03\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6931 va_loss=0.6741 f1m=0.638 auc=0.713 pnl_max=0.002155 thr=(0.65,0.50) trades=220 sel(va_pnl_max)=0.002155 best=pnl=0.002675@ep03\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6616 va_loss=0.6895 f1m=0.515 auc=0.672 pnl_max=0.000936 thr=(0.65,0.50) trades=220 sel(va_pnl_max)=0.000936 best=pnl=0.002675@ep03\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6518 va_loss=0.6782 f1m=0.568 auc=0.648 pnl_max=0.001508 thr=(0.50,0.55) trades=151 sel(va_pnl_max)=0.001508 best=pnl=0.002675@ep03\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.6404 va_loss=0.6868 f1m=0.524 auc=0.645 pnl_max=0.001013 thr=(0.70,0.50) trades=171 sel(va_pnl_max)=0.001013 best=pnl=0.002675@ep03\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.6397 va_loss=0.6967 f1m=0.500 auc=0.656 pnl_max=0.000832 thr=(0.65,0.50) trades=220 sel(va_pnl_max)=0.000832 best=pnl=0.002675@ep03\n",
      "PnL on fold-test: | thr_trade= 0.5 | thr_dir= 0.6 | pnl_mean= 0.0 | trades= 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>trade_test_f1m</th>\n",
       "      <th>dir_test_f1m</th>\n",
       "      <th>best_pnl_mean</th>\n",
       "      <th>best_thr_trade</th>\n",
       "      <th>best_thr_dir</th>\n",
       "      <th>n_trades_best</th>\n",
       "      <th>trade_rate_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.428922</td>\n",
       "      <td>0.198317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.233553</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.120755</td>\n",
       "      <td>0.345277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.515032</td>\n",
       "      <td>0.396988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  trade_test_f1m  dir_test_f1m  best_pnl_mean  best_thr_trade  \\\n",
       "0     1        0.428922      0.198317            0.0             0.5   \n",
       "1     2        0.233553      0.381679            0.0             0.5   \n",
       "2     3        0.120755      0.345277            0.0             0.5   \n",
       "3     4        0.515032      0.396988            0.0             0.5   \n",
       "\n",
       "   best_thr_dir  n_trades_best  trade_rate_best  \n",
       "0           0.5            0.0              0.0  \n",
       "1           0.5            0.0              0.0  \n",
       "2           0.5            0.0              0.0  \n",
       "3           0.6            0.0              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN (fold-test внутри CV-part):\n",
      "fold               2.500000\n",
      "trade_test_f1m     0.324565\n",
      "dir_test_f1m       0.330565\n",
      "best_pnl_mean      0.000000\n",
      "best_thr_trade     0.500000\n",
      "best_thr_dir       0.525000\n",
      "n_trades_best      0.000000\n",
      "trade_rate_best    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: run walk-forward folds for two-stage training (ONLY on CV-part)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "fold_rows = []\n",
    "models_trade = []\n",
    "models_dir = []\n",
    "\n",
    "for fi, (idx_tr, idx_va, idx_te) in enumerate(walk_splits, 1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fi}/{len(walk_splits)} sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # scale once per fold (fit only on train times)\n",
    "    X_scaled, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_tr, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "    # ---- Stage A: trade/no-trade on all samples (по AUC)\n",
    "    m_trade, r_trade = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr, idx_va, idx_te,\n",
    "        CFG,\n",
    "        stage_name=\"trade\",\n",
    "        select_metric=\"va_auc\",\n",
    "    )\n",
    "    models_trade.append(m_trade)\n",
    "\n",
    "    # ---- Stage B: direction ONLY on trade samples (train/val/test индексы фильтруем)\n",
    "    idx_tr_T = subset_trade_indices(idx_tr, sample_t, y_trade)\n",
    "    idx_va_T = subset_trade_indices(idx_va, sample_t, y_trade)\n",
    "    idx_te_T = subset_trade_indices(idx_te, sample_t, y_trade)\n",
    "\n",
    "    if len(idx_tr_T) < max(200, CFG[\"batch_size\"]*2) or len(idx_te_T) < 50:\n",
    "        print(\"[dir] skip: not enough trade samples in this fold.\")\n",
    "        fold_rows.append({\n",
    "            \"fold\": fi,\n",
    "            \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "            \"dir_test_f1m\": np.nan,\n",
    "            \"best_pnl_mean\": np.nan,\n",
    "            \"best_thr_trade\": np.nan,\n",
    "            \"best_thr_dir\": np.nan,\n",
    "            \"n_trades_best\": np.nan,\n",
    "            \"trade_rate_best\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # dir: учим на trade-only, но PnL-proxy считаем на полном idx_va (full val)\n",
    "    m_dir, r_dir = train_binary_classifier(\n",
    "        X_scaled, edge_feat,\n",
    "        y_trade, y_dir,\n",
    "        exit_ret, sample_t,\n",
    "        idx_tr_T, idx_va_T, idx_te_T,\n",
    "        CFG,\n",
    "        stage_name=\"dir\",\n",
    "        select_metric=\"va_pnl_max\",\n",
    "        trade_model_for_pnl=m_trade,\n",
    "        idx_val_pnl=idx_va,   # <-- полный val для pnl-proxy\n",
    "    )\n",
    "    models_dir.append(m_dir)\n",
    "\n",
    "    # ---- Two-stage PnL evaluation on fold TEST\n",
    "    prob_trade_te, er_te = predict_probs_on_indices(m_trade, X_scaled, edge_feat, idx_te, CFG)\n",
    "    prob_dir_te, _       = predict_probs_on_indices(m_dir,   X_scaled, edge_feat, idx_te, CFG)\n",
    "\n",
    "    sweep = sweep_thresholds(prob_trade_te, prob_dir_te, er_te, CFG)\n",
    "    best = sweep.iloc[0].to_dict()\n",
    "\n",
    "    print(\"PnL on fold-test:\",\n",
    "          \"| thr_trade=\", best[\"thr_trade\"],\n",
    "          \"| thr_dir=\", best[\"thr_dir\"],\n",
    "          \"| pnl_mean=\", best[\"pnl_mean\"],\n",
    "          \"| trades=\", best[\"n_trades\"])\n",
    "\n",
    "    fold_rows.append({\n",
    "        \"fold\": fi,\n",
    "        \"trade_test_f1m\": r_trade[\"test_f1m\"],\n",
    "        \"dir_test_f1m\": r_dir[\"test_f1m\"],\n",
    "        \"best_pnl_mean\": best[\"pnl_mean\"],\n",
    "        \"best_thr_trade\": best[\"thr_trade\"],\n",
    "        \"best_thr_dir\": best[\"thr_dir\"],\n",
    "        \"n_trades_best\": best[\"n_trades\"],\n",
    "        \"trade_rate_best\": best[\"trade_rate\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(fold_rows)\n",
    "display(summary)\n",
    "print(\"\\nMEAN (fold-test внутри CV-part):\")\n",
    "print(summary.mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea9ac3",
   "metadata": {},
   "source": [
    "## 11. Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50d16463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL TRAIN/TEST (CV=90% | FINAL=10%)\n",
      "Final split sizes:\n",
      "  train_final: 2104\n",
      "  val_final  : 233\n",
      "  FINAL test : 260\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : 0.00010919975466094911\n",
      "  pnl_sum  : 0.028391936793923378\n",
      "  n_trades : 27\n",
      "  trade_rate: 0.10384615384615385\n",
      "  sharpe (per-bar proxy): 0.7988579415838531\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.55 thr_dir: 0.6\n",
      "  pnl_mean : 0.00016489169502165169 trades: 24.0\n"
     ]
    }
   ],
   "source": [
    "# ЛОГИЧЕСКИЙ БЛОК: Final train on CV(90%) and evaluate once on FINAL(10%)\n",
    "# ИСПОЛНЕНИЕ БЛОКА:\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAIN/TEST (CV=90% | FINAL=10%)\")\n",
    "\n",
    "# 1) final train/val split внутри CV-part (по времени)\n",
    "val_w_final = max(1, int(CFG[\"val_window_frac\"] * n_samples_cv))\n",
    "train_end = n_samples_cv - val_w_final\n",
    "\n",
    "idx_train_final = np.arange(0, train_end, dtype=np.int64)\n",
    "idx_val_final   = np.arange(train_end, n_samples_cv, dtype=np.int64)\n",
    "idx_test_final  = idx_final_test.astype(np.int64)  # финальный holdout\n",
    "\n",
    "print(\"Final split sizes:\")\n",
    "print(\"  train_final:\", len(idx_train_final))\n",
    "print(\"  val_final  :\", len(idx_val_final))\n",
    "print(\"  FINAL test :\", len(idx_test_final))\n",
    "\n",
    "# 2) scaling (fit only on train_final)\n",
    "X_scaled_final, _ = fit_scale_nodes_train_only(X_node_raw, sample_t, idx_train_final, max_abs=CFG[\"max_abs_feat\"])\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=summary['best_thr_trade'][3],\n",
    "    thr_dir=summary['best_thr_dir'][3],\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c4946a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trade] ep 01 lr=2.00e-04 tr_loss=0.7465 va_loss=0.6877 f1m=0.525 auc=0.485 sel(va_auc)=0.485082 best=0.485082@ep01\n",
      "[trade] ep 02 lr=2.00e-04 tr_loss=0.6760 va_loss=0.7058 f1m=0.536 auc=0.489 sel(va_auc)=0.488889 best=0.488889@ep02\n",
      "[trade] ep 03 lr=2.00e-04 tr_loss=0.6487 va_loss=0.7180 f1m=0.477 auc=0.521 sel(va_auc)=0.520979 best=0.520979@ep03\n",
      "[trade] ep 04 lr=2.00e-04 tr_loss=0.6296 va_loss=0.7273 f1m=0.499 auc=0.545 sel(va_auc)=0.545221 best=0.545221@ep04\n",
      "[trade] ep 05 lr=2.00e-04 tr_loss=0.6267 va_loss=0.7286 f1m=0.481 auc=0.545 sel(va_auc)=0.544988 best=0.545221@ep04\n",
      "[trade] ep 06 lr=2.00e-04 tr_loss=0.6248 va_loss=0.7161 f1m=0.474 auc=0.547 sel(va_auc)=0.546931 best=0.546931@ep06\n",
      "[trade] ep 07 lr=2.00e-04 tr_loss=0.6215 va_loss=0.6990 f1m=0.540 auc=0.540 sel(va_auc)=0.539705 best=0.546931@ep06\n",
      "[trade] ep 08 lr=2.00e-04 tr_loss=0.6249 va_loss=0.7194 f1m=0.489 auc=0.543 sel(va_auc)=0.542735 best=0.546931@ep06\n",
      "[trade] ep 09 lr=2.00e-04 tr_loss=0.6198 va_loss=0.7184 f1m=0.481 auc=0.529 sel(va_auc)=0.528982 best=0.546931@ep06\n",
      "[trade] ep 10 lr=2.00e-04 tr_loss=0.6069 va_loss=0.7114 f1m=0.540 auc=0.529 sel(va_auc)=0.529448 best=0.546931@ep06\n",
      "[trade] ep 11 lr=1.00e-04 tr_loss=0.5929 va_loss=0.7245 f1m=0.540 auc=0.497 sel(va_auc)=0.496659 best=0.546931@ep06\n",
      "[trade] ep 12 lr=1.00e-04 tr_loss=0.5924 va_loss=0.7239 f1m=0.484 auc=0.494 sel(va_auc)=0.494095 best=0.546931@ep06\n",
      "[trade] ep 13 lr=1.00e-04 tr_loss=0.6044 va_loss=0.7130 f1m=0.520 auc=0.508 sel(va_auc)=0.507615 best=0.546931@ep06\n",
      "[trade] ep 14 lr=1.00e-04 tr_loss=0.5927 va_loss=0.7332 f1m=0.444 auc=0.497 sel(va_auc)=0.497358 best=0.546931@ep06\n",
      "Trade-only sizes for DIR:\n",
      "  train_final_T: 963\n",
      "  val_final_T  : 143\n",
      "  test_final_T : 207\n",
      "[dir] ep 01 lr=2.00e-04 tr_loss=0.8155 va_loss=0.7020 f1m=0.435 auc=0.496 pnl_max=-0.000832 thr=(0.50,0.50) trades=130 sel(va_pnl_max)=-0.000832 best=pnl=-0.000832@ep01\n",
      "[dir] ep 02 lr=2.00e-04 tr_loss=0.7312 va_loss=0.6877 f1m=0.598 auc=0.576 pnl_max=-0.000084 thr=(0.60,0.50) trades=105 sel(va_pnl_max)=-0.000084 best=pnl=-0.000084@ep02\n",
      "[dir] ep 03 lr=2.00e-04 tr_loss=0.6943 va_loss=0.6849 f1m=0.514 auc=0.609 pnl_max=0.000879 thr=(0.55,0.50) trades=111 sel(va_pnl_max)=0.000879 best=pnl=0.000879@ep03\n",
      "[dir] ep 04 lr=2.00e-04 tr_loss=0.7001 va_loss=0.6898 f1m=0.594 auc=0.577 pnl_max=-0.000546 thr=(0.60,0.50) trades=105 sel(va_pnl_max)=-0.000546 best=pnl=0.000879@ep03\n",
      "[dir] ep 05 lr=2.00e-04 tr_loss=0.6906 va_loss=0.6971 f1m=0.337 auc=0.567 pnl_max=-0.000667 thr=(0.65,0.50) trades=82 sel(va_pnl_max)=-0.000667 best=pnl=0.000879@ep03\n",
      "[dir] ep 06 lr=2.00e-04 tr_loss=0.6921 va_loss=0.7065 f1m=0.316 auc=0.586 pnl_max=-0.000484 thr=(0.65,0.50) trades=82 sel(va_pnl_max)=-0.000484 best=pnl=0.000879@ep03\n",
      "[dir] ep 07 lr=2.00e-04 tr_loss=0.6735 va_loss=0.6978 f1m=0.459 auc=0.542 pnl_max=-0.000285 thr=(0.50,0.50) trades=130 sel(va_pnl_max)=-0.000285 best=pnl=0.000879@ep03\n",
      "[dir] ep 08 lr=1.00e-04 tr_loss=0.6784 va_loss=0.7055 f1m=0.360 auc=0.578 pnl_max=-0.000701 thr=(0.65,0.55) trades=51 sel(va_pnl_max)=-0.000701 best=pnl=0.000879@ep03\n",
      "[dir] ep 09 lr=1.00e-04 tr_loss=0.6624 va_loss=0.7152 f1m=0.316 auc=0.593 pnl_max=-0.000484 thr=(0.65,0.50) trades=82 sel(va_pnl_max)=-0.000484 best=pnl=0.000879@ep03\n",
      "[dir] ep 10 lr=1.00e-04 tr_loss=0.6415 va_loss=0.7134 f1m=0.316 auc=0.626 pnl_max=-0.000484 thr=(0.65,0.50) trades=82 sel(va_pnl_max)=-0.000484 best=pnl=0.000879@ep03\n",
      "[dir] ep 11 lr=1.00e-04 tr_loss=0.6417 va_loss=0.7128 f1m=0.316 auc=0.637 pnl_max=-0.000484 thr=(0.65,0.50) trades=82 sel(va_pnl_max)=-0.000484 best=pnl=0.000879@ep03\n",
      "\n",
      "Chosen thresholds on val_final:\n",
      "  thr_trade*: 0.55\n",
      "  thr_dir*  : 0.5\n",
      "  val pnl_mean: 0.0008793226443231106 | val trades: 111\n",
      "\n",
      "FINAL HOLDOUT RESULT (fixed thresholds from val_final):\n",
      "  pnl_mean : -0.0006584244547411799\n",
      "  pnl_sum  : -0.17119035124778748\n",
      "  n_trades : 257\n",
      "  trade_rate: 0.9884615384615385\n",
      "  sharpe (per-bar proxy): -1.2857051238650743\n",
      "\n",
      "[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\n",
      "  thr_trade: 0.5 thr_dir: 0.65\n",
      "  pnl_mean : 0.0 trades: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3) train TRADE on train_final, select by AUC on val_final\n",
    "m_trade_final, r_trade_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final, idx_val_final, idx_test_final,\n",
    "    CFG,\n",
    "    stage_name=\"trade\",\n",
    "    select_metric=\"va_auc\",\n",
    ")\n",
    "\n",
    "# 4) train DIR on trade-only samples (train/val/test filtered),\n",
    "#    but pnl-proxy computed on full val_final; selector hard-fallback already inside\n",
    "idx_train_final_T = subset_trade_indices(idx_train_final, sample_t, y_trade)\n",
    "idx_val_final_T   = subset_trade_indices(idx_val_final,   sample_t, y_trade)\n",
    "idx_test_final_T  = subset_trade_indices(idx_test_final,  sample_t, y_trade)\n",
    "\n",
    "print(\"Trade-only sizes for DIR:\")\n",
    "print(\"  train_final_T:\", len(idx_train_final_T))\n",
    "print(\"  val_final_T  :\", len(idx_val_final_T))\n",
    "print(\"  test_final_T :\", len(idx_test_final_T))\n",
    "\n",
    "m_dir_final, r_dir_final = train_binary_classifier(\n",
    "    X_scaled_final, edge_feat,\n",
    "    y_trade, y_dir,\n",
    "    exit_ret, sample_t,\n",
    "    idx_train_final_T, idx_val_final_T, idx_test_final_T,\n",
    "    CFG,\n",
    "    stage_name=\"dir\",\n",
    "    select_metric=\"va_pnl_max\",\n",
    "    trade_model_for_pnl=m_trade_final,\n",
    "    idx_val_pnl=idx_val_final,   # pnl-proxy на полном val_final\n",
    ")\n",
    "\n",
    "# 5) выбрать пороги по val_final (grid sweep)\n",
    "prob_trade_val, er_val = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "prob_dir_val, _        = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_val_final, CFG)\n",
    "\n",
    "sweep_val = sweep_thresholds(prob_trade_val, prob_dir_val, er_val, CFG)\n",
    "best_val = sweep_val.iloc[0].to_dict()\n",
    "thr_trade_star = float(best_val[\"thr_trade\"])\n",
    "thr_dir_star   = float(best_val[\"thr_dir\"])\n",
    "\n",
    "print(\"\\nChosen thresholds on val_final:\")\n",
    "print(\"  thr_trade*:\", thr_trade_star)\n",
    "print(\"  thr_dir*  :\", thr_dir_star)\n",
    "print(\"  val pnl_mean:\", float(best_val[\"pnl_mean\"]), \"| val trades:\", int(best_val[\"n_trades\"]))\n",
    "\n",
    "# 6) финальная оценка на holdout (БЕЗ подбора порогов на holdout)\n",
    "prob_trade_hold, er_hold = predict_probs_on_indices(m_trade_final, X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "prob_dir_hold, _         = predict_probs_on_indices(m_dir_final,   X_scaled_final, edge_feat, idx_test_final, CFG)\n",
    "\n",
    "final_metrics = two_stage_pnl_by_threshold(\n",
    "    prob_trade=prob_trade_hold,\n",
    "    prob_dir=prob_dir_hold,\n",
    "    exit_ret=er_hold,\n",
    "    thr_trade=thr_trade_star,\n",
    "    thr_dir=thr_dir_star,\n",
    "    cost_bps=CFG[\"cost_bps\"],\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL HOLDOUT RESULT (fixed thresholds from val_final):\")\n",
    "print(\"  pnl_mean :\", final_metrics[\"pnl_mean\"])\n",
    "print(\"  pnl_sum  :\", final_metrics[\"pnl_sum\"])\n",
    "print(\"  n_trades :\", final_metrics[\"n_trades\"])\n",
    "print(\"  trade_rate:\", final_metrics[\"trade_rate\"])\n",
    "print(\"  sharpe (per-bar proxy):\", final_metrics[\"pnl_sharpe\"])\n",
    "\n",
    "# (опционально) oracle на holdout — НЕ для выбора, только “потолок”\n",
    "sweep_hold_oracle = sweep_thresholds(prob_trade_hold, prob_dir_hold, er_hold, CFG)\n",
    "best_hold_oracle = sweep_hold_oracle.iloc[0].to_dict()\n",
    "print(\"\\n[ORACLE] best possible on holdout by sweeping thresholds (DO NOT USE for selection):\")\n",
    "print(\"  thr_trade:\", best_hold_oracle[\"thr_trade\"], \"thr_dir:\", best_hold_oracle[\"thr_dir\"])\n",
    "print(\"  pnl_mean :\", best_hold_oracle[\"pnl_mean\"], \"trades:\", best_hold_oracle[\"n_trades\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
